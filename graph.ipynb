{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "b3fa745a-a393-498b-ab51-68804fadf751",
      "metadata": {
        "id": "b3fa745a-a393-498b-ab51-68804fadf751"
      },
      "source": [
        "\n",
        "# Building Multi-Agent Systems with Strands Agent Graph\n",
        "Multi-agent systems leverage multiple specialized AI agents working together to solve complex problems through coordinated collaboration. Each agent has specific capabilities and roles, connected through explicit communication pathways.\n",
        "\n",
        "In this lab, you'll learn to build multi-agent systems using the Strands Agent SDK. We'll progress from basic concepts to advanced implementations, exploring different topologies and real-world applications.\n",
        "\n",
        "**Learning Objectives:**\n",
        "By the end of this notebook, you'll be able to:\n",
        "- Understand the three core components of agent graphs (nodes, edges, conditions)\n",
        "- Send targeted messages between specific agents\n",
        "- Monitor and control multi-agent networks\n",
        "- Design specialized agent systems for real-world scenarios\n",
        "\n",
        "## Prerequisites\n",
        "\n",
        "- Python 3.10+\n",
        "- AWS account with Anthropic Claude 3.7 enabled on Amazon Bedrock\n",
        "- IAM role with permissions to use Amazon Bedrock\n",
        "- Basic understanding of AI agents and prompt engineering"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "afc1a597-0490-4ab1-9324-5498b5592662",
      "metadata": {
        "id": "afc1a597-0490-4ab1-9324-5498b5592662"
      },
      "source": [
        "## Setup and Installation\n",
        "\n",
        "Before we start, let's install the requirement packages for `strands-agents` and `strands-agents-tools`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "id": "e048e8cf-3fa7-495b-a761-7999936171c5",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e048e8cf-3fa7-495b-a761-7999936171c5",
        "outputId": "634020aa-73d6-4f76-9956-466cc704fdc8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: strands-agents in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 1)) (1.18.0)\n",
            "Requirement already satisfied: strands-agents-tools in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 2)) (0.2.16)\n",
            "Requirement already satisfied: perplexityai in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 3)) (0.20.0)\n",
            "Requirement already satisfied: boto3<2.0.0,>=1.26.0 in /usr/local/lib/python3.12/dist-packages (from strands-agents->-r requirements.txt (line 1)) (1.41.2)\n",
            "Requirement already satisfied: botocore<2.0.0,>=1.29.0 in /usr/local/lib/python3.12/dist-packages (from strands-agents->-r requirements.txt (line 1)) (1.41.2)\n",
            "Requirement already satisfied: docstring-parser<1.0,>=0.15 in /usr/local/lib/python3.12/dist-packages (from strands-agents->-r requirements.txt (line 1)) (0.17.0)\n",
            "Requirement already satisfied: jsonschema<5.0.0,>=4.0.0 in /usr/local/lib/python3.12/dist-packages (from strands-agents->-r requirements.txt (line 1)) (4.25.1)\n",
            "Requirement already satisfied: mcp<2.0.0,>=1.11.0 in /usr/local/lib/python3.12/dist-packages (from strands-agents->-r requirements.txt (line 1)) (1.22.0)\n",
            "Requirement already satisfied: opentelemetry-api<2.0.0,>=1.30.0 in /usr/local/lib/python3.12/dist-packages (from strands-agents->-r requirements.txt (line 1)) (1.38.0)\n",
            "Requirement already satisfied: opentelemetry-instrumentation-threading<1.00b0,>=0.51b0 in /usr/local/lib/python3.12/dist-packages (from strands-agents->-r requirements.txt (line 1)) (0.59b0)\n",
            "Requirement already satisfied: opentelemetry-sdk<2.0.0,>=1.30.0 in /usr/local/lib/python3.12/dist-packages (from strands-agents->-r requirements.txt (line 1)) (1.38.0)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.4.0 in /usr/local/lib/python3.12/dist-packages (from strands-agents->-r requirements.txt (line 1)) (2.11.10)\n",
            "Requirement already satisfied: typing-extensions<5.0.0,>=4.13.2 in /usr/local/lib/python3.12/dist-packages (from strands-agents->-r requirements.txt (line 1)) (4.15.0)\n",
            "Requirement already satisfied: watchdog<7.0.0,>=6.0.0 in /usr/local/lib/python3.12/dist-packages (from strands-agents->-r requirements.txt (line 1)) (6.0.0)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.0 in /usr/local/lib/python3.12/dist-packages (from strands-agents-tools->-r requirements.txt (line 2)) (3.13.2)\n",
            "Requirement already satisfied: aws-requests-auth<0.5.0,>=0.4.3 in /usr/local/lib/python3.12/dist-packages (from strands-agents-tools->-r requirements.txt (line 2)) (0.4.3)\n",
            "Requirement already satisfied: dill<0.5.0,>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from strands-agents-tools->-r requirements.txt (line 2)) (0.4.0)\n",
            "Requirement already satisfied: markdownify<2.0.0,>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from strands-agents-tools->-r requirements.txt (line 2)) (1.2.2)\n",
            "Requirement already satisfied: pillow<12.0.0,>=11.2.1 in /usr/local/lib/python3.12/dist-packages (from strands-agents-tools->-r requirements.txt (line 2)) (11.3.0)\n",
            "Requirement already satisfied: prompt-toolkit<4.0.0,>=3.0.51 in /usr/local/lib/python3.12/dist-packages (from strands-agents-tools->-r requirements.txt (line 2)) (3.0.52)\n",
            "Requirement already satisfied: pyjwt<3.0.0,>=2.10.1 in /usr/local/lib/python3.12/dist-packages (from strands-agents-tools->-r requirements.txt (line 2)) (2.10.1)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.28.0 in /usr/local/lib/python3.12/dist-packages (from strands-agents-tools->-r requirements.txt (line 2)) (2.32.4)\n",
            "Requirement already satisfied: rich<15.0.0,>=14.0.0 in /usr/local/lib/python3.12/dist-packages (from strands-agents-tools->-r requirements.txt (line 2)) (14.2.0)\n",
            "Requirement already satisfied: slack-bolt<2.0.0,>=1.23.0 in /usr/local/lib/python3.12/dist-packages (from strands-agents-tools->-r requirements.txt (line 2)) (1.27.0)\n",
            "Requirement already satisfied: sympy<2.0.0,>=1.12.0 in /usr/local/lib/python3.12/dist-packages (from strands-agents-tools->-r requirements.txt (line 2)) (1.14.0)\n",
            "Requirement already satisfied: tenacity<10.0.0,>=9.1.2 in /usr/local/lib/python3.12/dist-packages (from strands-agents-tools->-r requirements.txt (line 2)) (9.1.2)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.12/dist-packages (from perplexityai->-r requirements.txt (line 3)) (4.11.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.12/dist-packages (from perplexityai->-r requirements.txt (line 3)) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from perplexityai->-r requirements.txt (line 3)) (0.28.1)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.12/dist-packages (from perplexityai->-r requirements.txt (line 3)) (1.3.1)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.0->strands-agents-tools->-r requirements.txt (line 2)) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.0->strands-agents-tools->-r requirements.txt (line 2)) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.0->strands-agents-tools->-r requirements.txt (line 2)) (25.4.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.0->strands-agents-tools->-r requirements.txt (line 2)) (1.8.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.0->strands-agents-tools->-r requirements.txt (line 2)) (6.7.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.0->strands-agents-tools->-r requirements.txt (line 2)) (0.4.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.0->strands-agents-tools->-r requirements.txt (line 2)) (1.22.0)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.12/dist-packages (from anyio<5,>=3.5.0->perplexityai->-r requirements.txt (line 3)) (3.11)\n",
            "Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in /usr/local/lib/python3.12/dist-packages (from boto3<2.0.0,>=1.26.0->strands-agents->-r requirements.txt (line 1)) (1.0.1)\n",
            "Requirement already satisfied: s3transfer<0.16.0,>=0.15.0 in /usr/local/lib/python3.12/dist-packages (from boto3<2.0.0,>=1.26.0->strands-agents->-r requirements.txt (line 1)) (0.15.0)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.12/dist-packages (from botocore<2.0.0,>=1.29.0->strands-agents->-r requirements.txt (line 1)) (2.9.0.post0)\n",
            "Requirement already satisfied: urllib3!=2.2.0,<3,>=1.25.4 in /usr/local/lib/python3.12/dist-packages (from botocore<2.0.0,>=1.29.0->strands-agents->-r requirements.txt (line 1)) (2.5.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->perplexityai->-r requirements.txt (line 3)) (2025.11.12)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->perplexityai->-r requirements.txt (line 3)) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->perplexityai->-r requirements.txt (line 3)) (0.16.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.12/dist-packages (from jsonschema<5.0.0,>=4.0.0->strands-agents->-r requirements.txt (line 1)) (2025.9.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.12/dist-packages (from jsonschema<5.0.0,>=4.0.0->strands-agents->-r requirements.txt (line 1)) (0.37.0)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.12/dist-packages (from jsonschema<5.0.0,>=4.0.0->strands-agents->-r requirements.txt (line 1)) (0.29.0)\n",
            "Requirement already satisfied: beautifulsoup4<5,>=4.9 in /usr/local/lib/python3.12/dist-packages (from markdownify<2.0.0,>=1.0.0->strands-agents-tools->-r requirements.txt (line 2)) (4.13.5)\n",
            "Requirement already satisfied: six<2,>=1.15 in /usr/local/lib/python3.12/dist-packages (from markdownify<2.0.0,>=1.0.0->strands-agents-tools->-r requirements.txt (line 2)) (1.17.0)\n",
            "Requirement already satisfied: httpx-sse>=0.4 in /usr/local/lib/python3.12/dist-packages (from mcp<2.0.0,>=1.11.0->strands-agents->-r requirements.txt (line 1)) (0.4.3)\n",
            "Requirement already satisfied: pydantic-settings>=2.5.2 in /usr/local/lib/python3.12/dist-packages (from mcp<2.0.0,>=1.11.0->strands-agents->-r requirements.txt (line 1)) (2.12.0)\n",
            "Requirement already satisfied: python-multipart>=0.0.9 in /usr/local/lib/python3.12/dist-packages (from mcp<2.0.0,>=1.11.0->strands-agents->-r requirements.txt (line 1)) (0.0.20)\n",
            "Requirement already satisfied: sse-starlette>=1.6.1 in /usr/local/lib/python3.12/dist-packages (from mcp<2.0.0,>=1.11.0->strands-agents->-r requirements.txt (line 1)) (3.0.3)\n",
            "Requirement already satisfied: starlette>=0.27 in /usr/local/lib/python3.12/dist-packages (from mcp<2.0.0,>=1.11.0->strands-agents->-r requirements.txt (line 1)) (0.48.0)\n",
            "Requirement already satisfied: typing-inspection>=0.4.1 in /usr/local/lib/python3.12/dist-packages (from mcp<2.0.0,>=1.11.0->strands-agents->-r requirements.txt (line 1)) (0.4.2)\n",
            "Requirement already satisfied: uvicorn>=0.31.1 in /usr/local/lib/python3.12/dist-packages (from mcp<2.0.0,>=1.11.0->strands-agents->-r requirements.txt (line 1)) (0.38.0)\n",
            "Requirement already satisfied: importlib-metadata<8.8.0,>=6.0 in /usr/local/lib/python3.12/dist-packages (from opentelemetry-api<2.0.0,>=1.30.0->strands-agents->-r requirements.txt (line 1)) (8.7.0)\n",
            "Requirement already satisfied: opentelemetry-instrumentation==0.59b0 in /usr/local/lib/python3.12/dist-packages (from opentelemetry-instrumentation-threading<1.00b0,>=0.51b0->strands-agents->-r requirements.txt (line 1)) (0.59b0)\n",
            "Requirement already satisfied: wrapt<2.0.0,>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from opentelemetry-instrumentation-threading<1.00b0,>=0.51b0->strands-agents->-r requirements.txt (line 1)) (1.17.3)\n",
            "Requirement already satisfied: opentelemetry-semantic-conventions==0.59b0 in /usr/local/lib/python3.12/dist-packages (from opentelemetry-instrumentation==0.59b0->opentelemetry-instrumentation-threading<1.00b0,>=0.51b0->strands-agents->-r requirements.txt (line 1)) (0.59b0)\n",
            "Requirement already satisfied: packaging>=18.0 in /usr/local/lib/python3.12/dist-packages (from opentelemetry-instrumentation==0.59b0->opentelemetry-instrumentation-threading<1.00b0,>=0.51b0->strands-agents->-r requirements.txt (line 1)) (25.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.12/dist-packages (from prompt-toolkit<4.0.0,>=3.0.51->strands-agents-tools->-r requirements.txt (line 2)) (0.2.14)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.4.0->strands-agents->-r requirements.txt (line 1)) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.4.0->strands-agents->-r requirements.txt (line 1)) (2.33.2)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.28.0->strands-agents-tools->-r requirements.txt (line 2)) (3.4.4)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from rich<15.0.0,>=14.0.0->strands-agents-tools->-r requirements.txt (line 2)) (4.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.12/dist-packages (from rich<15.0.0,>=14.0.0->strands-agents-tools->-r requirements.txt (line 2)) (2.19.2)\n",
            "Requirement already satisfied: slack_sdk<4,>=3.38.0 in /usr/local/lib/python3.12/dist-packages (from slack-bolt<2.0.0,>=1.23.0->strands-agents-tools->-r requirements.txt (line 2)) (3.39.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy<2.0.0,>=1.12.0->strands-agents-tools->-r requirements.txt (line 2)) (1.3.0)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.12/dist-packages (from beautifulsoup4<5,>=4.9->markdownify<2.0.0,>=1.0.0->strands-agents-tools->-r requirements.txt (line 2)) (2.8)\n",
            "Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.12/dist-packages (from importlib-metadata<8.8.0,>=6.0->opentelemetry-api<2.0.0,>=1.30.0->strands-agents->-r requirements.txt (line 1)) (3.23.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.12/dist-packages (from markdown-it-py>=2.2.0->rich<15.0.0,>=14.0.0->strands-agents-tools->-r requirements.txt (line 2)) (0.1.2)\n",
            "Requirement already satisfied: python-dotenv>=0.21.0 in /usr/local/lib/python3.12/dist-packages (from pydantic-settings>=2.5.2->mcp<2.0.0,>=1.11.0->strands-agents->-r requirements.txt (line 1)) (1.2.1)\n",
            "Requirement already satisfied: cryptography>=3.4.0 in /usr/local/lib/python3.12/dist-packages (from pyjwt[crypto]>=2.10.1->mcp<2.0.0,>=1.11.0->strands-agents->-r requirements.txt (line 1)) (43.0.3)\n",
            "Requirement already satisfied: click>=7.0 in /usr/local/lib/python3.12/dist-packages (from uvicorn>=0.31.1->mcp<2.0.0,>=1.11.0->strands-agents->-r requirements.txt (line 1)) (8.3.1)\n",
            "Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.12/dist-packages (from cryptography>=3.4.0->pyjwt[crypto]>=2.10.1->mcp<2.0.0,>=1.11.0->strands-agents->-r requirements.txt (line 1)) (2.0.0)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.12/dist-packages (from cffi>=1.12->cryptography>=3.4.0->pyjwt[crypto]>=2.10.1->mcp<2.0.0,>=1.11.0->strands-agents->-r requirements.txt (line 1)) (2.23)\n"
          ]
        }
      ],
      "source": [
        "!pip install -r requirements.txt"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.environ[\"PERPLEXITY_API_KEY\"] = \"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\"\n"
      ],
      "metadata": {
        "id": "CGsRUVY5rlcB"
      },
      "id": "CGsRUVY5rlcB",
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from strands import Agent\n",
        "import importlib\n",
        "import perplexity_model\n",
        "importlib.reload(perplexity_model)\n",
        "from perplexity_model import PerplexityModel\n",
        "\n",
        "model = PerplexityModel(\n",
        "    api_key='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',\n",
        "    model_id='sonar-pro',\n",
        "    params={'max_tokens': 2048, 'temperature': 0.7}\n",
        ")\n",
        "\n",
        "agent = Agent(model=model)\n",
        "response = agent(\"who is the president of the united states\")\n",
        "print(response)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tcuiSLxWtuq6",
        "outputId": "a93aabec-55b6-4e0c-8c28-6935e366004e"
      },
      "id": "tcuiSLxWtuq6",
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The current president of the United States is **Donald J. Trump**, serving as the 47th president since January 20, 2025[6][7][8][4][3][5][2].\n",
            "\n",
            "Donald Trump won the 2024 presidential election and was inaugurated for a second, non-consecutive term, making him both the 45th and 47th president[2][4][6][7][8]. His vice president is JD Vance, and the First Lady is Melania Trump[5][2]. This return to office follows an extraordinary political comeback after losing his reelection bid in 2020 and then winning again in 2024[4].\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9a203754-ecd3-402d-be98-9ee8facc23d9",
      "metadata": {
        "id": "9a203754-ecd3-402d-be98-9ee8facc23d9"
      },
      "source": [
        "### Importing required packages\n",
        "\n",
        "Next we can import the required packages"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "680c68aa-36e9-48e7-a3ed-9d2e63a3b95c",
      "metadata": {
        "id": "680c68aa-36e9-48e7-a3ed-9d2e63a3b95c"
      },
      "outputs": [],
      "source": [
        "from strands import Agent\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cb3b24d8-69d5-496d-92a5-24ff8705de1c",
      "metadata": {
        "id": "cb3b24d8-69d5-496d-92a5-24ff8705de1c"
      },
      "source": [
        "## Understanding Agent Graph Components\n",
        "An agent graph is a structured network of interconnected AI agents designed to solve complex problems through coordinated collaboration. Each agent represents a specialized node with specific capabilities, and the connections between agents define explicit communication pathways.\n",
        "\n",
        "Before we start building, let's understand the three primary components of an agent graph:\n",
        "\n",
        "### 1. Nodes (Agents)\n",
        "Each node represents an AI agent with:\n",
        "- **Identity**: Unique identifier within the graph\n",
        "- **Role**: Specialized function or purpose\n",
        "- **System Prompt**: Instructions defining the agent's behavior\n",
        "- **Tools**: Capabilities available to the agent\n",
        "\n",
        "### 2. Edges (Connections)\n",
        "Edges define communication pathways with:\n",
        "- **Direction**: One-way or bidirectional information flow\n",
        "- **Condition**: Optional function that determines if the edge should be traversed\n",
        "- **Dependencies**: Define execution order and data flow between nodes\n",
        "\n",
        "### 3. GraphBuilder\n",
        "The GraphBuilder provides a simple interface for constructing graphs:\n",
        "- **add_node()**: Add an agent or multi-agent system as a node\n",
        "- **add_edge()**: Create a dependency between nodes\n",
        "- **set_entry_point()**: Define starting nodes for execution\n",
        "- **build()**: Validate and create the Graph instance\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "80c47290-ef84-4ab5-ad14-70d41f0ed40b",
      "metadata": {
        "id": "80c47290-ef84-4ab5-ad14-70d41f0ed40b"
      },
      "source": [
        "### Basic processing\n",
        "\n",
        "Let's start with a simple example of one task processed by two different agents providing an output that will depend on their defined role. Take a look at the execution order of the nodes and also the fact that with STrands SDK you can explicitly get a response only from one single node if needed. Architecture looks as following:\n",
        "\n",
        "<div style=\"text-align:left\">\n",
        "    <img src=\"https://github.com/strands-agents/samples/blob/main/01-tutorials/02-multi-agent-systems/03-graph-agent/images/basic.png?raw=1\" width=\"55%\" />\n",
        "</div>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 88,
      "id": "eba5fc53-8eca-46e8-84cf-9ca0f551140d",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eba5fc53-8eca-46e8-84cf-9ca0f551140d",
        "outputId": "5ae7fa88-342d-4690-d13d-a793bcff3149"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:strands.multiagent.graph:Graph without execution limits may run indefinitely if cycles exist\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Remote work has generally led to **stable or increased employee productivity**, with multiple large-scale studies reporting measurable gains compared to traditional office settings[1][3][5][6][7]. However, the impact varies depending on individual circumstances, job types, and how challenges associated with remote work are managed[2][3][10].\n",
            "\n",
            "Key points:\n",
            "\n",
            "- **Increased Productivity**: Multiple studies—including a two-year study of 800,000 employees and research by Stanford—found remote workers are up to 47% more productive, with some reporting a 13% increase in performance[1][3][6]. Factors include fewer distractions, reduced commute times, and the ability to work during peak productivity hours[1][2][3][5][6].\n",
            "  \n",
            "- **Improved Engagement and Satisfaction**: Remote work is associated with higher engagement and job satisfaction, which can reduce turnover and hiring costs for organizations[3][5][6][7].\n",
            "  \n",
            "- **Potential Drawbacks**: Challenges such as **isolation, communication barriers, and blurred work-life boundaries** can negatively affect productivity if not addressed[2][5][7][10]. Some studies note that fully remote work can sometimes lead to lower well-being despite higher engagement[5].\n",
            "\n",
            "- **Variability by Context**: The productivity impact of remote work depends on task type, technology availability, home environment, and management practices[3][10][11]. For most knowledge-based roles, the benefits are more pronounced.\n",
            "\n",
            "- **Sustainability**: Evidence suggests that sustained or improved productivity is possible when remote work transitions are well-planned and supported, rather than abrupt[7].\n",
            "\n",
            "Overall, **remote work tends to enhance productivity when employees are given autonomy, flexibility, and the right technological and social support**, but organizations need to address the associated risks to maximize long-term benefits[2][5][7][10].Remote work has generally had a **neutral to positive impact on employee productivity**, with many studies reporting stable or increased output, though the effects vary across roles, industries, and individual circumstances[1][2][3][5][7][8].\n",
            "\n",
            "Key findings:\n",
            "- **Productivity Stability or Increase:** Multiple large-scale studies and firm-level experiments show that productivity remained steady or improved after the shift to remote work, especially among knowledge workers[1][3][5][7]. For example, a Gallup analysis found output per worker slightly increased post-pandemic, even as remote employees worked fewer hours[1].\n",
            "- **Efficiency Gains:** Remote work eliminates commuting and allows employees to work during their most productive hours, which can boost efficiency and job satisfaction[2][7][12]. Some sources report remote employees are 35–40% more productive and make 40% fewer mistakes than office-based peers[7].\n",
            "- **Job Satisfaction and Retention:** Increased autonomy in remote setups has led to higher engagement and lower turnover, reducing hiring costs for firms[3][5].\n",
            "- **Challenges:** Productivity gains are not universal. Some studies found declines, particularly where remote work was poorly managed, or in roles needing close coordination or mentoring[4][6][9]. Common obstacles include isolation, communication barriers, and home distractions[2][4][8].\n",
            "- **Well-being Risks:** Despite higher engagement, fully remote workers often report greater stress and loneliness, which may threaten long-term performance if not addressed[5]. \n",
            "\n",
            "In summary, **remote work can support or enhance productivity when organizations implement clear goals, strong communication practices, and address well-being**. The impact is most positive for autonomous, knowledge-based roles, and where employees have supportive home environments and reliable technology[2][3][5][6][7].Remote work has generally led to a modest increase in employee productivity, especially for roles that benefit from autonomy and flexibility, although results vary depending on job type, individual circumstances, and management practices[1][2][3][4][7].\n",
            "\n",
            "Key factors contributing to **increased productivity** include:\n",
            "- **Reduced commuting time**, allowing employees to allocate more time and energy to work tasks[2][7].\n",
            "- **Fewer workplace distractions** for many roles, particularly knowledge workers, enabling better focus and output[4][6].\n",
            "- **Flexible scheduling**, which lets employees align work hours with their personal peak productivity periods[4][8].\n",
            "- **Higher engagement** and willingness to put in extra effort, particularly in high-trust organizations and among fully remote workers[3][7].\n",
            "\n",
            "However, there are notable **challenges and negative impacts**:\n",
            "- **Isolation and reduced social interaction** can decrease motivation and well-being, increasing risks of loneliness and stress, even as engagement rises[2][3][4][5].\n",
            "- **Home distractions** (family, chores) and **difficulty separating work from personal life** can reduce productivity for some employees[2][4].\n",
            "- **Communication barriers** and reduced mentoring opportunities can hinder collaboration, especially for teams that rely on frequent, spontaneous interaction[2][11].\n",
            "- **Variability across roles**: Individual contributors often report productivity gains, while managers and those in roles needing close coordination may face declines[4][6].\n",
            "\n",
            "On an organizational level, increased remote work was associated with higher industry-level productivity growth during the pandemic, as well as lower turnover and improved job satisfaction, which can reduce hiring costs[1][13]. Productivity gains are highest when organizations invest in effective digital collaboration tools, foster clear communication, and support employee well-being[4][10].\n",
            "\n",
            "In summary, **remote work tends to improve productivity for many employees**, particularly when supported by strong management and digital infrastructure, but outcomes are highly dependent on both individual and organizational factors[1][2][3][4][7][11].\n",
            "\n",
            "============================================================\n",
            "============================================================\n",
            "Response: GraphResult(status=<Status.COMPLETED: 'completed'>, results={'team_lead': NodeResult(result=AgentResult(stop_reason='end_turn', message={'role': 'assistant', 'content': []}, metrics=EventLoopMetrics(cycle_count=1, tool_metrics={}, cycle_durations=[12.1866614818573], traces=[<strands.telemetry.metrics.Trace object at 0x7fa5a1b990a0>], accumulated_usage={'inputTokens': 0, 'outputTokens': 0, 'totalTokens': 0}, accumulated_metrics={'latencyMs': 0}), state={}, interrupts=None, structured_output=None), execution_time=12187, status=<Status.COMPLETED: 'completed'>, accumulated_usage={'inputTokens': 0, 'outputTokens': 0, 'totalTokens': 0}, accumulated_metrics={'latencyMs': 0}, execution_count=1), 'analyst': NodeResult(result=AgentResult(stop_reason='end_turn', message={'role': 'assistant', 'content': []}, metrics=EventLoopMetrics(cycle_count=1, tool_metrics={}, cycle_durations=[11.795153141021729], traces=[<strands.telemetry.metrics.Trace object at 0x7fa5a1b9aa50>], accumulated_usage={'inputTokens': 0, 'outputTokens': 0, 'totalTokens': 0}, accumulated_metrics={'latencyMs': 0}), state={}, interrupts=None, structured_output=None), execution_time=11796, status=<Status.COMPLETED: 'completed'>, accumulated_usage={'inputTokens': 0, 'outputTokens': 0, 'totalTokens': 0}, accumulated_metrics={'latencyMs': 0}, execution_count=1), 'expert': NodeResult(result=AgentResult(stop_reason='end_turn', message={'role': 'assistant', 'content': []}, metrics=EventLoopMetrics(cycle_count=1, tool_metrics={}, cycle_durations=[12.11189866065979], traces=[<strands.telemetry.metrics.Trace object at 0x7fa5a1b9a690>], accumulated_usage={'inputTokens': 0, 'outputTokens': 0, 'totalTokens': 0}, accumulated_metrics={'latencyMs': 0}), state={}, interrupts=None, structured_output=None), execution_time=12112, status=<Status.COMPLETED: 'completed'>, accumulated_usage={'inputTokens': 0, 'outputTokens': 0, 'totalTokens': 0}, accumulated_metrics={'latencyMs': 0}, execution_count=1)}, accumulated_usage={'inputTokens': 0, 'outputTokens': 0, 'totalTokens': 0}, accumulated_metrics={'latencyMs': 0}, execution_count=3, execution_time=0, total_nodes=3, completed_nodes=3, failed_nodes=0, execution_order=[GraphNode(node_id='team_lead', executor=<strands.agent.agent.Agent object at 0x7fa5b2bb07d0>, dependencies=set(), execution_status=<Status.COMPLETED: 'completed'>, result=NodeResult(result=AgentResult(stop_reason='end_turn', message={'role': 'assistant', 'content': []}, metrics=EventLoopMetrics(cycle_count=1, tool_metrics={}, cycle_durations=[12.1866614818573], traces=[<strands.telemetry.metrics.Trace object at 0x7fa5a1b990a0>], accumulated_usage={'inputTokens': 0, 'outputTokens': 0, 'totalTokens': 0}, accumulated_metrics={'latencyMs': 0}), state={}, interrupts=None, structured_output=None), execution_time=12187, status=<Status.COMPLETED: 'completed'>, accumulated_usage={'inputTokens': 0, 'outputTokens': 0, 'totalTokens': 0}, accumulated_metrics={'latencyMs': 0}, execution_count=1), execution_time=12187, _initial_messages=[], _initial_state=<strands.agent.state.AgentState object at 0x7fa5a1b99c70>), GraphNode(node_id='analyst', executor=<strands.agent.agent.Agent object at 0x7fa5b0a3bc80>, dependencies={GraphNode(node_id='team_lead', executor=<strands.agent.agent.Agent object at 0x7fa5b2bb07d0>, dependencies=set(), execution_status=<Status.COMPLETED: 'completed'>, result=NodeResult(result=AgentResult(stop_reason='end_turn', message={'role': 'assistant', 'content': []}, metrics=EventLoopMetrics(cycle_count=1, tool_metrics={}, cycle_durations=[12.1866614818573], traces=[<strands.telemetry.metrics.Trace object at 0x7fa5a1b990a0>], accumulated_usage={'inputTokens': 0, 'outputTokens': 0, 'totalTokens': 0}, accumulated_metrics={'latencyMs': 0}), state={}, interrupts=None, structured_output=None), execution_time=12187, status=<Status.COMPLETED: 'completed'>, accumulated_usage={'inputTokens': 0, 'outputTokens': 0, 'totalTokens': 0}, accumulated_metrics={'latencyMs': 0}, execution_count=1), execution_time=12187, _initial_messages=[], _initial_state=<strands.agent.state.AgentState object at 0x7fa5a1b99c70>)}, execution_status=<Status.COMPLETED: 'completed'>, result=NodeResult(result=AgentResult(stop_reason='end_turn', message={'role': 'assistant', 'content': []}, metrics=EventLoopMetrics(cycle_count=1, tool_metrics={}, cycle_durations=[11.795153141021729], traces=[<strands.telemetry.metrics.Trace object at 0x7fa5a1b9aa50>], accumulated_usage={'inputTokens': 0, 'outputTokens': 0, 'totalTokens': 0}, accumulated_metrics={'latencyMs': 0}), state={}, interrupts=None, structured_output=None), execution_time=11796, status=<Status.COMPLETED: 'completed'>, accumulated_usage={'inputTokens': 0, 'outputTokens': 0, 'totalTokens': 0}, accumulated_metrics={'latencyMs': 0}, execution_count=1), execution_time=11796, _initial_messages=[], _initial_state=<strands.agent.state.AgentState object at 0x7fa5a1b9bc50>), GraphNode(node_id='expert', executor=<strands.agent.agent.Agent object at 0x7fa5a24d5160>, dependencies={GraphNode(node_id='team_lead', executor=<strands.agent.agent.Agent object at 0x7fa5b2bb07d0>, dependencies=set(), execution_status=<Status.COMPLETED: 'completed'>, result=NodeResult(result=AgentResult(stop_reason='end_turn', message={'role': 'assistant', 'content': []}, metrics=EventLoopMetrics(cycle_count=1, tool_metrics={}, cycle_durations=[12.1866614818573], traces=[<strands.telemetry.metrics.Trace object at 0x7fa5a1b990a0>], accumulated_usage={'inputTokens': 0, 'outputTokens': 0, 'totalTokens': 0}, accumulated_metrics={'latencyMs': 0}), state={}, interrupts=None, structured_output=None), execution_time=12187, status=<Status.COMPLETED: 'completed'>, accumulated_usage={'inputTokens': 0, 'outputTokens': 0, 'totalTokens': 0}, accumulated_metrics={'latencyMs': 0}, execution_count=1), execution_time=12187, _initial_messages=[], _initial_state=<strands.agent.state.AgentState object at 0x7fa5a1b99c70>)}, execution_status=<Status.COMPLETED: 'completed'>, result=NodeResult(result=AgentResult(stop_reason='end_turn', message={'role': 'assistant', 'content': []}, metrics=EventLoopMetrics(cycle_count=1, tool_metrics={}, cycle_durations=[12.11189866065979], traces=[<strands.telemetry.metrics.Trace object at 0x7fa5a1b9a690>], accumulated_usage={'inputTokens': 0, 'outputTokens': 0, 'totalTokens': 0}, accumulated_metrics={'latencyMs': 0}), state={}, interrupts=None, structured_output=None), execution_time=12112, status=<Status.COMPLETED: 'completed'>, accumulated_usage={'inputTokens': 0, 'outputTokens': 0, 'totalTokens': 0}, accumulated_metrics={'latencyMs': 0}, execution_count=1), execution_time=12112, _initial_messages=[], _initial_state=<strands.agent.state.AgentState object at 0x7fa5a1b9a090>)], edges=[(GraphNode(node_id='team_lead', executor=<strands.agent.agent.Agent object at 0x7fa5b2bb07d0>, dependencies=set(), execution_status=<Status.COMPLETED: 'completed'>, result=NodeResult(result=AgentResult(stop_reason='end_turn', message={'role': 'assistant', 'content': []}, metrics=EventLoopMetrics(cycle_count=1, tool_metrics={}, cycle_durations=[12.1866614818573], traces=[<strands.telemetry.metrics.Trace object at 0x7fa5a1b990a0>], accumulated_usage={'inputTokens': 0, 'outputTokens': 0, 'totalTokens': 0}, accumulated_metrics={'latencyMs': 0}), state={}, interrupts=None, structured_output=None), execution_time=12187, status=<Status.COMPLETED: 'completed'>, accumulated_usage={'inputTokens': 0, 'outputTokens': 0, 'totalTokens': 0}, accumulated_metrics={'latencyMs': 0}, execution_count=1), execution_time=12187, _initial_messages=[], _initial_state=<strands.agent.state.AgentState object at 0x7fa5a1b99c70>), GraphNode(node_id='analyst', executor=<strands.agent.agent.Agent object at 0x7fa5b0a3bc80>, dependencies={GraphNode(node_id='team_lead', executor=<strands.agent.agent.Agent object at 0x7fa5b2bb07d0>, dependencies=set(), execution_status=<Status.COMPLETED: 'completed'>, result=NodeResult(result=AgentResult(stop_reason='end_turn', message={'role': 'assistant', 'content': []}, metrics=EventLoopMetrics(cycle_count=1, tool_metrics={}, cycle_durations=[12.1866614818573], traces=[<strands.telemetry.metrics.Trace object at 0x7fa5a1b990a0>], accumulated_usage={'inputTokens': 0, 'outputTokens': 0, 'totalTokens': 0}, accumulated_metrics={'latencyMs': 0}), state={}, interrupts=None, structured_output=None), execution_time=12187, status=<Status.COMPLETED: 'completed'>, accumulated_usage={'inputTokens': 0, 'outputTokens': 0, 'totalTokens': 0}, accumulated_metrics={'latencyMs': 0}, execution_count=1), execution_time=12187, _initial_messages=[], _initial_state=<strands.agent.state.AgentState object at 0x7fa5a1b99c70>)}, execution_status=<Status.COMPLETED: 'completed'>, result=NodeResult(result=AgentResult(stop_reason='end_turn', message={'role': 'assistant', 'content': []}, metrics=EventLoopMetrics(cycle_count=1, tool_metrics={}, cycle_durations=[11.795153141021729], traces=[<strands.telemetry.metrics.Trace object at 0x7fa5a1b9aa50>], accumulated_usage={'inputTokens': 0, 'outputTokens': 0, 'totalTokens': 0}, accumulated_metrics={'latencyMs': 0}), state={}, interrupts=None, structured_output=None), execution_time=11796, status=<Status.COMPLETED: 'completed'>, accumulated_usage={'inputTokens': 0, 'outputTokens': 0, 'totalTokens': 0}, accumulated_metrics={'latencyMs': 0}, execution_count=1), execution_time=11796, _initial_messages=[], _initial_state=<strands.agent.state.AgentState object at 0x7fa5a1b9bc50>)), (GraphNode(node_id='team_lead', executor=<strands.agent.agent.Agent object at 0x7fa5b2bb07d0>, dependencies=set(), execution_status=<Status.COMPLETED: 'completed'>, result=NodeResult(result=AgentResult(stop_reason='end_turn', message={'role': 'assistant', 'content': []}, metrics=EventLoopMetrics(cycle_count=1, tool_metrics={}, cycle_durations=[12.1866614818573], traces=[<strands.telemetry.metrics.Trace object at 0x7fa5a1b990a0>], accumulated_usage={'inputTokens': 0, 'outputTokens': 0, 'totalTokens': 0}, accumulated_metrics={'latencyMs': 0}), state={}, interrupts=None, structured_output=None), execution_time=12187, status=<Status.COMPLETED: 'completed'>, accumulated_usage={'inputTokens': 0, 'outputTokens': 0, 'totalTokens': 0}, accumulated_metrics={'latencyMs': 0}, execution_count=1), execution_time=12187, _initial_messages=[], _initial_state=<strands.agent.state.AgentState object at 0x7fa5a1b99c70>), GraphNode(node_id='expert', executor=<strands.agent.agent.Agent object at 0x7fa5a24d5160>, dependencies={GraphNode(node_id='team_lead', executor=<strands.agent.agent.Agent object at 0x7fa5b2bb07d0>, dependencies=set(), execution_status=<Status.COMPLETED: 'completed'>, result=NodeResult(result=AgentResult(stop_reason='end_turn', message={'role': 'assistant', 'content': []}, metrics=EventLoopMetrics(cycle_count=1, tool_metrics={}, cycle_durations=[12.1866614818573], traces=[<strands.telemetry.metrics.Trace object at 0x7fa5a1b990a0>], accumulated_usage={'inputTokens': 0, 'outputTokens': 0, 'totalTokens': 0}, accumulated_metrics={'latencyMs': 0}), state={}, interrupts=None, structured_output=None), execution_time=12187, status=<Status.COMPLETED: 'completed'>, accumulated_usage={'inputTokens': 0, 'outputTokens': 0, 'totalTokens': 0}, accumulated_metrics={'latencyMs': 0}, execution_count=1), execution_time=12187, _initial_messages=[], _initial_state=<strands.agent.state.AgentState object at 0x7fa5a1b99c70>)}, execution_status=<Status.COMPLETED: 'completed'>, result=NodeResult(result=AgentResult(stop_reason='end_turn', message={'role': 'assistant', 'content': []}, metrics=EventLoopMetrics(cycle_count=1, tool_metrics={}, cycle_durations=[12.11189866065979], traces=[<strands.telemetry.metrics.Trace object at 0x7fa5a1b9a690>], accumulated_usage={'inputTokens': 0, 'outputTokens': 0, 'totalTokens': 0}, accumulated_metrics={'latencyMs': 0}), state={}, interrupts=None, structured_output=None), execution_time=12112, status=<Status.COMPLETED: 'completed'>, accumulated_usage={'inputTokens': 0, 'outputTokens': 0, 'totalTokens': 0}, accumulated_metrics={'latencyMs': 0}, execution_count=1), execution_time=12112, _initial_messages=[], _initial_state=<strands.agent.state.AgentState object at 0x7fa5a1b9a090>))], entry_points=[GraphNode(node_id='team_lead', executor=<strands.agent.agent.Agent object at 0x7fa5b2bb07d0>, dependencies=set(), execution_status=<Status.COMPLETED: 'completed'>, result=NodeResult(result=AgentResult(stop_reason='end_turn', message={'role': 'assistant', 'content': []}, metrics=EventLoopMetrics(cycle_count=1, tool_metrics={}, cycle_durations=[12.1866614818573], traces=[<strands.telemetry.metrics.Trace object at 0x7fa5a1b990a0>], accumulated_usage={'inputTokens': 0, 'outputTokens': 0, 'totalTokens': 0}, accumulated_metrics={'latencyMs': 0}), state={}, interrupts=None, structured_output=None), execution_time=12187, status=<Status.COMPLETED: 'completed'>, accumulated_usage={'inputTokens': 0, 'outputTokens': 0, 'totalTokens': 0}, accumulated_metrics={'latencyMs': 0}, execution_count=1), execution_time=12187, _initial_messages=[], _initial_state=<strands.agent.state.AgentState object at 0x7fa5a1b99c70>)])\n",
            "=============Node execution order:==========================\n",
            "============================================================\n",
            "Executed: team_lead\n",
            "Executed: analyst\n",
            "Executed: expert\n",
            "=============Graph metrics:=================================\n",
            "============================================================\n",
            "Total nodes: 3\n",
            "Completed nodes: 3\n",
            "Failed nodes: 0\n",
            "Execution time: 0ms\n",
            "Token usage: {'inputTokens': 0, 'outputTokens': 0, 'totalTokens': 0}\n",
            "\n",
            "\n",
            "=============Expert node results only:======================\n",
            "============================================================\n",
            "\n"
          ]
        }
      ],
      "source": [
        "#Initialize an agent with agent_graph capability\n",
        "from strands.multiagent import GraphBuilder\n",
        "\n",
        "# Create specialized agents\n",
        "coordinator = Agent(model=model, name=\"coordinator\", system_prompt=\"You are a research team leader coordinating specialists. Provide a short analysis, no need for follow ups\")\n",
        "analyst = Agent(model=model, name=\"data_analyst\", system_prompt=\"You are a data analyst specializing in statistical analysis. Provide a short analysis, no need for follow ups\")\n",
        "domain_expert = Agent(model=model,name=\"domain_expert\", system_prompt=\"You are a domain expert with deep subject knowledge. Provide a short analysis, no need for follow ups\")\n",
        "\n",
        "# Build the graph\n",
        "builder = GraphBuilder()\n",
        "\n",
        "# Add nodes\n",
        "builder.add_node(coordinator, \"team_lead\")\n",
        "builder.add_node(analyst, \"analyst\")\n",
        "builder.add_node(domain_expert, \"expert\")\n",
        "\n",
        "# Add edges (dependencies)\n",
        "builder.add_edge(\"team_lead\", \"analyst\")\n",
        "builder.add_edge(\"team_lead\", \"expert\")\n",
        "\n",
        "# Set entry points (optional - will be auto-detected if not specified)\n",
        "builder.set_entry_point(\"team_lead\")\n",
        "\n",
        "# Build the graph\n",
        "graph = builder.build()\n",
        "\n",
        "#Execute task on newly built graph\n",
        "result = graph(\"Analyze the impact of remote work on employee productivity.Provide a short analysis, no need for follow ups\")\n",
        "print(\"\\n\")\n",
        "print(\"============================================================\")\n",
        "print(\"============================================================\")\n",
        "\n",
        "print(f\"Response: {result}\")\n",
        "\n",
        "print(\"=============Node execution order:==========================\")\n",
        "print(\"============================================================\")\n",
        "\n",
        "# See which nodes were executed and in what order\n",
        "for node in result.execution_order:\n",
        "    print(f\"Executed: {node.node_id}\")\n",
        "\n",
        "print(\"=============Graph metrics:=================================\")\n",
        "print(\"============================================================\")\n",
        "\n",
        "\n",
        "# Get performance metrics\n",
        "print(f\"Total nodes: {result.total_nodes}\")\n",
        "print(f\"Completed nodes: {result.completed_nodes}\")\n",
        "print(f\"Failed nodes: {result.failed_nodes}\")\n",
        "print(f\"Execution time: {result.execution_time}ms\")\n",
        "print(f\"Token usage: {result.accumulated_usage}\")\n",
        "\n",
        "\n",
        "# Get results from specific nodes\n",
        "print(\"\\n\")\n",
        "print(\"=============Expert node results only:======================\")\n",
        "print(\"============================================================\")\n",
        "print(result.results[\"expert\"].result)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "de57dc8d-d748-4dc4-8380-ed789ba84d6b",
      "metadata": {
        "id": "de57dc8d-d748-4dc4-8380-ed789ba84d6b"
      },
      "source": [
        "### Parallel processing\n",
        "\n",
        "Now let's create a topology when we will have 2 agents processing the request looking at 2 different aspect  of the problem and have them input into a final agent responsible for summarization and risk calculation based on provided input\n",
        "<div style=\"text-align:left\">\n",
        "    <img src=\"https://github.com/strands-agents/samples/blob/main/01-tutorials/02-multi-agent-systems/03-graph-agent/images/parallel.png?raw=1\" width=\"55%\" />\n",
        "</div>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 86,
      "id": "7926cfeb-90c1-48cb-8d61-850ade47aebf",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7926cfeb-90c1-48cb-8d61-850ade47aebf",
        "outputId": "9ecf142e-5101-47b5-b031-5098620e0c0a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<>:39: SyntaxWarning: invalid escape sequence '\\$'\n",
            "<>:39: SyntaxWarning: invalid escape sequence '\\$'\n",
            "/tmp/ipython-input-489448519.py:39: SyntaxWarning: invalid escape sequence '\\$'\n",
            "  result = graph(\"Our company is considering launching a new AI-powered customer service platform. Initial investment is \\$2M with projected 3-year ROI of 150%. What's your financial assessment?\")\n",
            "WARNING:strands.multiagent.graph:Graph without execution limits may run indefinitely if cycles exist\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================================================\n",
            "============================================================\n",
            "Based on a projected **3-year ROI of 150%** on a **$2 million initial investment**, your company could expect a **net gain of $3 million** over three years, resulting in a total return of $5 million (\\$2M initial + \\$3M net gain)[2][5]. This is considered a **strong ROI for AI-powered customer service platforms** and aligns with or slightly exceeds industry benchmarks[2][4].\n",
            "\n",
            "**Key financial considerations:**\n",
            "\n",
            "- **ROI Calculation:**  \n",
            "  ROI = \\(\\frac{\\text{Net Gain}}{\\text{Initial Investment}} \\times 100\\)  \n",
            "  Here, Net Gain = \\$3M, Initial Investment = \\$2M, so ROI = (\\$3M / \\$2M) × 100 = 150%[2].\n",
            "\n",
            "- **Industry Benchmarks:**  \n",
            "  Typical 3-year ROI figures for AI customer service range from **148% to over 200%**, with some studies reporting average ROIs of **300–500%** for well-implemented solutions[2][4]. Your projected ROI is robust and competitive.\n",
            "\n",
            "- **Break-even and Payback:**  \n",
            "  With a 150% ROI over three years, your investment is projected to break even before the three-year mark, after which all gains contribute directly to profit[2].\n",
            "\n",
            "- **Cost Savings:**  \n",
            "  Major contributors to ROI include **labor cost reduction**, **faster resolution times**, and **increased customer retention** due to improved service[1][3][5].\n",
            "\n",
            "- **Risk and Sensitivity:**  \n",
            "  ROI projections depend on assumptions about adoption rates, actual operational savings, maintenance costs, and customer satisfaction improvements. It is recommended to **run sensitivity analyses** to test ROI under various scenarios and ensure robustness[2][6].\n",
            "\n",
            "- **Strategic Value:**  \n",
            "  Beyond quantified returns, benefits such as **scalability**, **improved customer experience**, and **process insights** can further enhance long-term value, though these may be harder to monetize directly[1][9].\n",
            "\n",
            "**Recommendation:**  \n",
            "The financial outlook is favorable if your assumptions hold. Ensure detailed tracking of **all cost components** (implementation, training, maintenance) and **quantify both direct and indirect benefits** (cost savings, revenue uplift, retention). Collaborate with your finance team to validate assumptions and conduct sensitivity and break-even analyses for a comprehensive risk assessment[6][12].\n",
            "\n",
            "If your business context supports the projected ROI, this investment appears justifiable and potentially strategic for long-term growth.The projected 3-year ROI of **150%** on a **\\$2M investment** in an AI-powered customer service platform is strong, significantly exceeding industry benchmarks, and signals a financially attractive opportunity assuming the projections are credible and risks are managed.\n",
            "\n",
            "Key financial assessment:\n",
            "\n",
            "- **ROI Calculation**: The standard ROI formula is:\n",
            "  \\[  \\text{ROI} = \\frac{\\text{Net Gain}}{\\text{Investment}} \\times 100\\%\n",
            "  \\]\n",
            "  For your case:\n",
            "  - Net Gain over 3 years = \\$2M × 1.5 = \\$3M\n",
            "  - Total Return after 3 years = Initial \\$2M + \\$3M gain = \\$5M\n",
            "  - ROI = (\\$5M - \\$2M) / \\$2M × 100% = 150%[3].\n",
            "\n",
            "- **Industry Benchmarks**: Recent studies and industry calculators indicate that average returns on AI-powered customer service projects range from **$3.50 up to $8.00** for every $1 invested, with some reporting ROIs of **60–2,100%** depending on specific use cases, scale, and efficiency improvements[3][4].\n",
            "    - A 150% ROI over 3 years (or 50% annualized, if returns are even) sits at the upper-middle range for serious enterprise deployments, suggesting the projections are ambitious but within plausible bounds for a well-executed rollout[3][4].\n",
            "\n",
            "- **Financial Drivers**: High ROI in AI customer service typically comes from:\n",
            "  - **Reduction in labor costs**: AI handles routine queries, reducing need for human agents.\n",
            "  - **Cost per interaction** drops significantly, with reported contact center cost reductions up to 60% in some cases[3][4].\n",
            "  - **Customer retention and satisfaction** often improve, boosting long-term revenue and customer lifetime value[4].\n",
            "  - **Operational efficiencies**: AI increases resolution speed and reduces escalation rates[4].\n",
            "  - **Scalability**: AI enables support to scale with minimal incremental cost[5].\n",
            "\n",
            "- **Caveats & Risks**:\n",
            "  - **Upfront and ongoing costs**: Ensure all costs (integration, licensing, training, maintenance) are included in the ROI calculation[1][3].\n",
            "  - **Adoption curve and change management**: Efficiency gains are highest with strong adoption and process alignment[2].\n",
            "  - **Variability**: Model potential downside scenarios (e.g., underperformance, integration delays, or lower adoption), as actual results often vary from projections[2].\n",
            "  - **Non-financial benefits**: Intangible gains, such as improved data for analytics or increased brand loyalty, may not be fully captured in ROI but are strategically valuable[1][2].\n",
            "\n",
            "- **Recommendations**:\n",
            "  - Validate the ROI assumptions using detailed modeling, including conservative, base, and optimistic scenarios[2].\n",
            "  - Track key KPIs post-launch: cost per interaction, agent productivity, CSAT, and customer retention[4][5].\n",
            "  - Use ROI calculators and scenario analysis tools to refine projections as real data emerges[6][7][9].\n",
            "\n",
            "A projected 150% ROI on a \\$2M AI customer service investment is robust, but your financial assessment should include scenario analysis and risk evaluation to ensure projections are realistic and achievable[2][3][4].The projected **3-year ROI of 150%** on an initial **$2M investment** in your AI-powered customer service platform indicates a strong financial case, with an expected return of $3M (your $2M principal plus $3M profit, totaling $5M) over three years[3][4][6]. This level of ROI is competitive and aligns with common industry benchmarks for successful AI customer service deployments.\n",
            "\n",
            "**Key financial assessment points:**\n",
            "\n",
            "- **ROI Calculation:** ROI is typically calculated as \\((\\text{Total Return} - \\text{Investment}) / \\text{Investment} \\times 100\\)[3]. Here: \\((5M - 2M) / 2M \\times 100 = 150\\%\\).\n",
            "- **Payback Period:** With a 150% ROI over three years, your payback period will be less than the full term. Specifically, you'll recover your initial capital and additional profit within three years, which is considered attractive for enterprise technology investments[3][6].\n",
            "- **Industry Benchmarks:** Case studies and models show annualized ROIs ranging from 100% to over 1000% for best-in-class AI customer service deployments, though these high numbers often reflect aggressive automation, cost savings, and rapid scaling[6]. A 150% ROI over three years is realistic and prudent, indicating a balanced, achievable target[3][4].\n",
            "- **Benefits Realized:** Most ROI in AI customer service comes from:\n",
            "  - Reduced operational costs (fewer agents needed, faster resolution)[5].\n",
            "  - Improved customer satisfaction and retention (higher lifetime value)[5].\n",
            "  - Increased automation and ticket deflection (lower cost per ticket)[6][9].\n",
            "\n",
            "**Other critical considerations:**\n",
            "\n",
            "- **Comprehensive Costing:** Ensure your model includes all relevant costs: software, integration, training, ongoing support, and change management[2][4].\n",
            "- **Scenario Analysis:** Test your ROI model against best-case, expected, and worst-case scenarios to understand possible variability in returns, especially given the evolving nature of AI technologies[2].\n",
            "- **Strategic Fit:** Evaluate qualitative benefits such as improved customer experience, competitive differentiation, and scalability, which can drive value beyond direct financial returns[2][4][5].\n",
            "\n",
            "**Summary:**  \n",
            "A 150% ROI over three years on a $2M investment is financially favorable and compares well to industry benchmarks for AI-powered customer service platforms. Ensure that your projections are conservative, include all costs, and validate through scenario analysis and ongoing measurement to maximize your likelihood of success[3][4][6].Based on an initial investment of **$2 million** and a projected 3-year ROI of **150%**, the financial outlook for launching an AI-powered customer service platform is highly attractive, assuming projections are realistic and risks are managed.\n",
            "\n",
            "**Key Financial Assessment:**\n",
            "\n",
            "- **ROI Calculation:**  \n",
            "  ROI is calculated as \\(\\text{ROI} = \\frac{\\text{Net Gain}}{\\text{Investment}} \\times 100\\).  \n",
            "  A 150% ROI on $2 million over 3 years means your expected net gain is $3 million (i.e., $2M initial investment returns a total of $5M after 3 years: $2M original + $3M profit)[5][3].\n",
            "\n",
            "- **Annualized Return:**  \n",
            "  Over 3 years, this translates to an annualized return of approximately 35% per year, which is strong for enterprise technology investments.\n",
            "\n",
            "- **Industry Benchmarks:**  \n",
            "  Customer service AI is producing some of the highest ROI figures in enterprise tech, with:\n",
            "  - Productivity gains (e.g., up to 52% reduction in case handling time, significant call deflection, and cost savings)[6][1].\n",
            "  - Some top performers report up to **8× ROI** in mature deployments[8].\n",
            "\n",
            "- **Key Value Drivers:**\n",
            "  - **Cost Reductions:** Automation reduces labor and training costs, cuts overtime, and increases agent productivity[1][6][3].\n",
            "  - **Revenue Increases:** Enhanced customer satisfaction and retention can drive repeat business and referrals[1][3].\n",
            "  - **Scalability:** AI enables 24/7 support without proportional increases in staffing or geographic constraints[6].\n",
            "  - **Strategic Value:** Intangible benefits include improved brand reputation, increased competitiveness, and better decision-making from AI analytics[3][7].\n",
            "\n",
            "**Considerations & Risks:**\n",
            "\n",
            "- **Assumptions Validation:** Ensure that projected savings, customer retention gains, and revenue uplifts are based on realistic operational data and market benchmarks[2][4].\n",
            "- **Cost Components:** Besides the $2M upfront, account for ongoing maintenance, upgrades, integration, and training costs, which can affect net returns[3][5][4].\n",
            "- **Qualitative Benefits:** Intangible gains (brand, loyalty, insights) should be considered, but rely primarily on measurable financial outcomes for investment justification[3][7].\n",
            "- **Scenario Analysis:** Use scenario planning to stress-test projections under varying adoption rates, market dynamics, and AI performance variability[2].\n",
            "\n",
            "**Risk Mitigation Strategies:**\n",
            "\n",
            "- Rigorously track both direct cost savings and revenue impacts post-launch.\n",
            "- Benchmark performance regularly against industry standards and your initial business case.\n",
            "- Prepare for integration challenges, change management, and potential resistance from staff or customers[2].\n",
            "\n",
            "**Summary Table: Financial Projection**\n",
            "\n",
            "| Initial Investment | 3-Year ROI (%) | Expected Net Gain | Total Return After 3 Years |\n",
            "|--------------------|----------------|-------------------|---------------------------|\n",
            "| $2,000,000         | 150%           | $3,000,000        | $5,000,000                |\n",
            "\n",
            "**Conclusion:**  \n",
            "If your projections are accurate and market conditions remain favorable, a 150% ROI over 3 years is financially compelling for an AI customer service platform, aligning with or exceeding current industry benchmarks. However, robust tracking, scenario analysis, and risk management are essential to realize these returns[2][3][6][8].\n",
            "\n",
            "============================================================\n",
            "============================================================\n",
            "Response: GraphResult(status=<Status.COMPLETED: 'completed'>, results={'finance_expert': NodeResult(result=AgentResult(stop_reason='end_turn', message={'role': 'assistant', 'content': []}, metrics=EventLoopMetrics(cycle_count=1, tool_metrics={}, cycle_durations=[8.44445252418518], traces=[<strands.telemetry.metrics.Trace object at 0x7fa5a1c896a0>], accumulated_usage={'inputTokens': 0, 'outputTokens': 0, 'totalTokens': 0}, accumulated_metrics={'latencyMs': 0}), state={}, interrupts=None, structured_output=None), execution_time=8445, status=<Status.COMPLETED: 'completed'>, accumulated_usage={'inputTokens': 0, 'outputTokens': 0, 'totalTokens': 0}, accumulated_metrics={'latencyMs': 0}, execution_count=1), 'tech_expert': NodeResult(result=AgentResult(stop_reason='end_turn', message={'role': 'assistant', 'content': []}, metrics=EventLoopMetrics(cycle_count=1, tool_metrics={}, cycle_durations=[19.023441791534424], traces=[<strands.telemetry.metrics.Trace object at 0x7fa5a1c8be00>], accumulated_usage={'inputTokens': 0, 'outputTokens': 0, 'totalTokens': 0}, accumulated_metrics={'latencyMs': 0}), state={}, interrupts=None, structured_output=None), execution_time=19024, status=<Status.COMPLETED: 'completed'>, accumulated_usage={'inputTokens': 0, 'outputTokens': 0, 'totalTokens': 0}, accumulated_metrics={'latencyMs': 0}, execution_count=1), 'market_expert': NodeResult(result=AgentResult(stop_reason='end_turn', message={'role': 'assistant', 'content': []}, metrics=EventLoopMetrics(cycle_count=1, tool_metrics={}, cycle_durations=[8.034435510635376], traces=[<strands.telemetry.metrics.Trace object at 0x7fa5a1c8bfb0>], accumulated_usage={'inputTokens': 0, 'outputTokens': 0, 'totalTokens': 0}, accumulated_metrics={'latencyMs': 0}), state={}, interrupts=None, structured_output=None), execution_time=8035, status=<Status.COMPLETED: 'completed'>, accumulated_usage={'inputTokens': 0, 'outputTokens': 0, 'totalTokens': 0}, accumulated_metrics={'latencyMs': 0}, execution_count=1), 'risk_analyst': NodeResult(result=AgentResult(stop_reason='end_turn', message={'role': 'assistant', 'content': []}, metrics=EventLoopMetrics(cycle_count=1, tool_metrics={}, cycle_durations=[19.07399892807007], traces=[<strands.telemetry.metrics.Trace object at 0x7fa5a1cdba10>], accumulated_usage={'inputTokens': 0, 'outputTokens': 0, 'totalTokens': 0}, accumulated_metrics={'latencyMs': 0}), state={}, interrupts=None, structured_output=None), execution_time=19075, status=<Status.COMPLETED: 'completed'>, accumulated_usage={'inputTokens': 0, 'outputTokens': 0, 'totalTokens': 0}, accumulated_metrics={'latencyMs': 0}, execution_count=1)}, accumulated_usage={'inputTokens': 0, 'outputTokens': 0, 'totalTokens': 0}, accumulated_metrics={'latencyMs': 0}, execution_count=4, execution_time=0, total_nodes=4, completed_nodes=4, failed_nodes=0, execution_order=[GraphNode(node_id='finance_expert', executor=<strands.agent.agent.Agent object at 0x7fa5a1d5a420>, dependencies=set(), execution_status=<Status.COMPLETED: 'completed'>, result=NodeResult(result=AgentResult(stop_reason='end_turn', message={'role': 'assistant', 'content': []}, metrics=EventLoopMetrics(cycle_count=1, tool_metrics={}, cycle_durations=[8.44445252418518], traces=[<strands.telemetry.metrics.Trace object at 0x7fa5a1c896a0>], accumulated_usage={'inputTokens': 0, 'outputTokens': 0, 'totalTokens': 0}, accumulated_metrics={'latencyMs': 0}), state={}, interrupts=None, structured_output=None), execution_time=8445, status=<Status.COMPLETED: 'completed'>, accumulated_usage={'inputTokens': 0, 'outputTokens': 0, 'totalTokens': 0}, accumulated_metrics={'latencyMs': 0}, execution_count=1), execution_time=8445, _initial_messages=[], _initial_state=<strands.agent.state.AgentState object at 0x7fa5a1c88b90>), GraphNode(node_id='tech_expert', executor=<strands.agent.agent.Agent object at 0x7fa5a25c9cd0>, dependencies={GraphNode(node_id='finance_expert', executor=<strands.agent.agent.Agent object at 0x7fa5a1d5a420>, dependencies=set(), execution_status=<Status.COMPLETED: 'completed'>, result=NodeResult(result=AgentResult(stop_reason='end_turn', message={'role': 'assistant', 'content': []}, metrics=EventLoopMetrics(cycle_count=1, tool_metrics={}, cycle_durations=[8.44445252418518], traces=[<strands.telemetry.metrics.Trace object at 0x7fa5a1c896a0>], accumulated_usage={'inputTokens': 0, 'outputTokens': 0, 'totalTokens': 0}, accumulated_metrics={'latencyMs': 0}), state={}, interrupts=None, structured_output=None), execution_time=8445, status=<Status.COMPLETED: 'completed'>, accumulated_usage={'inputTokens': 0, 'outputTokens': 0, 'totalTokens': 0}, accumulated_metrics={'latencyMs': 0}, execution_count=1), execution_time=8445, _initial_messages=[], _initial_state=<strands.agent.state.AgentState object at 0x7fa5a1c88b90>)}, execution_status=<Status.COMPLETED: 'completed'>, result=NodeResult(result=AgentResult(stop_reason='end_turn', message={'role': 'assistant', 'content': []}, metrics=EventLoopMetrics(cycle_count=1, tool_metrics={}, cycle_durations=[19.023441791534424], traces=[<strands.telemetry.metrics.Trace object at 0x7fa5a1c8be00>], accumulated_usage={'inputTokens': 0, 'outputTokens': 0, 'totalTokens': 0}, accumulated_metrics={'latencyMs': 0}), state={}, interrupts=None, structured_output=None), execution_time=19024, status=<Status.COMPLETED: 'completed'>, accumulated_usage={'inputTokens': 0, 'outputTokens': 0, 'totalTokens': 0}, accumulated_metrics={'latencyMs': 0}, execution_count=1), execution_time=19024, _initial_messages=[], _initial_state=<strands.agent.state.AgentState object at 0x7fa5a1c88c20>), GraphNode(node_id='market_expert', executor=<strands.agent.agent.Agent object at 0x7fa5a1c88440>, dependencies={GraphNode(node_id='finance_expert', executor=<strands.agent.agent.Agent object at 0x7fa5a1d5a420>, dependencies=set(), execution_status=<Status.COMPLETED: 'completed'>, result=NodeResult(result=AgentResult(stop_reason='end_turn', message={'role': 'assistant', 'content': []}, metrics=EventLoopMetrics(cycle_count=1, tool_metrics={}, cycle_durations=[8.44445252418518], traces=[<strands.telemetry.metrics.Trace object at 0x7fa5a1c896a0>], accumulated_usage={'inputTokens': 0, 'outputTokens': 0, 'totalTokens': 0}, accumulated_metrics={'latencyMs': 0}), state={}, interrupts=None, structured_output=None), execution_time=8445, status=<Status.COMPLETED: 'completed'>, accumulated_usage={'inputTokens': 0, 'outputTokens': 0, 'totalTokens': 0}, accumulated_metrics={'latencyMs': 0}, execution_count=1), execution_time=8445, _initial_messages=[], _initial_state=<strands.agent.state.AgentState object at 0x7fa5a1c88b90>)}, execution_status=<Status.COMPLETED: 'completed'>, result=NodeResult(result=AgentResult(stop_reason='end_turn', message={'role': 'assistant', 'content': []}, metrics=EventLoopMetrics(cycle_count=1, tool_metrics={}, cycle_durations=[8.034435510635376], traces=[<strands.telemetry.metrics.Trace object at 0x7fa5a1c8bfb0>], accumulated_usage={'inputTokens': 0, 'outputTokens': 0, 'totalTokens': 0}, accumulated_metrics={'latencyMs': 0}), state={}, interrupts=None, structured_output=None), execution_time=8035, status=<Status.COMPLETED: 'completed'>, accumulated_usage={'inputTokens': 0, 'outputTokens': 0, 'totalTokens': 0}, accumulated_metrics={'latencyMs': 0}, execution_count=1), execution_time=8035, _initial_messages=[], _initial_state=<strands.agent.state.AgentState object at 0x7fa5a1c88c80>), GraphNode(node_id='risk_analyst', executor=<strands.agent.agent.Agent object at 0x7fa5a1c886b0>, dependencies={GraphNode(node_id='tech_expert', executor=<strands.agent.agent.Agent object at 0x7fa5a25c9cd0>, dependencies={GraphNode(node_id='finance_expert', executor=<strands.agent.agent.Agent object at 0x7fa5a1d5a420>, dependencies=set(), execution_status=<Status.COMPLETED: 'completed'>, result=NodeResult(result=AgentResult(stop_reason='end_turn', message={'role': 'assistant', 'content': []}, metrics=EventLoopMetrics(cycle_count=1, tool_metrics={}, cycle_durations=[8.44445252418518], traces=[<strands.telemetry.metrics.Trace object at 0x7fa5a1c896a0>], accumulated_usage={'inputTokens': 0, 'outputTokens': 0, 'totalTokens': 0}, accumulated_metrics={'latencyMs': 0}), state={}, interrupts=None, structured_output=None), execution_time=8445, status=<Status.COMPLETED: 'completed'>, accumulated_usage={'inputTokens': 0, 'outputTokens': 0, 'totalTokens': 0}, accumulated_metrics={'latencyMs': 0}, execution_count=1), execution_time=8445, _initial_messages=[], _initial_state=<strands.agent.state.AgentState object at 0x7fa5a1c88b90>)}, execution_status=<Status.COMPLETED: 'completed'>, result=NodeResult(result=AgentResult(stop_reason='end_turn', message={'role': 'assistant', 'content': []}, metrics=EventLoopMetrics(cycle_count=1, tool_metrics={}, cycle_durations=[19.023441791534424], traces=[<strands.telemetry.metrics.Trace object at 0x7fa5a1c8be00>], accumulated_usage={'inputTokens': 0, 'outputTokens': 0, 'totalTokens': 0}, accumulated_metrics={'latencyMs': 0}), state={}, interrupts=None, structured_output=None), execution_time=19024, status=<Status.COMPLETED: 'completed'>, accumulated_usage={'inputTokens': 0, 'outputTokens': 0, 'totalTokens': 0}, accumulated_metrics={'latencyMs': 0}, execution_count=1), execution_time=19024, _initial_messages=[], _initial_state=<strands.agent.state.AgentState object at 0x7fa5a1c88c20>), GraphNode(node_id='market_expert', executor=<strands.agent.agent.Agent object at 0x7fa5a1c88440>, dependencies={GraphNode(node_id='finance_expert', executor=<strands.agent.agent.Agent object at 0x7fa5a1d5a420>, dependencies=set(), execution_status=<Status.COMPLETED: 'completed'>, result=NodeResult(result=AgentResult(stop_reason='end_turn', message={'role': 'assistant', 'content': []}, metrics=EventLoopMetrics(cycle_count=1, tool_metrics={}, cycle_durations=[8.44445252418518], traces=[<strands.telemetry.metrics.Trace object at 0x7fa5a1c896a0>], accumulated_usage={'inputTokens': 0, 'outputTokens': 0, 'totalTokens': 0}, accumulated_metrics={'latencyMs': 0}), state={}, interrupts=None, structured_output=None), execution_time=8445, status=<Status.COMPLETED: 'completed'>, accumulated_usage={'inputTokens': 0, 'outputTokens': 0, 'totalTokens': 0}, accumulated_metrics={'latencyMs': 0}, execution_count=1), execution_time=8445, _initial_messages=[], _initial_state=<strands.agent.state.AgentState object at 0x7fa5a1c88b90>)}, execution_status=<Status.COMPLETED: 'completed'>, result=NodeResult(result=AgentResult(stop_reason='end_turn', message={'role': 'assistant', 'content': []}, metrics=EventLoopMetrics(cycle_count=1, tool_metrics={}, cycle_durations=[8.034435510635376], traces=[<strands.telemetry.metrics.Trace object at 0x7fa5a1c8bfb0>], accumulated_usage={'inputTokens': 0, 'outputTokens': 0, 'totalTokens': 0}, accumulated_metrics={'latencyMs': 0}), state={}, interrupts=None, structured_output=None), execution_time=8035, status=<Status.COMPLETED: 'completed'>, accumulated_usage={'inputTokens': 0, 'outputTokens': 0, 'totalTokens': 0}, accumulated_metrics={'latencyMs': 0}, execution_count=1), execution_time=8035, _initial_messages=[], _initial_state=<strands.agent.state.AgentState object at 0x7fa5a1c88c80>)}, execution_status=<Status.COMPLETED: 'completed'>, result=NodeResult(result=AgentResult(stop_reason='end_turn', message={'role': 'assistant', 'content': []}, metrics=EventLoopMetrics(cycle_count=1, tool_metrics={}, cycle_durations=[19.07399892807007], traces=[<strands.telemetry.metrics.Trace object at 0x7fa5a1cdba10>], accumulated_usage={'inputTokens': 0, 'outputTokens': 0, 'totalTokens': 0}, accumulated_metrics={'latencyMs': 0}), state={}, interrupts=None, structured_output=None), execution_time=19075, status=<Status.COMPLETED: 'completed'>, accumulated_usage={'inputTokens': 0, 'outputTokens': 0, 'totalTokens': 0}, accumulated_metrics={'latencyMs': 0}, execution_count=1), execution_time=19075, _initial_messages=[], _initial_state=<strands.agent.state.AgentState object at 0x7fa5a1c88ce0>)], edges=[(GraphNode(node_id='tech_expert', executor=<strands.agent.agent.Agent object at 0x7fa5a25c9cd0>, dependencies={GraphNode(node_id='finance_expert', executor=<strands.agent.agent.Agent object at 0x7fa5a1d5a420>, dependencies=set(), execution_status=<Status.COMPLETED: 'completed'>, result=NodeResult(result=AgentResult(stop_reason='end_turn', message={'role': 'assistant', 'content': []}, metrics=EventLoopMetrics(cycle_count=1, tool_metrics={}, cycle_durations=[8.44445252418518], traces=[<strands.telemetry.metrics.Trace object at 0x7fa5a1c896a0>], accumulated_usage={'inputTokens': 0, 'outputTokens': 0, 'totalTokens': 0}, accumulated_metrics={'latencyMs': 0}), state={}, interrupts=None, structured_output=None), execution_time=8445, status=<Status.COMPLETED: 'completed'>, accumulated_usage={'inputTokens': 0, 'outputTokens': 0, 'totalTokens': 0}, accumulated_metrics={'latencyMs': 0}, execution_count=1), execution_time=8445, _initial_messages=[], _initial_state=<strands.agent.state.AgentState object at 0x7fa5a1c88b90>)}, execution_status=<Status.COMPLETED: 'completed'>, result=NodeResult(result=AgentResult(stop_reason='end_turn', message={'role': 'assistant', 'content': []}, metrics=EventLoopMetrics(cycle_count=1, tool_metrics={}, cycle_durations=[19.023441791534424], traces=[<strands.telemetry.metrics.Trace object at 0x7fa5a1c8be00>], accumulated_usage={'inputTokens': 0, 'outputTokens': 0, 'totalTokens': 0}, accumulated_metrics={'latencyMs': 0}), state={}, interrupts=None, structured_output=None), execution_time=19024, status=<Status.COMPLETED: 'completed'>, accumulated_usage={'inputTokens': 0, 'outputTokens': 0, 'totalTokens': 0}, accumulated_metrics={'latencyMs': 0}, execution_count=1), execution_time=19024, _initial_messages=[], _initial_state=<strands.agent.state.AgentState object at 0x7fa5a1c88c20>), GraphNode(node_id='risk_analyst', executor=<strands.agent.agent.Agent object at 0x7fa5a1c886b0>, dependencies={GraphNode(node_id='tech_expert', executor=<strands.agent.agent.Agent object at 0x7fa5a25c9cd0>, dependencies={GraphNode(node_id='finance_expert', executor=<strands.agent.agent.Agent object at 0x7fa5a1d5a420>, dependencies=set(), execution_status=<Status.COMPLETED: 'completed'>, result=NodeResult(result=AgentResult(stop_reason='end_turn', message={'role': 'assistant', 'content': []}, metrics=EventLoopMetrics(cycle_count=1, tool_metrics={}, cycle_durations=[8.44445252418518], traces=[<strands.telemetry.metrics.Trace object at 0x7fa5a1c896a0>], accumulated_usage={'inputTokens': 0, 'outputTokens': 0, 'totalTokens': 0}, accumulated_metrics={'latencyMs': 0}), state={}, interrupts=None, structured_output=None), execution_time=8445, status=<Status.COMPLETED: 'completed'>, accumulated_usage={'inputTokens': 0, 'outputTokens': 0, 'totalTokens': 0}, accumulated_metrics={'latencyMs': 0}, execution_count=1), execution_time=8445, _initial_messages=[], _initial_state=<strands.agent.state.AgentState object at 0x7fa5a1c88b90>)}, execution_status=<Status.COMPLETED: 'completed'>, result=NodeResult(result=AgentResult(stop_reason='end_turn', message={'role': 'assistant', 'content': []}, metrics=EventLoopMetrics(cycle_count=1, tool_metrics={}, cycle_durations=[19.023441791534424], traces=[<strands.telemetry.metrics.Trace object at 0x7fa5a1c8be00>], accumulated_usage={'inputTokens': 0, 'outputTokens': 0, 'totalTokens': 0}, accumulated_metrics={'latencyMs': 0}), state={}, interrupts=None, structured_output=None), execution_time=19024, status=<Status.COMPLETED: 'completed'>, accumulated_usage={'inputTokens': 0, 'outputTokens': 0, 'totalTokens': 0}, accumulated_metrics={'latencyMs': 0}, execution_count=1), execution_time=19024, _initial_messages=[], _initial_state=<strands.agent.state.AgentState object at 0x7fa5a1c88c20>), GraphNode(node_id='market_expert', executor=<strands.agent.agent.Agent object at 0x7fa5a1c88440>, dependencies={GraphNode(node_id='finance_expert', executor=<strands.agent.agent.Agent object at 0x7fa5a1d5a420>, dependencies=set(), execution_status=<Status.COMPLETED: 'completed'>, result=NodeResult(result=AgentResult(stop_reason='end_turn', message={'role': 'assistant', 'content': []}, metrics=EventLoopMetrics(cycle_count=1, tool_metrics={}, cycle_durations=[8.44445252418518], traces=[<strands.telemetry.metrics.Trace object at 0x7fa5a1c896a0>], accumulated_usage={'inputTokens': 0, 'outputTokens': 0, 'totalTokens': 0}, accumulated_metrics={'latencyMs': 0}), state={}, interrupts=None, structured_output=None), execution_time=8445, status=<Status.COMPLETED: 'completed'>, accumulated_usage={'inputTokens': 0, 'outputTokens': 0, 'totalTokens': 0}, accumulated_metrics={'latencyMs': 0}, execution_count=1), execution_time=8445, _initial_messages=[], _initial_state=<strands.agent.state.AgentState object at 0x7fa5a1c88b90>)}, execution_status=<Status.COMPLETED: 'completed'>, result=NodeResult(result=AgentResult(stop_reason='end_turn', message={'role': 'assistant', 'content': []}, metrics=EventLoopMetrics(cycle_count=1, tool_metrics={}, cycle_durations=[8.034435510635376], traces=[<strands.telemetry.metrics.Trace object at 0x7fa5a1c8bfb0>], accumulated_usage={'inputTokens': 0, 'outputTokens': 0, 'totalTokens': 0}, accumulated_metrics={'latencyMs': 0}), state={}, interrupts=None, structured_output=None), execution_time=8035, status=<Status.COMPLETED: 'completed'>, accumulated_usage={'inputTokens': 0, 'outputTokens': 0, 'totalTokens': 0}, accumulated_metrics={'latencyMs': 0}, execution_count=1), execution_time=8035, _initial_messages=[], _initial_state=<strands.agent.state.AgentState object at 0x7fa5a1c88c80>)}, execution_status=<Status.COMPLETED: 'completed'>, result=NodeResult(result=AgentResult(stop_reason='end_turn', message={'role': 'assistant', 'content': []}, metrics=EventLoopMetrics(cycle_count=1, tool_metrics={}, cycle_durations=[19.07399892807007], traces=[<strands.telemetry.metrics.Trace object at 0x7fa5a1cdba10>], accumulated_usage={'inputTokens': 0, 'outputTokens': 0, 'totalTokens': 0}, accumulated_metrics={'latencyMs': 0}), state={}, interrupts=None, structured_output=None), execution_time=19075, status=<Status.COMPLETED: 'completed'>, accumulated_usage={'inputTokens': 0, 'outputTokens': 0, 'totalTokens': 0}, accumulated_metrics={'latencyMs': 0}, execution_count=1), execution_time=19075, _initial_messages=[], _initial_state=<strands.agent.state.AgentState object at 0x7fa5a1c88ce0>)), (GraphNode(node_id='finance_expert', executor=<strands.agent.agent.Agent object at 0x7fa5a1d5a420>, dependencies=set(), execution_status=<Status.COMPLETED: 'completed'>, result=NodeResult(result=AgentResult(stop_reason='end_turn', message={'role': 'assistant', 'content': []}, metrics=EventLoopMetrics(cycle_count=1, tool_metrics={}, cycle_durations=[8.44445252418518], traces=[<strands.telemetry.metrics.Trace object at 0x7fa5a1c896a0>], accumulated_usage={'inputTokens': 0, 'outputTokens': 0, 'totalTokens': 0}, accumulated_metrics={'latencyMs': 0}), state={}, interrupts=None, structured_output=None), execution_time=8445, status=<Status.COMPLETED: 'completed'>, accumulated_usage={'inputTokens': 0, 'outputTokens': 0, 'totalTokens': 0}, accumulated_metrics={'latencyMs': 0}, execution_count=1), execution_time=8445, _initial_messages=[], _initial_state=<strands.agent.state.AgentState object at 0x7fa5a1c88b90>), GraphNode(node_id='tech_expert', executor=<strands.agent.agent.Agent object at 0x7fa5a25c9cd0>, dependencies={GraphNode(node_id='finance_expert', executor=<strands.agent.agent.Agent object at 0x7fa5a1d5a420>, dependencies=set(), execution_status=<Status.COMPLETED: 'completed'>, result=NodeResult(result=AgentResult(stop_reason='end_turn', message={'role': 'assistant', 'content': []}, metrics=EventLoopMetrics(cycle_count=1, tool_metrics={}, cycle_durations=[8.44445252418518], traces=[<strands.telemetry.metrics.Trace object at 0x7fa5a1c896a0>], accumulated_usage={'inputTokens': 0, 'outputTokens': 0, 'totalTokens': 0}, accumulated_metrics={'latencyMs': 0}), state={}, interrupts=None, structured_output=None), execution_time=8445, status=<Status.COMPLETED: 'completed'>, accumulated_usage={'inputTokens': 0, 'outputTokens': 0, 'totalTokens': 0}, accumulated_metrics={'latencyMs': 0}, execution_count=1), execution_time=8445, _initial_messages=[], _initial_state=<strands.agent.state.AgentState object at 0x7fa5a1c88b90>)}, execution_status=<Status.COMPLETED: 'completed'>, result=NodeResult(result=AgentResult(stop_reason='end_turn', message={'role': 'assistant', 'content': []}, metrics=EventLoopMetrics(cycle_count=1, tool_metrics={}, cycle_durations=[19.023441791534424], traces=[<strands.telemetry.metrics.Trace object at 0x7fa5a1c8be00>], accumulated_usage={'inputTokens': 0, 'outputTokens': 0, 'totalTokens': 0}, accumulated_metrics={'latencyMs': 0}), state={}, interrupts=None, structured_output=None), execution_time=19024, status=<Status.COMPLETED: 'completed'>, accumulated_usage={'inputTokens': 0, 'outputTokens': 0, 'totalTokens': 0}, accumulated_metrics={'latencyMs': 0}, execution_count=1), execution_time=19024, _initial_messages=[], _initial_state=<strands.agent.state.AgentState object at 0x7fa5a1c88c20>)), (GraphNode(node_id='finance_expert', executor=<strands.agent.agent.Agent object at 0x7fa5a1d5a420>, dependencies=set(), execution_status=<Status.COMPLETED: 'completed'>, result=NodeResult(result=AgentResult(stop_reason='end_turn', message={'role': 'assistant', 'content': []}, metrics=EventLoopMetrics(cycle_count=1, tool_metrics={}, cycle_durations=[8.44445252418518], traces=[<strands.telemetry.metrics.Trace object at 0x7fa5a1c896a0>], accumulated_usage={'inputTokens': 0, 'outputTokens': 0, 'totalTokens': 0}, accumulated_metrics={'latencyMs': 0}), state={}, interrupts=None, structured_output=None), execution_time=8445, status=<Status.COMPLETED: 'completed'>, accumulated_usage={'inputTokens': 0, 'outputTokens': 0, 'totalTokens': 0}, accumulated_metrics={'latencyMs': 0}, execution_count=1), execution_time=8445, _initial_messages=[], _initial_state=<strands.agent.state.AgentState object at 0x7fa5a1c88b90>), GraphNode(node_id='market_expert', executor=<strands.agent.agent.Agent object at 0x7fa5a1c88440>, dependencies={GraphNode(node_id='finance_expert', executor=<strands.agent.agent.Agent object at 0x7fa5a1d5a420>, dependencies=set(), execution_status=<Status.COMPLETED: 'completed'>, result=NodeResult(result=AgentResult(stop_reason='end_turn', message={'role': 'assistant', 'content': []}, metrics=EventLoopMetrics(cycle_count=1, tool_metrics={}, cycle_durations=[8.44445252418518], traces=[<strands.telemetry.metrics.Trace object at 0x7fa5a1c896a0>], accumulated_usage={'inputTokens': 0, 'outputTokens': 0, 'totalTokens': 0}, accumulated_metrics={'latencyMs': 0}), state={}, interrupts=None, structured_output=None), execution_time=8445, status=<Status.COMPLETED: 'completed'>, accumulated_usage={'inputTokens': 0, 'outputTokens': 0, 'totalTokens': 0}, accumulated_metrics={'latencyMs': 0}, execution_count=1), execution_time=8445, _initial_messages=[], _initial_state=<strands.agent.state.AgentState object at 0x7fa5a1c88b90>)}, execution_status=<Status.COMPLETED: 'completed'>, result=NodeResult(result=AgentResult(stop_reason='end_turn', message={'role': 'assistant', 'content': []}, metrics=EventLoopMetrics(cycle_count=1, tool_metrics={}, cycle_durations=[8.034435510635376], traces=[<strands.telemetry.metrics.Trace object at 0x7fa5a1c8bfb0>], accumulated_usage={'inputTokens': 0, 'outputTokens': 0, 'totalTokens': 0}, accumulated_metrics={'latencyMs': 0}), state={}, interrupts=None, structured_output=None), execution_time=8035, status=<Status.COMPLETED: 'completed'>, accumulated_usage={'inputTokens': 0, 'outputTokens': 0, 'totalTokens': 0}, accumulated_metrics={'latencyMs': 0}, execution_count=1), execution_time=8035, _initial_messages=[], _initial_state=<strands.agent.state.AgentState object at 0x7fa5a1c88c80>)), (GraphNode(node_id='market_expert', executor=<strands.agent.agent.Agent object at 0x7fa5a1c88440>, dependencies={GraphNode(node_id='finance_expert', executor=<strands.agent.agent.Agent object at 0x7fa5a1d5a420>, dependencies=set(), execution_status=<Status.COMPLETED: 'completed'>, result=NodeResult(result=AgentResult(stop_reason='end_turn', message={'role': 'assistant', 'content': []}, metrics=EventLoopMetrics(cycle_count=1, tool_metrics={}, cycle_durations=[8.44445252418518], traces=[<strands.telemetry.metrics.Trace object at 0x7fa5a1c896a0>], accumulated_usage={'inputTokens': 0, 'outputTokens': 0, 'totalTokens': 0}, accumulated_metrics={'latencyMs': 0}), state={}, interrupts=None, structured_output=None), execution_time=8445, status=<Status.COMPLETED: 'completed'>, accumulated_usage={'inputTokens': 0, 'outputTokens': 0, 'totalTokens': 0}, accumulated_metrics={'latencyMs': 0}, execution_count=1), execution_time=8445, _initial_messages=[], _initial_state=<strands.agent.state.AgentState object at 0x7fa5a1c88b90>)}, execution_status=<Status.COMPLETED: 'completed'>, result=NodeResult(result=AgentResult(stop_reason='end_turn', message={'role': 'assistant', 'content': []}, metrics=EventLoopMetrics(cycle_count=1, tool_metrics={}, cycle_durations=[8.034435510635376], traces=[<strands.telemetry.metrics.Trace object at 0x7fa5a1c8bfb0>], accumulated_usage={'inputTokens': 0, 'outputTokens': 0, 'totalTokens': 0}, accumulated_metrics={'latencyMs': 0}), state={}, interrupts=None, structured_output=None), execution_time=8035, status=<Status.COMPLETED: 'completed'>, accumulated_usage={'inputTokens': 0, 'outputTokens': 0, 'totalTokens': 0}, accumulated_metrics={'latencyMs': 0}, execution_count=1), execution_time=8035, _initial_messages=[], _initial_state=<strands.agent.state.AgentState object at 0x7fa5a1c88c80>), GraphNode(node_id='risk_analyst', executor=<strands.agent.agent.Agent object at 0x7fa5a1c886b0>, dependencies={GraphNode(node_id='tech_expert', executor=<strands.agent.agent.Agent object at 0x7fa5a25c9cd0>, dependencies={GraphNode(node_id='finance_expert', executor=<strands.agent.agent.Agent object at 0x7fa5a1d5a420>, dependencies=set(), execution_status=<Status.COMPLETED: 'completed'>, result=NodeResult(result=AgentResult(stop_reason='end_turn', message={'role': 'assistant', 'content': []}, metrics=EventLoopMetrics(cycle_count=1, tool_metrics={}, cycle_durations=[8.44445252418518], traces=[<strands.telemetry.metrics.Trace object at 0x7fa5a1c896a0>], accumulated_usage={'inputTokens': 0, 'outputTokens': 0, 'totalTokens': 0}, accumulated_metrics={'latencyMs': 0}), state={}, interrupts=None, structured_output=None), execution_time=8445, status=<Status.COMPLETED: 'completed'>, accumulated_usage={'inputTokens': 0, 'outputTokens': 0, 'totalTokens': 0}, accumulated_metrics={'latencyMs': 0}, execution_count=1), execution_time=8445, _initial_messages=[], _initial_state=<strands.agent.state.AgentState object at 0x7fa5a1c88b90>)}, execution_status=<Status.COMPLETED: 'completed'>, result=NodeResult(result=AgentResult(stop_reason='end_turn', message={'role': 'assistant', 'content': []}, metrics=EventLoopMetrics(cycle_count=1, tool_metrics={}, cycle_durations=[19.023441791534424], traces=[<strands.telemetry.metrics.Trace object at 0x7fa5a1c8be00>], accumulated_usage={'inputTokens': 0, 'outputTokens': 0, 'totalTokens': 0}, accumulated_metrics={'latencyMs': 0}), state={}, interrupts=None, structured_output=None), execution_time=19024, status=<Status.COMPLETED: 'completed'>, accumulated_usage={'inputTokens': 0, 'outputTokens': 0, 'totalTokens': 0}, accumulated_metrics={'latencyMs': 0}, execution_count=1), execution_time=19024, _initial_messages=[], _initial_state=<strands.agent.state.AgentState object at 0x7fa5a1c88c20>), GraphNode(node_id='market_expert', executor=<strands.agent.agent.Agent object at 0x7fa5a1c88440>, dependencies={GraphNode(node_id='finance_expert', executor=<strands.agent.agent.Agent object at 0x7fa5a1d5a420>, dependencies=set(), execution_status=<Status.COMPLETED: 'completed'>, result=NodeResult(result=AgentResult(stop_reason='end_turn', message={'role': 'assistant', 'content': []}, metrics=EventLoopMetrics(cycle_count=1, tool_metrics={}, cycle_durations=[8.44445252418518], traces=[<strands.telemetry.metrics.Trace object at 0x7fa5a1c896a0>], accumulated_usage={'inputTokens': 0, 'outputTokens': 0, 'totalTokens': 0}, accumulated_metrics={'latencyMs': 0}), state={}, interrupts=None, structured_output=None), execution_time=8445, status=<Status.COMPLETED: 'completed'>, accumulated_usage={'inputTokens': 0, 'outputTokens': 0, 'totalTokens': 0}, accumulated_metrics={'latencyMs': 0}, execution_count=1), execution_time=8445, _initial_messages=[], _initial_state=<strands.agent.state.AgentState object at 0x7fa5a1c88b90>)}, execution_status=<Status.COMPLETED: 'completed'>, result=NodeResult(result=AgentResult(stop_reason='end_turn', message={'role': 'assistant', 'content': []}, metrics=EventLoopMetrics(cycle_count=1, tool_metrics={}, cycle_durations=[8.034435510635376], traces=[<strands.telemetry.metrics.Trace object at 0x7fa5a1c8bfb0>], accumulated_usage={'inputTokens': 0, 'outputTokens': 0, 'totalTokens': 0}, accumulated_metrics={'latencyMs': 0}), state={}, interrupts=None, structured_output=None), execution_time=8035, status=<Status.COMPLETED: 'completed'>, accumulated_usage={'inputTokens': 0, 'outputTokens': 0, 'totalTokens': 0}, accumulated_metrics={'latencyMs': 0}, execution_count=1), execution_time=8035, _initial_messages=[], _initial_state=<strands.agent.state.AgentState object at 0x7fa5a1c88c80>)}, execution_status=<Status.COMPLETED: 'completed'>, result=NodeResult(result=AgentResult(stop_reason='end_turn', message={'role': 'assistant', 'content': []}, metrics=EventLoopMetrics(cycle_count=1, tool_metrics={}, cycle_durations=[19.07399892807007], traces=[<strands.telemetry.metrics.Trace object at 0x7fa5a1cdba10>], accumulated_usage={'inputTokens': 0, 'outputTokens': 0, 'totalTokens': 0}, accumulated_metrics={'latencyMs': 0}), state={}, interrupts=None, structured_output=None), execution_time=19075, status=<Status.COMPLETED: 'completed'>, accumulated_usage={'inputTokens': 0, 'outputTokens': 0, 'totalTokens': 0}, accumulated_metrics={'latencyMs': 0}, execution_count=1), execution_time=19075, _initial_messages=[], _initial_state=<strands.agent.state.AgentState object at 0x7fa5a1c88ce0>))], entry_points=[GraphNode(node_id='finance_expert', executor=<strands.agent.agent.Agent object at 0x7fa5a1d5a420>, dependencies=set(), execution_status=<Status.COMPLETED: 'completed'>, result=NodeResult(result=AgentResult(stop_reason='end_turn', message={'role': 'assistant', 'content': []}, metrics=EventLoopMetrics(cycle_count=1, tool_metrics={}, cycle_durations=[8.44445252418518], traces=[<strands.telemetry.metrics.Trace object at 0x7fa5a1c896a0>], accumulated_usage={'inputTokens': 0, 'outputTokens': 0, 'totalTokens': 0}, accumulated_metrics={'latencyMs': 0}), state={}, interrupts=None, structured_output=None), execution_time=8445, status=<Status.COMPLETED: 'completed'>, accumulated_usage={'inputTokens': 0, 'outputTokens': 0, 'totalTokens': 0}, accumulated_metrics={'latencyMs': 0}, execution_count=1), execution_time=8445, _initial_messages=[], _initial_state=<strands.agent.state.AgentState object at 0x7fa5a1c88b90>)])\n",
            "=============Node execution order:==========================\n",
            "============================================================\n",
            "Executed: finance_expert\n",
            "Executed: tech_expert\n",
            "Executed: market_expert\n",
            "Executed: risk_analyst\n",
            "=============Graph metrics:=================================\n",
            "============================================================\n",
            "Total nodes: 4\n",
            "Completed nodes: 4\n",
            "Failed nodes: 0\n",
            "Execution time: 0ms\n",
            "Token usage: {'inputTokens': 0, 'outputTokens': 0, 'totalTokens': 0}\n",
            "Financial Advisor:\n",
            "============================================================\n",
            "============================================================\n",
            "\n",
            "\n",
            "\n",
            "Technical Expert:\n",
            "============================================================\n",
            "============================================================\n",
            "\n",
            "\n",
            "\n",
            "Market Researcher:\n",
            "============================================================\n",
            "============================================================\n",
            "\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "#Initialize an agent with agent_graph capability\n",
        "from strands.multiagent import GraphBuilder\n",
        "\n",
        "mesh_agent = Agent()\n",
        "# Create specialized agents\n",
        "\n",
        "financial_advisor = Agent(model=model,name=\"financial_advisor\", system_prompt=\"You are a financial advisor focused on cost-benefit analysis, budget implications, and ROI calculations. Engage with other experts to build comprehensive financial perspectives.\")\n",
        "technical_architect = Agent(model=model, name=\"technical_architect\", system_prompt=\"You are a technical architect who evaluates feasibility, implementation challenges, and technical risks. Collaborate with other experts to ensure technical viability.\")\n",
        "market_researcher = Agent(model=model, name=\"market_researcher\", system_prompt=\"You are a market researcher who analyzes market conditions, user needs, and competitive landscape. Work with other experts to validate market opportunities.\")\n",
        "risk_analyst = Agent(model=model, name=\"risk_analyst\", system_prompt=\"You are a risk analyst who identifies potential risks, mitigation strategies, and compliance issues. Collaborate with other experts to ensure comprehensive risk assessment.\")\n",
        "\n",
        "\n",
        "# Build the graph\n",
        "builder = GraphBuilder()\n",
        "\n",
        "# Add nodes\n",
        "builder.add_node(financial_advisor, \"finance_expert\")\n",
        "builder.add_node(technical_architect, \"tech_expert\")\n",
        "builder.add_node(market_researcher, \"market_expert\")\n",
        "builder.add_node(risk_analyst, \"risk_analyst\")\n",
        "\n",
        "# Add edges (dependencies)\n",
        "builder.add_edge(\"finance_expert\", \"tech_expert\")\n",
        "builder.add_edge(\"finance_expert\", \"market_expert\")\n",
        "builder.add_edge(\"tech_expert\", \"risk_analyst\")\n",
        "builder.add_edge(\"market_expert\", \"risk_analyst\")\n",
        "\n",
        "\n",
        "# Set entry points (optional - will be auto-detected if not specified)\n",
        "builder.set_entry_point(\"finance_expert\")\n",
        "\n",
        "# Build the graph\n",
        "graph = builder.build()\n",
        "\n",
        "print(\"============================================================\")\n",
        "print(\"============================================================\")\n",
        "\n",
        "#Execute task on newly built graph\n",
        "result = graph(\"Our company is considering launching a new AI-powered customer service platform. Initial investment is \\$2M with projected 3-year ROI of 150%. What's your financial assessment?\")\n",
        "print(\"\\n\")\n",
        "print(\"============================================================\")\n",
        "print(\"============================================================\")\n",
        "\n",
        "print(f\"Response: {result}\")\n",
        "\n",
        "print(\"=============Node execution order:==========================\")\n",
        "print(\"============================================================\")\n",
        "\n",
        "# See which nodes were executed and in what order\n",
        "for node in result.execution_order:\n",
        "    print(f\"Executed: {node.node_id}\")\n",
        "\n",
        "print(\"=============Graph metrics:=================================\")\n",
        "print(\"============================================================\")\n",
        "\n",
        "\n",
        "# Get performance metrics\n",
        "print(f\"Total nodes: {result.total_nodes}\")\n",
        "print(f\"Completed nodes: {result.completed_nodes}\")\n",
        "print(f\"Failed nodes: {result.failed_nodes}\")\n",
        "print(f\"Execution time: {result.execution_time}ms\")\n",
        "print(f\"Token usage: {result.accumulated_usage}\")\n",
        "\n",
        "\n",
        "# Get results from specific nodes\n",
        "\n",
        "print(\"Financial Advisor:\")\n",
        "print(\"============================================================\")\n",
        "print(\"============================================================\")\n",
        "print(result.results[\"finance_expert\"].result)\n",
        "print(\"\\n\")\n",
        "\n",
        "print(\"Technical Expert:\")\n",
        "print(\"============================================================\")\n",
        "print(\"============================================================\")\n",
        "print(result.results[\"tech_expert\"].result)\n",
        "print(\"\\n\")\n",
        "\n",
        "print(\"Market Researcher:\")\n",
        "print(\"============================================================\")\n",
        "print(\"============================================================\")\n",
        "print(result.results[\"market_expert\"].result)\n",
        "print(\"\\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ae0eb88e-fdc1-4387-8eb0-4a9ae50ca2ea",
      "metadata": {
        "id": "ae0eb88e-fdc1-4387-8eb0-4a9ae50ca2ea"
      },
      "source": [
        "### Branching with conditions\n",
        "\n",
        "Let's create an agent graph that would classify the request and depending on conditions we define in the code - will route the request either to technical or business agent.\n",
        "\n",
        "Take a close look on differences between the node execution order and number of nodes executed in this graph based on two different prompts.\n",
        "\n",
        "<div style=\"text-align:left\">\n",
        "    <img src=\"https://github.com/strands-agents/samples/blob/main/01-tutorials/02-multi-agent-systems/03-graph-agent/images/conditional.png?raw=1\" width=\"55%\" />\n",
        "</div>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 89,
      "id": "5058e219-8fb8-4503-8bbf-9e69dd06cf62",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5058e219-8fb8-4503-8bbf-9e69dd06cf62",
        "outputId": "54732468-7987-4056-a1fe-9cb025bde0f7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:strands.multiagent.graph:Graph without execution limits may run indefinitely if cycles exist\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================================================\n",
            "============================================================\n",
            "The technical aspect of working from home centers on ensuring secure, reliable access to workplace systems, appropriate hardware and software, and a safe and productive work environment. Key considerations and risk factors include equipment requirements, network security, software needs, and ergonomics.\n",
            "\n",
            "**Things to Consider:**\n",
            "\n",
            "- **Hardware Requirements:**\n",
            "  - A modern **laptop or desktop** with up-to-date processors (e.g., current Intel Core or AMD Ryzen), at least **8GB RAM** (16GB preferred for heavy multitasking), **256GB+ SSD storage**, and a **21-inch or larger monitor** for comfortable viewing[1][9].\n",
            "  - Essential peripherals: **Webcam, microphone, speakers or headset, keyboard, mouse**, docking station, and surge protector/uninterruptible power supply[3][7][13].\n",
            "  - Good ergonomics: An **ergonomic chair**, properly positioned desk, and adequate lighting reduce physical health risks[4][13].\n",
            "- **Software & Tools:**\n",
            "  - Operating system (Windows 10 or Mac OS X), up-to-date **antivirus software**, **VPN client** for secure company access, and standard productivity suites (Microsoft Office, project management, communication and collaboration tools)[1][3][9].\n",
            "- **Internet Connectivity:**\n",
            "  - **High-speed, reliable internet** (minimum 10 Mbps per device) is essential for video conferencing and cloud access[1][5][11].\n",
            "  - Wired (Ethernet) connections are preferred for stability in critical tasks[13].\n",
            "- **Physical Workspace:**\n",
            "  - A **quiet, dedicated workspace** that minimizes distractions and supports confidentiality[5].\n",
            "\n",
            "**Key Risk Factors:**\n",
            "\n",
            "- **Cybersecurity Risks:**\n",
            "  - **Unsecured home Wi-Fi:** Home networks usually lack enterprise-grade security, increasing the risk of unauthorized access and data breaches[2][4][8].\n",
            "  - **Personal device usage (BYOD):** Personal devices may lack security updates and proper configuration, making them vulnerable to malware, phishing, and data leaks[2][4][6][10].\n",
            "  - **Phishing and social engineering:** Remote workers are prime targets for cyberattacks due to lower IT oversight and more isolated communication[2][4][10].\n",
            "  - **Expanded attack surface:** More endpoints (devices, home networks) to protect increases the workload for IT and the potential for vulnerabilities[6].\n",
            "  - **Weak password practices and lack of multi-factor authentication (MFA):** Increases the risk of unauthorized system access[2][8].\n",
            "- **Data Protection and Compliance:**\n",
            "  - Risk of **data loss** or exposure if local storage is not encrypted or if files are stored on personal devices/cloud accounts[2][4].\n",
            "  - **Difficulty in enforcing data handling policies** remotely can lead to regulatory non-compliance.\n",
            "- **IT Support and Oversight:**\n",
            "  - **Absence of physical IT support** makes it harder to monitor, patch, and secure devices, increasing the risk of undetected vulnerabilities[2].\n",
            "- **Physical and Environmental Risks:**\n",
            "  - **Ergonomic concerns:** Improper setups can lead to musculoskeletal injuries, eye strain, and reduced productivity[4][13].\n",
            "  - **Electrical safety:** Inadequate surge protection or use of faulty devices can damage equipment or cause hazards[7].\n",
            "- **Business Continuity:**\n",
            "  - **Power outages** or network downtime at home can disrupt work, so backup solutions (UPS, mobile hotspots) are advisable[7][13].\n",
            "\n",
            "**Summary Table: Technical Considerations and Risks**\n",
            "\n",
            "| Aspect                 | Key Considerations                                     | Main Risks Identified                                     |\n",
            "|------------------------|--------------------------------------------------------|-----------------------------------------------------------|\n",
            "| Hardware               | Modern computer, peripherals, ergonomic furniture      | Device failure, poor ergonomics, electrical hazards       |\n",
            "| Software               | Up-to-date OS, security, productivity, VPN tools       | Unpatched software, inadequate security                   |\n",
            "| Internet Connectivity  | High-speed, reliable connection, preferably wired      | Outages, slow speeds, unsecured Wi-Fi                     |\n",
            "| Cybersecurity          | Encrypted data, MFA, company-issued devices if possible| Data breaches, phishing, malware, weak passwords          |\n",
            "| IT Support             | Remote monitoring, regular updates and support         | Delayed incident response, lack of oversight              |\n",
            "| Physical Workspace     | Quiet, dedicated, well-lit and ventilated area         | Distractions, confidentiality breaches, health issues     |\n",
            "\n",
            "Organizations should conduct regular risk assessments of remote setups, enforce clear security policies (especially for BYOD), and offer training on best practices to mitigate these risks[4][2][10].\n",
            "\n",
            "============================================================\n",
            "============================================================\n",
            "Response: GraphResult(status=<Status.COMPLETED: 'completed'>, results={'classifier': NodeResult(result=AgentResult(stop_reason='end_turn', message={'role': 'assistant', 'content': []}, metrics=EventLoopMetrics(cycle_count=1, tool_metrics={}, cycle_durations=[10.476651430130005], traces=[<strands.telemetry.metrics.Trace object at 0x7fa5a14330b0>], accumulated_usage={'inputTokens': 0, 'outputTokens': 0, 'totalTokens': 0}, accumulated_metrics={'latencyMs': 0}), state={}, interrupts=None, structured_output=None), execution_time=10477, status=<Status.COMPLETED: 'completed'>, accumulated_usage={'inputTokens': 0, 'outputTokens': 0, 'totalTokens': 0}, accumulated_metrics={'latencyMs': 0}, execution_count=1)}, accumulated_usage={'inputTokens': 0, 'outputTokens': 0, 'totalTokens': 0}, accumulated_metrics={'latencyMs': 0}, execution_count=1, execution_time=0, total_nodes=3, completed_nodes=1, failed_nodes=0, execution_order=[GraphNode(node_id='classifier', executor=<strands.agent.agent.Agent object at 0x7fa5a1cd8560>, dependencies=set(), execution_status=<Status.COMPLETED: 'completed'>, result=NodeResult(result=AgentResult(stop_reason='end_turn', message={'role': 'assistant', 'content': []}, metrics=EventLoopMetrics(cycle_count=1, tool_metrics={}, cycle_durations=[10.476651430130005], traces=[<strands.telemetry.metrics.Trace object at 0x7fa5a14330b0>], accumulated_usage={'inputTokens': 0, 'outputTokens': 0, 'totalTokens': 0}, accumulated_metrics={'latencyMs': 0}), state={}, interrupts=None, structured_output=None), execution_time=10477, status=<Status.COMPLETED: 'completed'>, accumulated_usage={'inputTokens': 0, 'outputTokens': 0, 'totalTokens': 0}, accumulated_metrics={'latencyMs': 0}, execution_count=1), execution_time=10477, _initial_messages=[], _initial_state=<strands.agent.state.AgentState object at 0x7fa5a14327e0>)], edges=[(GraphNode(node_id='classifier', executor=<strands.agent.agent.Agent object at 0x7fa5a1cd8560>, dependencies=set(), execution_status=<Status.COMPLETED: 'completed'>, result=NodeResult(result=AgentResult(stop_reason='end_turn', message={'role': 'assistant', 'content': []}, metrics=EventLoopMetrics(cycle_count=1, tool_metrics={}, cycle_durations=[10.476651430130005], traces=[<strands.telemetry.metrics.Trace object at 0x7fa5a14330b0>], accumulated_usage={'inputTokens': 0, 'outputTokens': 0, 'totalTokens': 0}, accumulated_metrics={'latencyMs': 0}), state={}, interrupts=None, structured_output=None), execution_time=10477, status=<Status.COMPLETED: 'completed'>, accumulated_usage={'inputTokens': 0, 'outputTokens': 0, 'totalTokens': 0}, accumulated_metrics={'latencyMs': 0}, execution_count=1), execution_time=10477, _initial_messages=[], _initial_state=<strands.agent.state.AgentState object at 0x7fa5a14327e0>), GraphNode(node_id='business_report', executor=<strands.agent.agent.Agent object at 0x7fa5a1432300>, dependencies={GraphNode(node_id='classifier', executor=<strands.agent.agent.Agent object at 0x7fa5a1cd8560>, dependencies=set(), execution_status=<Status.COMPLETED: 'completed'>, result=NodeResult(result=AgentResult(stop_reason='end_turn', message={'role': 'assistant', 'content': []}, metrics=EventLoopMetrics(cycle_count=1, tool_metrics={}, cycle_durations=[10.476651430130005], traces=[<strands.telemetry.metrics.Trace object at 0x7fa5a14330b0>], accumulated_usage={'inputTokens': 0, 'outputTokens': 0, 'totalTokens': 0}, accumulated_metrics={'latencyMs': 0}), state={}, interrupts=None, structured_output=None), execution_time=10477, status=<Status.COMPLETED: 'completed'>, accumulated_usage={'inputTokens': 0, 'outputTokens': 0, 'totalTokens': 0}, accumulated_metrics={'latencyMs': 0}, execution_count=1), execution_time=10477, _initial_messages=[], _initial_state=<strands.agent.state.AgentState object at 0x7fa5a14327e0>)}, execution_status=<Status.PENDING: 'pending'>, result=None, execution_time=0, _initial_messages=[], _initial_state=<strands.agent.state.AgentState object at 0x7fa5a14328d0>)), (GraphNode(node_id='classifier', executor=<strands.agent.agent.Agent object at 0x7fa5a1cd8560>, dependencies=set(), execution_status=<Status.COMPLETED: 'completed'>, result=NodeResult(result=AgentResult(stop_reason='end_turn', message={'role': 'assistant', 'content': []}, metrics=EventLoopMetrics(cycle_count=1, tool_metrics={}, cycle_durations=[10.476651430130005], traces=[<strands.telemetry.metrics.Trace object at 0x7fa5a14330b0>], accumulated_usage={'inputTokens': 0, 'outputTokens': 0, 'totalTokens': 0}, accumulated_metrics={'latencyMs': 0}), state={}, interrupts=None, structured_output=None), execution_time=10477, status=<Status.COMPLETED: 'completed'>, accumulated_usage={'inputTokens': 0, 'outputTokens': 0, 'totalTokens': 0}, accumulated_metrics={'latencyMs': 0}, execution_count=1), execution_time=10477, _initial_messages=[], _initial_state=<strands.agent.state.AgentState object at 0x7fa5a14327e0>), GraphNode(node_id='technical_report', executor=<strands.agent.agent.Agent object at 0x7fa5a14320c0>, dependencies={GraphNode(node_id='classifier', executor=<strands.agent.agent.Agent object at 0x7fa5a1cd8560>, dependencies=set(), execution_status=<Status.COMPLETED: 'completed'>, result=NodeResult(result=AgentResult(stop_reason='end_turn', message={'role': 'assistant', 'content': []}, metrics=EventLoopMetrics(cycle_count=1, tool_metrics={}, cycle_durations=[10.476651430130005], traces=[<strands.telemetry.metrics.Trace object at 0x7fa5a14330b0>], accumulated_usage={'inputTokens': 0, 'outputTokens': 0, 'totalTokens': 0}, accumulated_metrics={'latencyMs': 0}), state={}, interrupts=None, structured_output=None), execution_time=10477, status=<Status.COMPLETED: 'completed'>, accumulated_usage={'inputTokens': 0, 'outputTokens': 0, 'totalTokens': 0}, accumulated_metrics={'latencyMs': 0}, execution_count=1), execution_time=10477, _initial_messages=[], _initial_state=<strands.agent.state.AgentState object at 0x7fa5a14327e0>)}, execution_status=<Status.PENDING: 'pending'>, result=None, execution_time=0, _initial_messages=[], _initial_state=<strands.agent.state.AgentState object at 0x7fa5a1432870>))], entry_points=[GraphNode(node_id='classifier', executor=<strands.agent.agent.Agent object at 0x7fa5a1cd8560>, dependencies=set(), execution_status=<Status.COMPLETED: 'completed'>, result=NodeResult(result=AgentResult(stop_reason='end_turn', message={'role': 'assistant', 'content': []}, metrics=EventLoopMetrics(cycle_count=1, tool_metrics={}, cycle_durations=[10.476651430130005], traces=[<strands.telemetry.metrics.Trace object at 0x7fa5a14330b0>], accumulated_usage={'inputTokens': 0, 'outputTokens': 0, 'totalTokens': 0}, accumulated_metrics={'latencyMs': 0}), state={}, interrupts=None, structured_output=None), execution_time=10477, status=<Status.COMPLETED: 'completed'>, accumulated_usage={'inputTokens': 0, 'outputTokens': 0, 'totalTokens': 0}, accumulated_metrics={'latencyMs': 0}, execution_count=1), execution_time=10477, _initial_messages=[], _initial_state=<strands.agent.state.AgentState object at 0x7fa5a14327e0>)])\n",
            "=============Node execution order:==========================\n",
            "============================================================\n",
            "Executed: classifier\n",
            "=============Graph metrics:=================================\n",
            "============================================================\n",
            "Total nodes: 3\n",
            "Completed nodes: 1\n",
            "Failed nodes: 0\n",
            "Execution time: 0ms\n",
            "Token usage: {'inputTokens': 0, 'outputTokens': 0, 'totalTokens': 0}\n",
            "Classifier:\n",
            "============================================================\n",
            "============================================================\n",
            "\n",
            "\n",
            "\n",
            "Working from home has significantly transformed business operations, delivering both measurable benefits and notable challenges. Key considerations for organizations include productivity, cost, employee satisfaction, and risks related to management, collaboration, and career progression.\n",
            "\n",
            "**Key Business Impacts to Consider:**\n",
            "\n",
            "- **Productivity:** Multiple studies show remote work can lead to higher productivity, with gains of 13–40% reported in some cases, often attributed to fewer workplace distractions and improved flexibility[1][5]. US Bureau of Labor Statistics data links increased remote work with higher total factor productivity (TFP) across many industries[4].\n",
            "- **Cost Savings:** Remote work reduces the need for physical office space, lowering real estate and facilities costs. A 1% increase in remote work was associated with a 0.4% decrease in office building cost growth[4]. Businesses also save on utilities and some recruitment costs.\n",
            "- **Talent Attraction & Retention:** Offering remote or hybrid options is now a major driver of employee satisfaction and retention. Remote workers are 24% more satisfied, and companies offering flexibility see up to 25% lower turnover[1]. Many employees would accept lower pay to maintain remote options.\n",
            "- **Business Growth:** Fully remote firms have demonstrated revenue growth rates 1.7 times higher than office-based peers between 2019 and 2024[2].\n",
            "- **Employee Well-being & Engagement:** Most employees report improved work-life balance and lower stress levels when working remotely[8]. However, engagement and a sense of connection with teams can suffer, with 30–40% reporting feelings of disconnection[1].\n",
            "\n",
            "**Key Risk Factors:**\n",
            "\n",
            "- **Management and Performance Assessment Challenges:** Managers report lower visibility into employee performance, making evaluation and career development more difficult. Around 60% of managers find it harder to assess remote employees compared to on-site staff[1].\n",
            "- **Collaboration and Communication:** Remote work can create communication gaps (29% of employees cite this as a challenge), increase reliance on asynchronous tools, and often leads to more frequent—but sometimes less effective—virtual meetings, contributing to mental fatigue[1].\n",
            "- **Career Progression Concerns:** About 50% of remote workers worry their chances for promotion are negatively impacted by reduced visibility compared to in-office peers[1].\n",
            "- **Employee Isolation:** Loneliness and a lack of team cohesion are significant risks, with 22% of employees citing loneliness as a primary challenge[1]. This can affect morale, engagement, and retention.\n",
            "- **Distractions and Time Management:** Home environments can introduce distractions, and 25% of remote workers report difficulty managing their time effectively[1].\n",
            "- **Security and Compliance:** While not always top of mind for business leaders, remote work increases risks around data security and compliance due to distributed access and varied home network setups. Businesses must invest in secure tools and training.\n",
            "\n",
            "**Additional Considerations:**\n",
            "\n",
            "- **Hybrid Models Preferred:** In 2025, 83% of workers cite hybrid work—a blend of remote and in-office—as the ideal model, offering flexibility while maintaining opportunities for in-person collaboration[1].\n",
            "- **Technology Investment:** Cloud-based collaboration and project management tools are critical to sustaining productivity, with companies reporting up to 35% productivity gains from adopting centralized digital platforms[1].\n",
            "- **Organizational Culture:** Sustaining a strong, inclusive company culture requires intentional strategies when teams are remote, such as regular virtual check-ins, transparent communication, and targeted team-building initiatives.\n",
            "\n",
            "Overall, while working from home offers compelling business advantages—including productivity gains, cost savings, and talent retention—companies must proactively address risks around management, communication, career development, and employee well-being to maximize benefits and minimize drawbacks.\n",
            "\n",
            "============================================================\n",
            "============================================================\n",
            "Response: GraphResult(status=<Status.COMPLETED: 'completed'>, results={'classifier': NodeResult(result=AgentResult(stop_reason='end_turn', message={'role': 'assistant', 'content': []}, metrics=EventLoopMetrics(cycle_count=2, tool_metrics={}, cycle_durations=[10.476651430130005, 13.257744073867798], traces=[<strands.telemetry.metrics.Trace object at 0x7fa5a14330b0>, <strands.telemetry.metrics.Trace object at 0x7fa5a1cd8d40>], accumulated_usage={'inputTokens': 0, 'outputTokens': 0, 'totalTokens': 0}, accumulated_metrics={'latencyMs': 0}), state={}, interrupts=None, structured_output=None), execution_time=13258, status=<Status.COMPLETED: 'completed'>, accumulated_usage={'inputTokens': 0, 'outputTokens': 0, 'totalTokens': 0}, accumulated_metrics={'latencyMs': 0}, execution_count=1)}, accumulated_usage={'inputTokens': 0, 'outputTokens': 0, 'totalTokens': 0}, accumulated_metrics={'latencyMs': 0}, execution_count=1, execution_time=0, total_nodes=3, completed_nodes=1, failed_nodes=0, execution_order=[GraphNode(node_id='classifier', executor=<strands.agent.agent.Agent object at 0x7fa5a1cd8560>, dependencies=set(), execution_status=<Status.COMPLETED: 'completed'>, result=NodeResult(result=AgentResult(stop_reason='end_turn', message={'role': 'assistant', 'content': []}, metrics=EventLoopMetrics(cycle_count=2, tool_metrics={}, cycle_durations=[10.476651430130005, 13.257744073867798], traces=[<strands.telemetry.metrics.Trace object at 0x7fa5a14330b0>, <strands.telemetry.metrics.Trace object at 0x7fa5a1cd8d40>], accumulated_usage={'inputTokens': 0, 'outputTokens': 0, 'totalTokens': 0}, accumulated_metrics={'latencyMs': 0}), state={}, interrupts=None, structured_output=None), execution_time=13258, status=<Status.COMPLETED: 'completed'>, accumulated_usage={'inputTokens': 0, 'outputTokens': 0, 'totalTokens': 0}, accumulated_metrics={'latencyMs': 0}, execution_count=1), execution_time=13258, _initial_messages=[], _initial_state=<strands.agent.state.AgentState object at 0x7fa5a14327e0>)], edges=[(GraphNode(node_id='classifier', executor=<strands.agent.agent.Agent object at 0x7fa5a1cd8560>, dependencies=set(), execution_status=<Status.COMPLETED: 'completed'>, result=NodeResult(result=AgentResult(stop_reason='end_turn', message={'role': 'assistant', 'content': []}, metrics=EventLoopMetrics(cycle_count=2, tool_metrics={}, cycle_durations=[10.476651430130005, 13.257744073867798], traces=[<strands.telemetry.metrics.Trace object at 0x7fa5a14330b0>, <strands.telemetry.metrics.Trace object at 0x7fa5a1cd8d40>], accumulated_usage={'inputTokens': 0, 'outputTokens': 0, 'totalTokens': 0}, accumulated_metrics={'latencyMs': 0}), state={}, interrupts=None, structured_output=None), execution_time=13258, status=<Status.COMPLETED: 'completed'>, accumulated_usage={'inputTokens': 0, 'outputTokens': 0, 'totalTokens': 0}, accumulated_metrics={'latencyMs': 0}, execution_count=1), execution_time=13258, _initial_messages=[], _initial_state=<strands.agent.state.AgentState object at 0x7fa5a14327e0>), GraphNode(node_id='business_report', executor=<strands.agent.agent.Agent object at 0x7fa5a1432300>, dependencies={GraphNode(node_id='classifier', executor=<strands.agent.agent.Agent object at 0x7fa5a1cd8560>, dependencies=set(), execution_status=<Status.COMPLETED: 'completed'>, result=NodeResult(result=AgentResult(stop_reason='end_turn', message={'role': 'assistant', 'content': []}, metrics=EventLoopMetrics(cycle_count=2, tool_metrics={}, cycle_durations=[10.476651430130005, 13.257744073867798], traces=[<strands.telemetry.metrics.Trace object at 0x7fa5a14330b0>, <strands.telemetry.metrics.Trace object at 0x7fa5a1cd8d40>], accumulated_usage={'inputTokens': 0, 'outputTokens': 0, 'totalTokens': 0}, accumulated_metrics={'latencyMs': 0}), state={}, interrupts=None, structured_output=None), execution_time=13258, status=<Status.COMPLETED: 'completed'>, accumulated_usage={'inputTokens': 0, 'outputTokens': 0, 'totalTokens': 0}, accumulated_metrics={'latencyMs': 0}, execution_count=1), execution_time=13258, _initial_messages=[], _initial_state=<strands.agent.state.AgentState object at 0x7fa5a14327e0>)}, execution_status=<Status.PENDING: 'pending'>, result=None, execution_time=0, _initial_messages=[], _initial_state=<strands.agent.state.AgentState object at 0x7fa5a14328d0>)), (GraphNode(node_id='classifier', executor=<strands.agent.agent.Agent object at 0x7fa5a1cd8560>, dependencies=set(), execution_status=<Status.COMPLETED: 'completed'>, result=NodeResult(result=AgentResult(stop_reason='end_turn', message={'role': 'assistant', 'content': []}, metrics=EventLoopMetrics(cycle_count=2, tool_metrics={}, cycle_durations=[10.476651430130005, 13.257744073867798], traces=[<strands.telemetry.metrics.Trace object at 0x7fa5a14330b0>, <strands.telemetry.metrics.Trace object at 0x7fa5a1cd8d40>], accumulated_usage={'inputTokens': 0, 'outputTokens': 0, 'totalTokens': 0}, accumulated_metrics={'latencyMs': 0}), state={}, interrupts=None, structured_output=None), execution_time=13258, status=<Status.COMPLETED: 'completed'>, accumulated_usage={'inputTokens': 0, 'outputTokens': 0, 'totalTokens': 0}, accumulated_metrics={'latencyMs': 0}, execution_count=1), execution_time=13258, _initial_messages=[], _initial_state=<strands.agent.state.AgentState object at 0x7fa5a14327e0>), GraphNode(node_id='technical_report', executor=<strands.agent.agent.Agent object at 0x7fa5a14320c0>, dependencies={GraphNode(node_id='classifier', executor=<strands.agent.agent.Agent object at 0x7fa5a1cd8560>, dependencies=set(), execution_status=<Status.COMPLETED: 'completed'>, result=NodeResult(result=AgentResult(stop_reason='end_turn', message={'role': 'assistant', 'content': []}, metrics=EventLoopMetrics(cycle_count=2, tool_metrics={}, cycle_durations=[10.476651430130005, 13.257744073867798], traces=[<strands.telemetry.metrics.Trace object at 0x7fa5a14330b0>, <strands.telemetry.metrics.Trace object at 0x7fa5a1cd8d40>], accumulated_usage={'inputTokens': 0, 'outputTokens': 0, 'totalTokens': 0}, accumulated_metrics={'latencyMs': 0}), state={}, interrupts=None, structured_output=None), execution_time=13258, status=<Status.COMPLETED: 'completed'>, accumulated_usage={'inputTokens': 0, 'outputTokens': 0, 'totalTokens': 0}, accumulated_metrics={'latencyMs': 0}, execution_count=1), execution_time=13258, _initial_messages=[], _initial_state=<strands.agent.state.AgentState object at 0x7fa5a14327e0>)}, execution_status=<Status.PENDING: 'pending'>, result=None, execution_time=0, _initial_messages=[], _initial_state=<strands.agent.state.AgentState object at 0x7fa5a1432870>))], entry_points=[GraphNode(node_id='classifier', executor=<strands.agent.agent.Agent object at 0x7fa5a1cd8560>, dependencies=set(), execution_status=<Status.COMPLETED: 'completed'>, result=NodeResult(result=AgentResult(stop_reason='end_turn', message={'role': 'assistant', 'content': []}, metrics=EventLoopMetrics(cycle_count=2, tool_metrics={}, cycle_durations=[10.476651430130005, 13.257744073867798], traces=[<strands.telemetry.metrics.Trace object at 0x7fa5a14330b0>, <strands.telemetry.metrics.Trace object at 0x7fa5a1cd8d40>], accumulated_usage={'inputTokens': 0, 'outputTokens': 0, 'totalTokens': 0}, accumulated_metrics={'latencyMs': 0}), state={}, interrupts=None, structured_output=None), execution_time=13258, status=<Status.COMPLETED: 'completed'>, accumulated_usage={'inputTokens': 0, 'outputTokens': 0, 'totalTokens': 0}, accumulated_metrics={'latencyMs': 0}, execution_count=1), execution_time=13258, _initial_messages=[], _initial_state=<strands.agent.state.AgentState object at 0x7fa5a14327e0>)])\n",
            "=============Node execution order:==========================\n",
            "============================================================\n",
            "Executed: classifier\n",
            "=============Graph metrics:=================================\n",
            "============================================================\n",
            "Total nodes: 3\n",
            "Completed nodes: 1\n",
            "Failed nodes: 0\n",
            "Execution time: 0ms\n",
            "Token usage: {'inputTokens': 0, 'outputTokens': 0, 'totalTokens': 0}\n",
            "Classifier:\n",
            "============================================================\n",
            "============================================================\n",
            "\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "#Initialize an agent with agent_graph capability\n",
        "from strands.multiagent import GraphBuilder\n",
        "\n",
        "mesh_agent = Agent()\n",
        "# Create specialized agents\n",
        "\n",
        "classifier = Agent(model=model,name=\"classifier\", system_prompt=\"You are an agent responsible for classification of the report request, return only Technical or Business clasification.\")\n",
        "technical_report = Agent(model=model, name=\"technical_expert\", system_prompt=\"You are a technical expert htat focuses on providing short summary from technical perspective\")\n",
        "business_report = Agent(model=model, name=\"business_expert\", system_prompt=\"You are a business expert that focuses on providing short summary from business perspective\")\n",
        "\n",
        "# Build the graph\n",
        "builder = GraphBuilder()\n",
        "\n",
        "# Add nodes\n",
        "builder.add_node(classifier, \"classifier\")\n",
        "builder.add_node(technical_report, \"technical_report\")\n",
        "builder.add_node(business_report, \"business_report\")\n",
        "\n",
        "def is_technical(state):\n",
        "    classifier_result = state.results.get(\"classifier\")\n",
        "    if not classifier_result:\n",
        "        return False\n",
        "    result_text = str(classifier_result.result)\n",
        "    return \"technical\" in result_text.lower()\n",
        "\n",
        "def is_business(state):\n",
        "    classifier_result = state.results.get(\"classifier\")\n",
        "    if not classifier_result:\n",
        "        return False\n",
        "    result_text = str(classifier_result.result)\n",
        "    return \"business\" in result_text.lower()\n",
        "\n",
        "# Add edges (dependencies)\n",
        "builder.add_edge(\"classifier\", \"technical_report\", condition=is_technical)\n",
        "builder.add_edge(\"classifier\", \"business_report\", condition=is_business)\n",
        "\n",
        "# Set entry points (optional - will be auto-detected if not specified)\n",
        "builder.set_entry_point(\"classifier\")\n",
        "\n",
        "# Build the graph\n",
        "graph = builder.build()\n",
        "\n",
        "print(\"============================================================\")\n",
        "print(\"============================================================\")\n",
        "\n",
        "#Execute task on newly built graph\n",
        "result = graph(\"Provide report on technical aspect of working from home, outline things to consider and key risk factors\")\n",
        "print(\"\\n\")\n",
        "print(\"============================================================\")\n",
        "print(\"============================================================\")\n",
        "\n",
        "print(f\"Response: {result}\")\n",
        "\n",
        "print(\"=============Node execution order:==========================\")\n",
        "print(\"============================================================\")\n",
        "\n",
        "# See which nodes were executed and in what order\n",
        "for node in result.execution_order:\n",
        "    print(f\"Executed: {node.node_id}\")\n",
        "\n",
        "print(\"=============Graph metrics:=================================\")\n",
        "print(\"============================================================\")\n",
        "\n",
        "\n",
        "# Get performance metrics\n",
        "print(f\"Total nodes: {result.total_nodes}\")\n",
        "print(f\"Completed nodes: {result.completed_nodes}\")\n",
        "print(f\"Failed nodes: {result.failed_nodes}\")\n",
        "print(f\"Execution time: {result.execution_time}ms\")\n",
        "print(f\"Token usage: {result.accumulated_usage}\")\n",
        "\n",
        "# Get results from specific nodes\n",
        "\n",
        "print(\"Classifier:\")\n",
        "print(\"============================================================\")\n",
        "print(\"============================================================\")\n",
        "print(result.results[\"classifier\"].result)\n",
        "print(\"\\n\")\n",
        "\n",
        "#Execute task on newly built graph\n",
        "result = graph(\"Provide report on business impact of working from home, outline things to consider and key risk factors\")\n",
        "print(\"\\n\")\n",
        "print(\"============================================================\")\n",
        "print(\"============================================================\")\n",
        "\n",
        "print(f\"Response: {result}\")\n",
        "\n",
        "print(\"=============Node execution order:==========================\")\n",
        "print(\"============================================================\")\n",
        "\n",
        "# See which nodes were executed and in what order\n",
        "for node in result.execution_order:\n",
        "    print(f\"Executed: {node.node_id}\")\n",
        "\n",
        "print(\"=============Graph metrics:=================================\")\n",
        "print(\"============================================================\")\n",
        "\n",
        "\n",
        "# Get performance metrics\n",
        "print(f\"Total nodes: {result.total_nodes}\")\n",
        "print(f\"Completed nodes: {result.completed_nodes}\")\n",
        "print(f\"Failed nodes: {result.failed_nodes}\")\n",
        "print(f\"Execution time: {result.execution_time}ms\")\n",
        "print(f\"Token usage: {result.accumulated_usage}\")\n",
        "\n",
        "# Get results from specific nodes\n",
        "\n",
        "print(\"Classifier:\")\n",
        "print(\"============================================================\")\n",
        "print(\"============================================================\")\n",
        "print(result.results[\"classifier\"].result)\n",
        "print(\"\\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6d35f546-fe6a-4ce2-acf5-4ed8690c593d",
      "metadata": {
        "id": "6d35f546-fe6a-4ce2-acf5-4ed8690c593d"
      },
      "source": [
        "## Key Takeaways and Best Practices\n",
        "\n",
        "\n",
        "### Best Practices:\n",
        "\n",
        "**Design for acyclicity:** Ensure your graph has no cycles</p>\n",
        "**Use meaningful node IDs:** Choose descriptive names for nodes</p>\n",
        "**Validate graph structure:** The builder will check for cycles and validate entry points</p>\n",
        "**Handle node failures:** Consider how failures in one node affect the overall workflow</p>\n",
        "**Use conditional edges:** For dynamic workflows based on intermediate results</p>\n",
        "**Consider parallelism:** Independent branches can execute concurrently</p>\n",
        "**Nest multi-agent patterns:** Use Swarms within Graphs for complex workflows</p>\n",
        "**Leverage multi-modal inputs:** Use ContentBlocks for rich inputs including images</p>\n",
        "\n",
        "## Conclusion\n",
        "\n",
        "You've now mastered the fundamentals of building multi-agent systems with Strands Agent Graph! You can create sophisticated networks of specialized AI agents that collaborate to solve complex problems.\n",
        "\n",
        "The key to successful multi-agent systems is:\n",
        "- Matching topology to use case\n",
        "- Defining clear agent roles and responsibilities  \n",
        "- Establishing proper communication patterns\n",
        "- Managing resources and cleanup effectively\n",
        "\n",
        "From here, you can build increasingly sophisticated systems for real-world applications in research, content creation, decision-making, customer service, and beyond."
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.3"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
  "cells": [
    {
      "cell_type": "markdown",
      "id": "b3fa745a-a393-498b-ab51-68804fadf751",
      "metadata": {
        "id": "b3fa745a-a393-498b-ab51-68804fadf751"
      },
      "source": [
        "\n",
        "# Building Multi-Agent Systems with Strands Agent Graph\n",
        "Multi-agent systems leverage multiple specialized AI agents working together to solve complex problems through coordinated collaboration. Each agent has specific capabilities and roles, connected through explicit communication pathways.\n",
        "\n",
        "In this lab, you'll learn to build multi-agent systems using the Strands Agent SDK. We'll progress from basic concepts to advanced implementations, exploring different topologies and real-world applications.\n",
        "\n",
        "**Learning Objectives:**\n",
        "By the end of this notebook, you'll be able to:\n",
        "- Understand the three core components of agent graphs (nodes, edges, conditions)\n",
        "- Send targeted messages between specific agents\n",
        "- Monitor and control multi-agent networks\n",
        "- Design specialized agent systems for real-world scenarios\n",
        "\n",
        "## Prerequisites\n",
        "\n",
        "- Python 3.10+\n",
        "- AWS account with Anthropic Claude 3.7 enabled on Amazon Bedrock\n",
        "- IAM role with permissions to use Amazon Bedrock\n",
        "- Basic understanding of AI agents and prompt engineering"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "afc1a597-0490-4ab1-9324-5498b5592662",
      "metadata": {
        "id": "afc1a597-0490-4ab1-9324-5498b5592662"
      },
      "source": [
        "## Setup and Installation\n",
        "\n",
        "Before we start, let's install the requirement packages for `strands-agents` and `strands-agents-tools`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "id": "e048e8cf-3fa7-495b-a761-7999936171c5",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e048e8cf-3fa7-495b-a761-7999936171c5",
        "outputId": "634020aa-73d6-4f76-9956-466cc704fdc8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: strands-agents in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 1)) (1.18.0)\n",
            "Requirement already satisfied: strands-agents-tools in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 2)) (0.2.16)\n",
            "Requirement already satisfied: perplexityai in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 3)) (0.20.0)\n",
            "Requirement already satisfied: boto3<2.0.0,>=1.26.0 in /usr/local/lib/python3.12/dist-packages (from strands-agents->-r requirements.txt (line 1)) (1.41.2)\n",
            "Requirement already satisfied: botocore<2.0.0,>=1.29.0 in /usr/local/lib/python3.12/dist-packages (from strands-agents->-r requirements.txt (line 1)) (1.41.2)\n",
            "Requirement already satisfied: docstring-parser<1.0,>=0.15 in /usr/local/lib/python3.12/dist-packages (from strands-agents->-r requirements.txt (line 1)) (0.17.0)\n",
            "Requirement already satisfied: jsonschema<5.0.0,>=4.0.0 in /usr/local/lib/python3.12/dist-packages (from strands-agents->-r requirements.txt (line 1)) (4.25.1)\n",
            "Requirement already satisfied: mcp<2.0.0,>=1.11.0 in /usr/local/lib/python3.12/dist-packages (from strands-agents->-r requirements.txt (line 1)) (1.22.0)\n",
            "Requirement already satisfied: opentelemetry-api<2.0.0,>=1.30.0 in /usr/local/lib/python3.12/dist-packages (from strands-agents->-r requirements.txt (line 1)) (1.38.0)\n",
            "Requirement already satisfied: opentelemetry-instrumentation-threading<1.00b0,>=0.51b0 in /usr/local/lib/python3.12/dist-packages (from strands-agents->-r requirements.txt (line 1)) (0.59b0)\n",
            "Requirement already satisfied: opentelemetry-sdk<2.0.0,>=1.30.0 in /usr/local/lib/python3.12/dist-packages (from strands-agents->-r requirements.txt (line 1)) (1.38.0)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.4.0 in /usr/local/lib/python3.12/dist-packages (from strands-agents->-r requirements.txt (line 1)) (2.11.10)\n",
            "Requirement already satisfied: typing-extensions<5.0.0,>=4.13.2 in /usr/local/lib/python3.12/dist-packages (from strands-agents->-r requirements.txt (line 1)) (4.15.0)\n",
            "Requirement already satisfied: watchdog<7.0.0,>=6.0.0 in /usr/local/lib/python3.12/dist-packages (from strands-agents->-r requirements.txt (line 1)) (6.0.0)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.0 in /usr/local/lib/python3.12/dist-packages (from strands-agents-tools->-r requirements.txt (line 2)) (3.13.2)\n",
            "Requirement already satisfied: aws-requests-auth<0.5.0,>=0.4.3 in /usr/local/lib/python3.12/dist-packages (from strands-agents-tools->-r requirements.txt (line 2)) (0.4.3)\n",
            "Requirement already satisfied: dill<0.5.0,>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from strands-agents-tools->-r requirements.txt (line 2)) (0.4.0)\n",
            "Requirement already satisfied: markdownify<2.0.0,>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from strands-agents-tools->-r requirements.txt (line 2)) (1.2.2)\n",
            "Requirement already satisfied: pillow<12.0.0,>=11.2.1 in /usr/local/lib/python3.12/dist-packages (from strands-agents-tools->-r requirements.txt (line 2)) (11.3.0)\n",
            "Requirement already satisfied: prompt-toolkit<4.0.0,>=3.0.51 in /usr/local/lib/python3.12/dist-packages (from strands-agents-tools->-r requirements.txt (line 2)) (3.0.52)\n",
            "Requirement already satisfied: pyjwt<3.0.0,>=2.10.1 in /usr/local/lib/python3.12/dist-packages (from strands-agents-tools->-r requirements.txt (line 2)) (2.10.1)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.28.0 in /usr/local/lib/python3.12/dist-packages (from strands-agents-tools->-r requirements.txt (line 2)) (2.32.4)\n",
            "Requirement already satisfied: rich<15.0.0,>=14.0.0 in /usr/local/lib/python3.12/dist-packages (from strands-agents-tools->-r requirements.txt (line 2)) (14.2.0)\n",
            "Requirement already satisfied: slack-bolt<2.0.0,>=1.23.0 in /usr/local/lib/python3.12/dist-packages (from strands-agents-tools->-r requirements.txt (line 2)) (1.27.0)\n",
            "Requirement already satisfied: sympy<2.0.0,>=1.12.0 in /usr/local/lib/python3.12/dist-packages (from strands-agents-tools->-r requirements.txt (line 2)) (1.14.0)\n",
            "Requirement already satisfied: tenacity<10.0.0,>=9.1.2 in /usr/local/lib/python3.12/dist-packages (from strands-agents-tools->-r requirements.txt (line 2)) (9.1.2)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.12/dist-packages (from perplexityai->-r requirements.txt (line 3)) (4.11.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.12/dist-packages (from perplexityai->-r requirements.txt (line 3)) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from perplexityai->-r requirements.txt (line 3)) (0.28.1)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.12/dist-packages (from perplexityai->-r requirements.txt (line 3)) (1.3.1)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.0->strands-agents-tools->-r requirements.txt (line 2)) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.0->strands-agents-tools->-r requirements.txt (line 2)) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.0->strands-agents-tools->-r requirements.txt (line 2)) (25.4.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.0->strands-agents-tools->-r requirements.txt (line 2)) (1.8.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.0->strands-agents-tools->-r requirements.txt (line 2)) (6.7.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.0->strands-agents-tools->-r requirements.txt (line 2)) (0.4.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.0->strands-agents-tools->-r requirements.txt (line 2)) (1.22.0)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.12/dist-packages (from anyio<5,>=3.5.0->perplexityai->-r requirements.txt (line 3)) (3.11)\n",
            "Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in /usr/local/lib/python3.12/dist-packages (from boto3<2.0.0,>=1.26.0->strands-agents->-r requirements.txt (line 1)) (1.0.1)\n",
            "Requirement already satisfied: s3transfer<0.16.0,>=0.15.0 in /usr/local/lib/python3.12/dist-packages (from boto3<2.0.0,>=1.26.0->strands-agents->-r requirements.txt (line 1)) (0.15.0)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.12/dist-packages (from botocore<2.0.0,>=1.29.0->strands-agents->-r requirements.txt (line 1)) (2.9.0.post0)\n",
            "Requirement already satisfied: urllib3!=2.2.0,<3,>=1.25.4 in /usr/local/lib/python3.12/dist-packages (from botocore<2.0.0,>=1.29.0->strands-agents->-r requirements.txt (line 1)) (2.5.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->perplexityai->-r requirements.txt (line 3)) (2025.11.12)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->perplexityai->-r requirements.txt (line 3)) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->perplexityai->-r requirements.txt (line 3)) (0.16.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.12/dist-packages (from jsonschema<5.0.0,>=4.0.0->strands-agents->-r requirements.txt (line 1)) (2025.9.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.12/dist-packages (from jsonschema<5.0.0,>=4.0.0->strands-agents->-r requirements.txt (line 1)) (0.37.0)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.12/dist-packages (from jsonschema<5.0.0,>=4.0.0->strands-agents->-r requirements.txt (line 1)) (0.29.0)\n",
            "Requirement already satisfied: beautifulsoup4<5,>=4.9 in /usr/local/lib/python3.12/dist-packages (from markdownify<2.0.0,>=1.0.0->strands-agents-tools->-r requirements.txt (line 2)) (4.13.5)\n",
            "Requirement already satisfied: six<2,>=1.15 in /usr/local/lib/python3.12/dist-packages (from markdownify<2.0.0,>=1.0.0->strands-agents-tools->-r requirements.txt (line 2)) (1.17.0)\n",
            "Requirement already satisfied: httpx-sse>=0.4 in /usr/local/lib/python3.12/dist-packages (from mcp<2.0.0,>=1.11.0->strands-agents->-r requirements.txt (line 1)) (0.4.3)\n",
            "Requirement already satisfied: pydantic-settings>=2.5.2 in /usr/local/lib/python3.12/dist-packages (from mcp<2.0.0,>=1.11.0->strands-agents->-r requirements.txt (line 1)) (2.12.0)\n",
            "Requirement already satisfied: python-multipart>=0.0.9 in /usr/local/lib/python3.12/dist-packages (from mcp<2.0.0,>=1.11.0->strands-agents->-r requirements.txt (line 1)) (0.0.20)\n",
            "Requirement already satisfied: sse-starlette>=1.6.1 in /usr/local/lib/python3.12/dist-packages (from mcp<2.0.0,>=1.11.0->strands-agents->-r requirements.txt (line 1)) (3.0.3)\n",
            "Requirement already satisfied: starlette>=0.27 in /usr/local/lib/python3.12/dist-packages (from mcp<2.0.0,>=1.11.0->strands-agents->-r requirements.txt (line 1)) (0.48.0)\n",
            "Requirement already satisfied: typing-inspection>=0.4.1 in /usr/local/lib/python3.12/dist-packages (from mcp<2.0.0,>=1.11.0->strands-agents->-r requirements.txt (line 1)) (0.4.2)\n",
            "Requirement already satisfied: uvicorn>=0.31.1 in /usr/local/lib/python3.12/dist-packages (from mcp<2.0.0,>=1.11.0->strands-agents->-r requirements.txt (line 1)) (0.38.0)\n",
            "Requirement already satisfied: importlib-metadata<8.8.0,>=6.0 in /usr/local/lib/python3.12/dist-packages (from opentelemetry-api<2.0.0,>=1.30.0->strands-agents->-r requirements.txt (line 1)) (8.7.0)\n",
            "Requirement already satisfied: opentelemetry-instrumentation==0.59b0 in /usr/local/lib/python3.12/dist-packages (from opentelemetry-instrumentation-threading<1.00b0,>=0.51b0->strands-agents->-r requirements.txt (line 1)) (0.59b0)\n",
            "Requirement already satisfied: wrapt<2.0.0,>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from opentelemetry-instrumentation-threading<1.00b0,>=0.51b0->strands-agents->-r requirements.txt (line 1)) (1.17.3)\n",
            "Requirement already satisfied: opentelemetry-semantic-conventions==0.59b0 in /usr/local/lib/python3.12/dist-packages (from opentelemetry-instrumentation==0.59b0->opentelemetry-instrumentation-threading<1.00b0,>=0.51b0->strands-agents->-r requirements.txt (line 1)) (0.59b0)\n",
            "Requirement already satisfied: packaging>=18.0 in /usr/local/lib/python3.12/dist-packages (from opentelemetry-instrumentation==0.59b0->opentelemetry-instrumentation-threading<1.00b0,>=0.51b0->strands-agents->-r requirements.txt (line 1)) (25.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.12/dist-packages (from prompt-toolkit<4.0.0,>=3.0.51->strands-agents-tools->-r requirements.txt (line 2)) (0.2.14)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.4.0->strands-agents->-r requirements.txt (line 1)) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.4.0->strands-agents->-r requirements.txt (line 1)) (2.33.2)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.28.0->strands-agents-tools->-r requirements.txt (line 2)) (3.4.4)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from rich<15.0.0,>=14.0.0->strands-agents-tools->-r requirements.txt (line 2)) (4.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.12/dist-packages (from rich<15.0.0,>=14.0.0->strands-agents-tools->-r requirements.txt (line 2)) (2.19.2)\n",
            "Requirement already satisfied: slack_sdk<4,>=3.38.0 in /usr/local/lib/python3.12/dist-packages (from slack-bolt<2.0.0,>=1.23.0->strands-agents-tools->-r requirements.txt (line 2)) (3.39.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy<2.0.0,>=1.12.0->strands-agents-tools->-r requirements.txt (line 2)) (1.3.0)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.12/dist-packages (from beautifulsoup4<5,>=4.9->markdownify<2.0.0,>=1.0.0->strands-agents-tools->-r requirements.txt (line 2)) (2.8)\n",
            "Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.12/dist-packages (from importlib-metadata<8.8.0,>=6.0->opentelemetry-api<2.0.0,>=1.30.0->strands-agents->-r requirements.txt (line 1)) (3.23.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.12/dist-packages (from markdown-it-py>=2.2.0->rich<15.0.0,>=14.0.0->strands-agents-tools->-r requirements.txt (line 2)) (0.1.2)\n",
            "Requirement already satisfied: python-dotenv>=0.21.0 in /usr/local/lib/python3.12/dist-packages (from pydantic-settings>=2.5.2->mcp<2.0.0,>=1.11.0->strands-agents->-r requirements.txt (line 1)) (1.2.1)\n",
            "Requirement already satisfied: cryptography>=3.4.0 in /usr/local/lib/python3.12/dist-packages (from pyjwt[crypto]>=2.10.1->mcp<2.0.0,>=1.11.0->strands-agents->-r requirements.txt (line 1)) (43.0.3)\n",
            "Requirement already satisfied: click>=7.0 in /usr/local/lib/python3.12/dist-packages (from uvicorn>=0.31.1->mcp<2.0.0,>=1.11.0->strands-agents->-r requirements.txt (line 1)) (8.3.1)\n",
            "Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.12/dist-packages (from cryptography>=3.4.0->pyjwt[crypto]>=2.10.1->mcp<2.0.0,>=1.11.0->strands-agents->-r requirements.txt (line 1)) (2.0.0)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.12/dist-packages (from cffi>=1.12->cryptography>=3.4.0->pyjwt[crypto]>=2.10.1->mcp<2.0.0,>=1.11.0->strands-agents->-r requirements.txt (line 1)) (2.23)\n"
          ]
        }
      ],
      "source": [
        "!pip install -r requirements.txt"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.environ[\"PERPLEXITY_API_KEY\"] = \"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\"\n"
      ],
      "metadata": {
        "id": "CGsRUVY5rlcB"
      },
      "id": "CGsRUVY5rlcB",
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from strands import Agent\n",
        "import importlib\n",
        "import perplexity_model\n",
        "importlib.reload(perplexity_model)\n",
        "from perplexity_model import PerplexityModel\n",
        "\n",
        "model = PerplexityModel(\n",
        "    api_key='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',\n",
        "    model_id='sonar-pro',\n",
        "    params={'max_tokens': 2048, 'temperature': 0.7}\n",
        ")\n",
        "\n",
        "agent = Agent(model=model)\n",
        "response = agent(\"who is the president of the united states\")\n",
        "print(response)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tcuiSLxWtuq6",
        "outputId": "a93aabec-55b6-4e0c-8c28-6935e366004e"
      },
      "id": "tcuiSLxWtuq6",
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The current president of the United States is **Donald J. Trump**, serving as the 47th president since January 20, 2025[6][7][8][4][3][5][2].\n",
            "\n",
            "Donald Trump won the 2024 presidential election and was inaugurated for a second, non-consecutive term, making him both the 45th and 47th president[2][4][6][7][8]. His vice president is JD Vance, and the First Lady is Melania Trump[5][2]. This return to office follows an extraordinary political comeback after losing his reelection bid in 2020 and then winning again in 2024[4].\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9a203754-ecd3-402d-be98-9ee8facc23d9",
      "metadata": {
        "id": "9a203754-ecd3-402d-be98-9ee8facc23d9"
      },
      "source": [
        "### Importing required packages\n",
        "\n",
        "Next we can import the required packages"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "680c68aa-36e9-48e7-a3ed-9d2e63a3b95c",
      "metadata": {
        "id": "680c68aa-36e9-48e7-a3ed-9d2e63a3b95c"
      },
      "outputs": [],
      "source": [
        "from strands import Agent\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cb3b24d8-69d5-496d-92a5-24ff8705de1c",
      "metadata": {
        "id": "cb3b24d8-69d5-496d-92a5-24ff8705de1c"
      },
      "source": [
        "## Understanding Agent Graph Components\n",
        "An agent graph is a structured network of interconnected AI agents designed to solve complex problems through coordinated collaboration. Each agent represents a specialized node with specific capabilities, and the connections between agents define explicit communication pathways.\n",
        "\n",
        "Before we start building, let's understand the three primary components of an agent graph:\n",
        "\n",
        "### 1. Nodes (Agents)\n",
        "Each node represents an AI agent with:\n",
        "- **Identity**: Unique identifier within the graph\n",
        "- **Role**: Specialized function or purpose\n",
        "- **System Prompt**: Instructions defining the agent's behavior\n",
        "- **Tools**: Capabilities available to the agent\n",
        "\n",
        "### 2. Edges (Connections)\n",
        "Edges define communication pathways with:\n",
        "- **Direction**: One-way or bidirectional information flow\n",
        "- **Condition**: Optional function that determines if the edge should be traversed\n",
        "- **Dependencies**: Define execution order and data flow between nodes\n",
        "\n",
        "### 3. GraphBuilder\n",
        "The GraphBuilder provides a simple interface for constructing graphs:\n",
        "- **add_node()**: Add an agent or multi-agent system as a node\n",
        "- **add_edge()**: Create a dependency between nodes\n",
        "- **set_entry_point()**: Define starting nodes for execution\n",
        "- **build()**: Validate and create the Graph instance\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "80c47290-ef84-4ab5-ad14-70d41f0ed40b",
      "metadata": {
        "id": "80c47290-ef84-4ab5-ad14-70d41f0ed40b"
      },
      "source": [
        "### Basic processing\n",
        "\n",
        "Let's start with a simple example of one task processed by two different agents providing an output that will depend on their defined role. Take a look at the execution order of the nodes and also the fact that with STrands SDK you can explicitly get a response only from one single node if needed. Architecture looks as following:\n",
        "\n",
        "<div style=\"text-align:left\">\n",
        "    <img src=\"https://github.com/strands-agents/samples/blob/main/01-tutorials/02-multi-agent-systems/03-graph-agent/images/basic.png?raw=1\" width=\"55%\" />\n",
        "</div>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 88,
      "id": "eba5fc53-8eca-46e8-84cf-9ca0f551140d",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eba5fc53-8eca-46e8-84cf-9ca0f551140d",
        "outputId": "5ae7fa88-342d-4690-d13d-a793bcff3149"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:strands.multiagent.graph:Graph without execution limits may run indefinitely if cycles exist\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Remote work has generally led to **stable or increased employee productivity**, with multiple large-scale studies reporting measurable gains compared to traditional office settings[1][3][5][6][7]. However, the impact varies depending on individual circumstances, job types, and how challenges associated with remote work are managed[2][3][10].\n",
            "\n",
            "Key points:\n",
            "\n",
            "- **Increased Productivity**: Multiple studies—including a two-year study of 800,000 employees and research by Stanford—found remote workers are up to 47% more productive, with some reporting a 13% increase in performance[1][3][6]. Factors include fewer distractions, reduced commute times, and the ability to work during peak productivity hours[1][2][3][5][6].\n",
            "  \n",
            "- **Improved Engagement and Satisfaction**: Remote work is associated with higher engagement and job satisfaction, which can reduce turnover and hiring costs for organizations[3][5][6][7].\n",
            "  \n",
            "- **Potential Drawbacks**: Challenges such as **isolation, communication barriers, and blurred work-life boundaries** can negatively affect productivity if not addressed[2][5][7][10]. Some studies note that fully remote work can sometimes lead to lower well-being despite higher engagement[5].\n",
            "\n",
            "- **Variability by Context**: The productivity impact of remote work depends on task type, technology availability, home environment, and management practices[3][10][11]. For most knowledge-based roles, the benefits are more pronounced.\n",
            "\n",
            "- **Sustainability**: Evidence suggests that sustained or improved productivity is possible when remote work transitions are well-planned and supported, rather than abrupt[7].\n",
            "\n",
            "Overall, **remote work tends to enhance productivity when employees are given autonomy, flexibility, and the right technological and social support**, but organizations need to address the associated risks to maximize long-term benefits[2][5][7][10].Remote work has generally had a **neutral to positive impact on employee productivity**, with many studies reporting stable or increased output, though the effects vary across roles, industries, and individual circumstances[1][2][3][5][7][8].\n",
            "\n",
            "Key findings:\n",
            "- **Productivity Stability or Increase:** Multiple large-scale studies and firm-level experiments show that productivity remained steady or improved after the shift to remote work, especially among knowledge workers[1][3][5][7]. For example, a Gallup analysis found output per worker slightly increased post-pandemic, even as remote employees worked fewer hours[1].\n",
            "- **Efficiency Gains:** Remote work eliminates commuting and allows employees to work during their most productive hours, which can boost efficiency and job satisfaction[2][7][12]. Some sources report remote employees are 35–40% more productive and make 40% fewer mistakes than office-based peers[7].\n",
            "- **Job Satisfaction and Retention:** Increased autonomy in remote setups has led to higher engagement and lower turnover, reducing hiring costs for firms[3][5].\n",
            "- **Challenges:** Productivity gains are not universal. Some studies found declines, particularly where remote work was poorly managed, or in roles needing close coordination or mentoring[4][6][9]. Common obstacles include isolation, communication barriers, and home distractions[2][4][8].\n",
            "- **Well-being Risks:** Despite higher engagement, fully remote workers often report greater stress and loneliness, which may threaten long-term performance if not addressed[5]. \n",
            "\n",
            "In summary, **remote work can support or enhance productivity when organizations implement clear goals, strong communication practices, and address well-being**. The impact is most positive for autonomous, knowledge-based roles, and where employees have supportive home environments and reliable technology[2][3][5][6][7].Remote work has generally led to a modest increase in employee productivity, especially for roles that benefit from autonomy and flexibility, although results vary depending on job type, individual circumstances, and management practices[1][2][3][4][7].\n",
            "\n",
            "Key factors contributing to **increased productivity** include:\n",
            "- **Reduced commuting time**, allowing employees to allocate more time and energy to work tasks[2][7].\n",
            "- **Fewer workplace distractions** for many roles, particularly knowledge workers, enabling better focus and output[4][6].\n",
            "- **Flexible scheduling**, which lets employees align work hours with their personal peak productivity periods[4][8].\n",
            "- **Higher engagement** and willingness to put in extra effort, particularly in high-trust organizations and among fully remote workers[3][7].\n",
            "\n",
            "However, there are notable **challenges and negative impacts**:\n",
            "- **Isolation and reduced social interaction** can decrease motivation and well-being, increasing risks of loneliness and stress, even as engagement rises[2][3][4][5].\n",
            "- **Home distractions** (family, chores) and **difficulty separating work from personal life** can reduce productivity for some employees[2][4].\n",
            "- **Communication barriers** and reduced mentoring opportunities can hinder collaboration, especially for teams that rely on frequent, spontaneous interaction[2][11].\n",
            "- **Variability across roles**: Individual contributors often report productivity gains, while managers and those in roles needing close coordination may face declines[4][6].\n",
            "\n",
            "On an organizational level, increased remote work was associated with higher industry-level productivity growth during the pandemic, as well as lower turnover and improved job satisfaction, which can reduce hiring costs[1][13]. Productivity gains are highest when organizations invest in effective digital collaboration tools, foster clear communication, and support employee well-being[4][10].\n",
            "\n",
            "In summary, **remote work tends to improve productivity for many employees**, particularly when supported by strong management and digital infrastructure, but outcomes are highly dependent on both individual and organizational factors[1][2][3][4][7][11].\n",
            "\n",
            "============================================================\n",
            "============================================================\n",
            "Response: GraphResult(status=<Status.COMPLETED: 'completed'>, results={'team_lead': NodeResult(result=AgentResult(stop_reason='end_turn', message={'role': 'assistant', 'content': []}, metrics=EventLoopMetrics(cycle_count=1, tool_metrics={}, cycle_durations=[12.1866614818573], traces=[<strands.telemetry.metrics.Trace object at 0x7fa5a1b990a0>], accumulated_usage={'inputTokens': 0, 'outputTokens': 0, 'totalTokens': 0}, accumulated_metrics={'latencyMs': 0}), state={}, interrupts=None, structured_output=None), execution_time=12187, status=<Status.COMPLETED: 'completed'>, accumulated_usage={'inputTokens': 0, 'outputTokens': 0, 'totalTokens': 0}, accumulated_metrics={'latencyMs': 0}, execution_count=1), 'analyst': NodeResult(result=AgentResult(stop_reason='end_turn', message={'role': 'assistant', 'content': []}, metrics=EventLoopMetrics(cycle_count=1, tool_metrics={}, cycle_durations=[11.795153141021729], traces=[<strands.telemetry.metrics.Trace object at 0x7fa5a1b9aa50>], accumulated_usage={'inputTokens': 0, 'outputTokens': 0, 'totalTokens': 0}, accumulated_metrics={'latencyMs': 0}), state={}, interrupts=None, structured_output=None), execution_time=11796, status=<Status.COMPLETED: 'completed'>, accumulated_usage={'inputTokens': 0, 'outputTokens': 0, 'totalTokens': 0}, accumulated_metrics={'latencyMs': 0}, execution_count=1), 'expert': NodeResult(result=AgentResult(stop_reason='end_turn', message={'role': 'assistant', 'content': []}, metrics=EventLoopMetrics(cycle_count=1, tool_metrics={}, cycle_durations=[12.11189866065979], traces=[<strands.telemetry.metrics.Trace object at 0x7fa5a1b9a690>], accumulated_usage={'inputTokens': 0, 'outputTokens': 0, 'totalTokens': 0}, accumulated_metrics={'latencyMs': 0}), state={}, interrupts=None, structured_output=None), execution_time=12112, status=<Status.COMPLETED: 'completed'>, accumulated_usage={'inputTokens': 0, 'outputTokens': 0, 'totalTokens': 0}, accumulated_metrics={'latencyMs': 0}, execution_count=1)}, accumulated_usage={'inputTokens': 0, 'outputTokens': 0, 'totalTokens': 0}, accumulated_metrics={'latencyMs': 0}, execution_count=3, execution_time=0, total_nodes=3, completed_nodes=3, failed_nodes=0, execution_order=[GraphNode(node_id='team_lead', executor=<strands.agent.agent.Agent object at 0x7fa5b2bb07d0>, dependencies=set(), execution_status=<Status.COMPLETED: 'completed'>, result=NodeResult(result=AgentResult(stop_reason='end_turn', message={'role': 'assistant', 'content': []}, metrics=EventLoopMetrics(cycle_count=1, tool_metrics={}, cycle_durations=[12.1866614818573], traces=[<strands.telemetry.metrics.Trace object at 0x7fa5a1b990a0>], accumulated_usage={'inputTokens': 0, 'outputTokens': 0, 'totalTokens': 0}, accumulated_metrics={'latencyMs': 0}), state={}, interrupts=None, structured_output=None), execution_time=12187, status=<Status.COMPLETED: 'completed'>, accumulated_usage={'inputTokens': 0, 'outputTokens': 0, 'totalTokens': 0}, accumulated_metrics={'latencyMs': 0}, execution_count=1), execution_time=12187, _initial_messages=[], _initial_state=<strands.agent.state.AgentState object at 0x7fa5a1b99c70>), GraphNode(node_id='analyst', executor=<strands.agent.agent.Agent object at 0x7fa5b0a3bc80>, dependencies={GraphNode(node_id='team_lead', executor=<strands.agent.agent.Agent object at 0x7fa5b2bb07d0>, dependencies=set(), execution_status=<Status.COMPLETED: 'completed'>, result=NodeResult(result=AgentResult(stop_reason='end_turn', message={'role': 'assistant', 'content': []}, metrics=EventLoopMetrics(cycle_count=1, tool_metrics={}, cycle_durations=[12.1866614818573], traces=[<strands.telemetry.metrics.Trace object at 0x7fa5a1b990a0>], accumulated_usage={'inputTokens': 0, 'outputTokens': 0, 'totalTokens': 0}, accumulated_metrics={'latencyMs': 0}), state={}, interrupts=None, structured_output=None), execution_time=12187, status=<Status.COMPLETED: 'completed'>, accumulated_usage={'inputTokens': 0, 'outputTokens': 0, 'totalTokens': 0}, accumulated_metrics={'latencyMs': 0}, execution_count=1), execution_time=12187, _initial_messages=[], _initial_state=<strands.agent.state.AgentState object at 0x7fa5a1b99c70>)}, execution_status=<Status.COMPLETED: 'completed'>, result=NodeResult(result=AgentResult(stop_reason='end_turn', message={'role': 'assistant', 'content': []}, metrics=EventLoopMetrics(cycle_count=1, tool_metrics={}, cycle_durations=[11.795153141021729], traces=[<strands.telemetry.metrics.Trace object at 0x7fa5a1b9aa50>], accumulated_usage={'inputTokens': 0, 'outputTokens': 0, 'totalTokens': 0}, accumulated_metrics={'latencyMs': 0}), state={}, interrupts=None, structured_output=None), execution_time=11796, status=<Status.COMPLETED: 'completed'>, accumulated_usage={'inputTokens': 0, 'outputTokens': 0, 'totalTokens': 0}, accumulated_metrics={'latencyMs': 0}, execution_count=1), execution_time=11796, _initial_messages=[], _initial_state=<strands.agent.state.AgentState object at 0x7fa5a1b9bc50>), GraphNode(node_id='expert', executor=<strands.agent.agent.Agent object at 0x7fa5a24d5160>, dependencies={GraphNode(node_id='team_lead', executor=<strands.agent.agent.Agent object at 0x7fa5b2bb07d0>, dependencies=set(), execution_status=<Status.COMPLETED: 'completed'>, result=NodeResult(result=AgentResult(stop_reason='end_turn', message={'role': 'assistant', 'content': []}, metrics=EventLoopMetrics(cycle_count=1, tool_metrics={}, cycle_durations=[12.1866614818573], traces=[<strands.telemetry.metrics.Trace object at 0x7fa5a1b990a0>], accumulated_usage={'inputTokens': 0, 'outputTokens': 0, 'totalTokens': 0}, accumulated_metrics={'latencyMs': 0}), state={}, interrupts=None, structured_output=None), execution_time=12187, status=<Status.COMPLETED: 'completed'>, accumulated_usage={'inputTokens': 0, 'outputTokens': 0, 'totalTokens': 0}, accumulated_metrics={'latencyMs': 0}, execution_count=1), execution_time=12187, _initial_messages=[], _initial_state=<strands.agent.state.AgentState object at 0x7fa5a1b99c70>)}, execution_status=<Status.COMPLETED: 'completed'>, result=NodeResult(result=AgentResult(stop_reason='end_turn', message={'role': 'assistant', 'content': []}, metrics=EventLoopMetrics(cycle_count=1, tool_metrics={}, cycle_durations=[12.11189866065979], traces=[<strands.telemetry.metrics.Trace object at 0x7fa5a1b9a690>], accumulated_usage={'inputTokens': 0, 'outputTokens': 0, 'totalTokens': 0}, accumulated_metrics={'latencyMs': 0}), state={}, interrupts=None, structured_output=None), execution_time=12112, status=<Status.COMPLETED: 'completed'>, accumulated_usage={'inputTokens': 0, 'outputTokens': 0, 'totalTokens': 0}, accumulated_metrics={'latencyMs': 0}, execution_count=1), execution_time=12112, _initial_messages=[], _initial_state=<strands.agent.state.AgentState object at 0x7fa5a1b9a090>)], edges=[(GraphNode(node_id='team_lead', executor=<strands.agent.agent.Agent object at 0x7fa5b2bb07d0>, dependencies=set(), execution_status=<Status.COMPLETED: 'completed'>, result=NodeResult(result=AgentResult(stop_reason='end_turn', message={'role': 'assistant', 'content': []}, metrics=EventLoopMetrics(cycle_count=1, tool_metrics={}, cycle_durations=[12.1866614818573], traces=[<strands.telemetry.metrics.Trace object at 0x7fa5a1b990a0>], accumulated_usage={'inputTokens': 0, 'outputTokens': 0, 'totalTokens': 0}, accumulated_metrics={'latencyMs': 0}), state={}, interrupts=None, structured_output=None), execution_time=12187, status=<Status.COMPLETED: 'completed'>, accumulated_usage={'inputTokens': 0, 'outputTokens': 0, 'totalTokens': 0}, accumulated_metrics={'latencyMs': 0}, execution_count=1), execution_time=12187, _initial_messages=[], _initial_state=<strands.agent.state.AgentState object at 0x7fa5a1b99c70>), GraphNode(node_id='analyst', executor=<strands.agent.agent.Agent object at 0x7fa5b0a3bc80>, dependencies={GraphNode(node_id='team_lead', executor=<strands.agent.agent.Agent object at 0x7fa5b2bb07d0>, dependencies=set(), execution_status=<Status.COMPLETED: 'completed'>, result=NodeResult(result=AgentResult(stop_reason='end_turn', message={'role': 'assistant', 'content': []}, metrics=EventLoopMetrics(cycle_count=1, tool_metrics={}, cycle_durations=[12.1866614818573], traces=[<strands.telemetry.metrics.Trace object at 0x7fa5a1b990a0>], accumulated_usage={'inputTokens': 0, 'outputTokens': 0, 'totalTokens': 0}, accumulated_metrics={'latencyMs': 0}), state={}, interrupts=None, structured_output=None), execution_time=12187, status=<Status.COMPLETED: 'completed'>, accumulated_usage={'inputTokens': 0, 'outputTokens': 0, 'totalTokens': 0}, accumulated_metrics={'latencyMs': 0}, execution_count=1), execution_time=12187, _initial_messages=[], _initial_state=<strands.agent.state.AgentState object at 0x7fa5a1b99c70>)}, execution_status=<Status.COMPLETED: 'completed'>, result=NodeResult(result=AgentResult(stop_reason='end_turn', message={'role': 'assistant', 'content': []}, metrics=EventLoopMetrics(cycle_count=1, tool_metrics={}, cycle_durations=[11.795153141021729], traces=[<strands.telemetry.metrics.Trace object at 0x7fa5a1b9aa50>], accumulated_usage={'inputTokens': 0, 'outputTokens': 0, 'totalTokens': 0}, accumulated_metrics={'latencyMs': 0}), state={}, interrupts=None, structured_output=None), execution_time=11796, status=<Status.COMPLETED: 'completed'>, accumulated_usage={'inputTokens': 0, 'outputTokens': 0, 'totalTokens': 0}, accumulated_metrics={'latencyMs': 0}, execution_count=1), execution_time=11796, _initial_messages=[], _initial_state=<strands.agent.state.AgentState object at 0x7fa5a1b9bc50>)), (GraphNode(node_id='team_lead', executor=<strands.agent.agent.Agent object at 0x7fa5b2bb07d0>, dependencies=set(), execution_status=<Status.COMPLETED: 'completed'>, result=NodeResult(result=AgentResult(stop_reason='end_turn', message={'role': 'assistant', 'content': []}, metrics=EventLoopMetrics(cycle_count=1, tool_metrics={}, cycle_durations=[12.1866614818573], traces=[<strands.telemetry.metrics.Trace object at 0x7fa5a1b990a0>], accumulated_usage={'inputTokens': 0, 'outputTokens': 0, 'totalTokens': 0}, accumulated_metrics={'latencyMs': 0}), state={}, interrupts=None, structured_output=None), execution_time=12187, status=<Status.COMPLETED: 'completed'>, accumulated_usage={'inputTokens': 0, 'outputTokens': 0, 'totalTokens': 0}, accumulated_metrics={'latencyMs': 0}, execution_count=1), execution_time=12187, _initial_messages=[], _initial_state=<strands.agent.state.AgentState object at 0x7fa5a1b99c70>), GraphNode(node_id='expert', executor=<strands.agent.agent.Agent object at 0x7fa5a24d5160>, dependencies={GraphNode(node_id='team_lead', executor=<strands.agent.agent.Agent object at 0x7fa5b2bb07d0>, dependencies=set(), execution_status=<Status.COMPLETED: 'completed'>, result=NodeResult(result=AgentResult(stop_reason='end_turn', message={'role': 'assistant', 'content': []}, metrics=EventLoopMetrics(cycle_count=1, tool_metrics={}, cycle_durations=[12.1866614818573], traces=[<strands.telemetry.metrics.Trace object at 0x7fa5a1b990a0>], accumulated_usage={'inputTokens': 0, 'outputTokens': 0, 'totalTokens': 0}, accumulated_metrics={'latencyMs': 0}), state={}, interrupts=None, structured_output=None), execution_time=12187, status=<Status.COMPLETED: 'completed'>, accumulated_usage={'inputTokens': 0, 'outputTokens': 0, 'totalTokens': 0}, accumulated_metrics={'latencyMs': 0}, execution_count=1), execution_time=12187, _initial_messages=[], _initial_state=<strands.agent.state.AgentState object at 0x7fa5a1b99c70>)}, execution_status=<Status.COMPLETED: 'completed'>, result=NodeResult(result=AgentResult(stop_reason='end_turn', message={'role': 'assistant', 'content': []}, metrics=EventLoopMetrics(cycle_count=1, tool_metrics={}, cycle_durations=[12.11189866065979], traces=[<strands.telemetry.metrics.Trace object at 0x7fa5a1b9a690>], accumulated_usage={'inputTokens': 0, 'outputTokens': 0, 'totalTokens': 0}, accumulated_metrics={'latencyMs': 0}), state={}, interrupts=None, structured_output=None), execution_time=12112, status=<Status.COMPLETED: 'completed'>, accumulated_usage={'inputTokens': 0, 'outputTokens': 0, 'totalTokens': 0}, accumulated_metrics={'latencyMs': 0}, execution_count=1), execution_time=12112, _initial_messages=[], _initial_state=<strands.agent.state.AgentState object at 0x7fa5a1b9a090>))], entry_points=[GraphNode(node_id='team_lead', executor=<strands.agent.agent.Agent object at 0x7fa5b2bb07d0>, dependencies=set(), execution_status=<Status.COMPLETED: 'completed'>, result=NodeResult(result=AgentResult(stop_reason='end_turn', message={'role': 'assistant', 'content': []}, metrics=EventLoopMetrics(cycle_count=1, tool_metrics={}, cycle_durations=[12.1866614818573], traces=[<strands.telemetry.metrics.Trace object at 0x7fa5a1b990a0>], accumulated_usage={'inputTokens': 0, 'outputTokens': 0, 'totalTokens': 0}, accumulated_metrics={'latencyMs': 0}), state={}, interrupts=None, structured_output=None), execution_time=12187, status=<Status.COMPLETED: 'completed'>, accumulated_usage={'inputTokens': 0, 'outputTokens': 0, 'totalTokens': 0}, accumulated_metrics={'latencyMs': 0}, execution_count=1), execution_time=12187, _initial_messages=[], _initial_state=<strands.agent.state.AgentState object at 0x7fa5a1b99c70>)])\n",
            "=============Node execution order:==========================\n",
            "============================================================\n",
            "Executed: team_lead\n",
            "Executed: analyst\n",
            "Executed: expert\n",
            "=============Graph metrics:=================================\n",
            "============================================================\n",
            "Total nodes: 3\n",
            "Completed nodes: 3\n",
            "Failed nodes: 0\n",
            "Execution time: 0ms\n",
            "Token usage: {'inputTokens': 0, 'outputTokens': 0, 'totalTokens': 0}\n",
            "\n",
            "\n",
            "=============Expert node results only:======================\n",
            "============================================================\n",
            "\n"
          ]
        }
      ],
      "source": [
        "#Initialize an agent with agent_graph capability\n",
        "from strands.multiagent import GraphBuilder\n",
        "\n",
        "# Create specialized agents\n",
        "coordinator = Agent(model=model, name=\"coordinator\", system_prompt=\"You are a research team leader coordinating specialists. Provide a short analysis, no need for follow ups\")\n",
        "analyst = Agent(model=model, name=\"data_analyst\", system_prompt=\"You are a data analyst specializing in statistical analysis. Provide a short analysis, no need for follow ups\")\n",
        "domain_expert = Agent(model=model,name=\"domain_expert\", system_prompt=\"You are a domain expert with deep subject knowledge. Provide a short analysis, no need for follow ups\")\n",
        "\n",
        "# Build the graph\n",
        "builder = GraphBuilder()\n",
        "\n",
        "# Add nodes\n",
        "builder.add_node(coordinator, \"team_lead\")\n",
        "builder.add_node(analyst, \"analyst\")\n",
        "builder.add_node(domain_expert, \"expert\")\n",
        "\n",
        "# Add edges (dependencies)\n",
        "builder.add_edge(\"team_lead\", \"analyst\")\n",
        "builder.add_edge(\"team_lead\", \"expert\")\n",
        "\n",
        "# Set entry points (optional - will be auto-detected if not specified)\n",
        "builder.set_entry_point(\"team_lead\")\n",
        "\n",
        "# Build the graph\n",
        "graph = builder.build()\n",
        "\n",
        "#Execute task on newly built graph\n",
        "result = graph(\"Analyze the impact of remote work on employee productivity.Provide a short analysis, no need for follow ups\")\n",
        "print(\"\\n\")\n",
        "print(\"============================================================\")\n",
        "print(\"============================================================\")\n",
        "\n",
        "print(f\"Response: {result}\")\n",
        "\n",
        "print(\"=============Node execution order:==========================\")\n",
        "print(\"============================================================\")\n",
        "\n",
        "# See which nodes were executed and in what order\n",
        "for node in result.execution_order:\n",
        "    print(f\"Executed: {node.node_id}\")\n",
        "\n",
        "print(\"=============Graph metrics:=================================\")\n",
        "print(\"============================================================\")\n",
        "\n",
        "\n",
        "# Get performance metrics\n",
        "print(f\"Total nodes: {result.total_nodes}\")\n",
        "print(f\"Completed nodes: {result.completed_nodes}\")\n",
        "print(f\"Failed nodes: {result.failed_nodes}\")\n",
        "print(f\"Execution time: {result.execution_time}ms\")\n",
        "print(f\"Token usage: {result.accumulated_usage}\")\n",
        "\n",
        "\n",
        "# Get results from specific nodes\n",
        "print(\"\\n\")\n",
        "print(\"=============Expert node results only:======================\")\n",
        "print(\"============================================================\")\n",
        "print(result.results[\"expert\"].result)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "de57dc8d-d748-4dc4-8380-ed789ba84d6b",
      "metadata": {
        "id": "de57dc8d-d748-4dc4-8380-ed789ba84d6b"
      },
      "source": [
        "### Parallel processing\n",
        "\n",
        "Now let's create a topology when we will have 2 agents processing the request looking at 2 different aspect  of the problem and have them input into a final agent responsible for summarization and risk calculation based on provided input\n",
        "<div style=\"text-align:left\">\n",
        "    <img src=\"https://github.com/strands-agents/samples/blob/main/01-tutorials/02-multi-agent-systems/03-graph-agent/images/parallel.png?raw=1\" width=\"55%\" />\n",
        "</div>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 86,
      "id": "7926cfeb-90c1-48cb-8d61-850ade47aebf",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7926cfeb-90c1-48cb-8d61-850ade47aebf",
        "outputId": "9ecf142e-5101-47b5-b031-5098620e0c0a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<>:39: SyntaxWarning: invalid escape sequence '\\$'\n",
            "<>:39: SyntaxWarning: invalid escape sequence '\\$'\n",
            "/tmp/ipython-input-489448519.py:39: SyntaxWarning: invalid escape sequence '\\$'\n",
            "  result = graph(\"Our company is considering launching a new AI-powered customer service platform. Initial investment is \\$2M with projected 3-year ROI of 150%. What's your financial assessment?\")\n",
            "WARNING:strands.multiagent.graph:Graph without execution limits may run indefinitely if cycles exist\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================================================\n",
            "============================================================\n",
            "Based on a projected **3-year ROI of 150%** on a **$2 million initial investment**, your company could expect a **net gain of $3 million** over three years, resulting in a total return of $5 million (\\$2M initial + \\$3M net gain)[2][5]. This is considered a **strong ROI for AI-powered customer service platforms** and aligns with or slightly exceeds industry benchmarks[2][4].\n",
            "\n",
            "**Key financial considerations:**\n",
            "\n",
            "- **ROI Calculation:**  \n",
            "  ROI = \\(\\frac{\\text{Net Gain}}{\\text{Initial Investment}} \\times 100\\)  \n",
            "  Here, Net Gain = \\$3M, Initial Investment = \\$2M, so ROI = (\\$3M / \\$2M) × 100 = 150%[2].\n",
            "\n",
            "- **Industry Benchmarks:**  \n",
            "  Typical 3-year ROI figures for AI customer service range from **148% to over 200%**, with some studies reporting average ROIs of **300–500%** for well-implemented solutions[2][4]. Your projected ROI is robust and competitive.\n",
            "\n",
            "- **Break-even and Payback:**  \n",
            "  With a 150% ROI over three years, your investment is projected to break even before the three-year mark, after which all gains contribute directly to profit[2].\n",
            "\n",
            "- **Cost Savings:**  \n",
            "  Major contributors to ROI include **labor cost reduction**, **faster resolution times**, and **increased customer retention** due to improved service[1][3][5].\n",
            "\n",
            "- **Risk and Sensitivity:**  \n",
            "  ROI projections depend on assumptions about adoption rates, actual operational savings, maintenance costs, and customer satisfaction improvements. It is recommended to **run sensitivity analyses** to test ROI under various scenarios and ensure robustness[2][6].\n",
            "\n",
            "- **Strategic Value:**  \n",
            "  Beyond quantified returns, benefits such as **scalability**, **improved customer experience**, and **process insights** can further enhance long-term value, though these may be harder to monetize directly[1][9].\n",
            "\n",
            "**Recommendation:**  \n",
            "The financial outlook is favorable if your assumptions hold. Ensure detailed tracking of **all cost components** (implementation, training, maintenance) and **quantify both direct and indirect benefits** (cost savings, revenue uplift, retention). Collaborate with your finance team to validate assumptions and conduct sensitivity and break-even analyses for a comprehensive risk assessment[6][12].\n",
            "\n",
            "If your business context supports the projected ROI, this investment appears justifiable and potentially strategic for long-term growth.The projected 3-year ROI of **150%** on a **\\$2M investment** in an AI-powered customer service platform is strong, significantly exceeding industry benchmarks, and signals a financially attractive opportunity assuming the projections are credible and risks are managed.\n",
            "\n",
            "Key financial assessment:\n",
            "\n",
            "- **ROI Calculation**: The standard ROI formula is:\n",
            "  \\[  \\text{ROI} = \\frac{\\text{Net Gain}}{\\text{Investment}} \\times 100\\%\n",
            "  \\]\n",
            "  For your case:\n",
            "  - Net Gain over 3 years = \\$2M × 1.5 = \\$3M\n",
            "  - Total Return after 3 years = Initial \\$2M + \\$3M gain = \\$5M\n",
            "  - ROI = (\\$5M - \\$2M) / \\$2M × 100% = 150%[3].\n",
            "\n",
            "- **Industry Benchmarks**: Recent studies and industry calculators indicate that average returns on AI-powered customer service projects range from **$3.50 up to $8.00** for every $1 invested, with some reporting ROIs of **60–2,100%** depending on specific use cases, scale, and efficiency improvements[3][4].\n",
            "    - A 150% ROI over 3 years (or 50% annualized, if returns are even) sits at the upper-middle range for serious enterprise deployments, suggesting the projections are ambitious but within plausible bounds for a well-executed rollout[3][4].\n",
            "\n",
            "- **Financial Drivers**: High ROI in AI customer service typically comes from:\n",
            "  - **Reduction in labor costs**: AI handles routine queries, reducing need for human agents.\n",
            "  - **Cost per interaction** drops significantly, with reported contact center cost reductions up to 60% in some cases[3][4].\n",
            "  - **Customer retention and satisfaction** often improve, boosting long-term revenue and customer lifetime value[4].\n",
            "  - **Operational efficiencies**: AI increases resolution speed and reduces escalation rates[4].\n",
            "  - **Scalability**: AI enables support to scale with minimal incremental cost[5].\n",
            "\n",
            "- **Caveats & Risks**:\n",
            "  - **Upfront and ongoing costs**: Ensure all costs (integration, licensing, training, maintenance) are included in the ROI calculation[1][3].\n",
            "  - **Adoption curve and change management**: Efficiency gains are highest with strong adoption and process alignment[2].\n",
            "  - **Variability**: Model potential downside scenarios (e.g., underperformance, integration delays, or lower adoption), as actual results often vary from projections[2].\n",
            "  - **Non-financial benefits**: Intangible gains, such as improved data for analytics or increased brand loyalty, may not be fully captured in ROI but are strategically valuable[1][2].\n",
            "\n",
            "- **Recommendations**:\n",
            "  - Validate the ROI assumptions using detailed modeling, including conservative, base, and optimistic scenarios[2].\n",
            "  - Track key KPIs post-launch: cost per interaction, agent productivity, CSAT, and customer retention[4][5].\n",
            "  - Use ROI calculators and scenario analysis tools to refine projections as real data emerges[6][7][9].\n",
            "\n",
            "A projected 150% ROI on a \\$2M AI customer service investment is robust, but your financial assessment should include scenario analysis and risk evaluation to ensure projections are realistic and achievable[2][3][4].The projected **3-year ROI of 150%** on an initial **$2M investment** in your AI-powered customer service platform indicates a strong financial case, with an expected return of $3M (your $2M principal plus $3M profit, totaling $5M) over three years[3][4][6]. This level of ROI is competitive and aligns with common industry benchmarks for successful AI customer service deployments.\n",
            "\n",
            "**Key financial assessment points:**\n",
            "\n",
            "- **ROI Calculation:** ROI is typically calculated as \\((\\text{Total Return} - \\text{Investment}) / \\text{Investment} \\times 100\\)[3]. Here: \\((5M - 2M) / 2M \\times 100 = 150\\%\\).\n",
            "- **Payback Period:** With a 150% ROI over three years, your payback period will be less than the full term. Specifically, you'll recover your initial capital and additional profit within three years, which is considered attractive for enterprise technology investments[3][6].\n",
            "- **Industry Benchmarks:** Case studies and models show annualized ROIs ranging from 100% to over 1000% for best-in-class AI customer service deployments, though these high numbers often reflect aggressive automation, cost savings, and rapid scaling[6]. A 150% ROI over three years is realistic and prudent, indicating a balanced, achievable target[3][4].\n",
            "- **Benefits Realized:** Most ROI in AI customer service comes from:\n",
            "  - Reduced operational costs (fewer agents needed, faster resolution)[5].\n",
            "  - Improved customer satisfaction and retention (higher lifetime value)[5].\n",
            "  - Increased automation and ticket deflection (lower cost per ticket)[6][9].\n",
            "\n",
            "**Other critical considerations:**\n",
            "\n",
            "- **Comprehensive Costing:** Ensure your model includes all relevant costs: software, integration, training, ongoing support, and change management[2][4].\n",
            "- **Scenario Analysis:** Test your ROI model against best-case, expected, and worst-case scenarios to understand possible variability in returns, especially given the evolving nature of AI technologies[2].\n",
            "- **Strategic Fit:** Evaluate qualitative benefits such as improved customer experience, competitive differentiation, and scalability, which can drive value beyond direct financial returns[2][4][5].\n",
            "\n",
            "**Summary:**  \n",
            "A 150% ROI over three years on a $2M investment is financially favorable and compares well to industry benchmarks for AI-powered customer service platforms. Ensure that your projections are conservative, include all costs, and validate through scenario analysis and ongoing measurement to maximize your likelihood of success[3][4][6].Based on an initial investment of **$2 million** and a projected 3-year ROI of **150%**, the financial outlook for launching an AI-powered customer service platform is highly attractive, assuming projections are realistic and risks are managed.\n",
            "\n",
            "**Key Financial Assessment:**\n",
            "\n",
            "- **ROI Calculation:**  \n",
            "  ROI is calculated as \\(\\text{ROI} = \\frac{\\text{Net Gain}}{\\text{Investment}} \\times 100\\).  \n",
            "  A 150% ROI on $2 million over 3 years means your expected net gain is $3 million (i.e., $2M initial investment returns a total of $5M after 3 years: $2M original + $3M profit)[5][3].\n",
            "\n",
            "- **Annualized Return:**  \n",
            "  Over 3 years, this translates to an annualized return of approximately 35% per year, which is strong for enterprise technology investments.\n",
            "\n",
            "- **Industry Benchmarks:**  \n",
            "  Customer service AI is producing some of the highest ROI figures in enterprise tech, with:\n",
            "  - Productivity gains (e.g., up to 52% reduction in case handling time, significant call deflection, and cost savings)[6][1].\n",
            "  - Some top performers report up to **8× ROI** in mature deployments[8].\n",
            "\n",
            "- **Key Value Drivers:**\n",
            "  - **Cost Reductions:** Automation reduces labor and training costs, cuts overtime, and increases agent productivity[1][6][3].\n",
            "  - **Revenue Increases:** Enhanced customer satisfaction and retention can drive repeat business and referrals[1][3].\n",
            "  - **Scalability:** AI enables 24/7 support without proportional increases in staffing or geographic constraints[6].\n",
            "  - **Strategic Value:** Intangible benefits include improved brand reputation, increased competitiveness, and better decision-making from AI analytics[3][7].\n",
            "\n",
            "**Considerations & Risks:**\n",
            "\n",
            "- **Assumptions Validation:** Ensure that projected savings, customer retention gains, and revenue uplifts are based on realistic operational data and market benchmarks[2][4].\n",
            "- **Cost Components:** Besides the $2M upfront, account for ongoing maintenance, upgrades, integration, and training costs, which can affect net returns[3][5][4].\n",
            "- **Qualitative Benefits:** Intangible gains (brand, loyalty, insights) should be considered, but rely primarily on measurable financial outcomes for investment justification[3][7].\n",
            "- **Scenario Analysis:** Use scenario planning to stress-test projections under varying adoption rates, market dynamics, and AI performance variability[2].\n",
            "\n",
            "**Risk Mitigation Strategies:**\n",
            "\n",
            "- Rigorously track both direct cost savings and revenue impacts post-launch.\n",
            "- Benchmark performance regularly against industry standards and your initial business case.\n",
            "- Prepare for integration challenges, change management, and potential resistance from staff or customers[2].\n",
            "\n",
            "**Summary Table: Financial Projection**\n",
            "\n",
            "| Initial Investment | 3-Year ROI (%) | Expected Net Gain | Total Return After 3 Years |\n",
            "|--------------------|----------------|-------------------|---------------------------|\n",
            "| $2,000,000         | 150%           | $3,000,000        | $5,000,000                |\n",
            "\n",
            "**Conclusion:**  \n",
            "If your projections are accurate and market conditions remain favorable, a 150% ROI over 3 years is financially compelling for an AI customer service platform, aligning with or exceeding current industry benchmarks. However, robust tracking, scenario analysis, and risk management are essential to realize these returns[2][3][6][8].\n",
            "\n",
            "============================================================\n",
            "============================================================\n",
            "Response: GraphResult(status=<Status.COMPLETED: 'completed'>, results={'finance_expert': NodeResult(result=AgentResult(stop_reason='end_turn', message={'role': 'assistant', 'content': []}, metrics=EventLoopMetrics(cycle_count=1, tool_metrics={}, cycle_durations=[8.44445252418518], traces=[<strands.telemetry.metrics.Trace object at 0x7fa5a1c896a0>], accumulated_usage={'inputTokens': 0, 'outputTokens': 0, 'totalTokens': 0}, accumulated_metrics={'latencyMs': 0}), state={}, interrupts=None, structured_output=None), execution_time=8445, status=<Status.COMPLETED: 'completed'>, accumulated_usage={'inputTokens': 0, 'outputTokens': 0, 'totalTokens': 0}, accumulated_metrics={'latencyMs': 0}, execution_count=1), 'tech_expert': NodeResult(result=AgentResult(stop_reason='end_turn', message={'role': 'assistant', 'content': []}, metrics=EventLoopMetrics(cycle_count=1, tool_metrics={}, cycle_durations=[19.023441791534424], traces=[<strands.telemetry.metrics.Trace object at 0x7fa5a1c8be00>], accumulated_usage={'inputTokens': 0, 'outputTokens': 0, 'totalTokens': 0}, accumulated_metrics={'latencyMs': 0}), state={}, interrupts=None, structured_output=None), execution_time=19024, status=<Status.COMPLETED: 'completed'>, accumulated_usage={'inputTokens': 0, 'outputTokens': 0, 'totalTokens': 0}, accumulated_metrics={'latencyMs': 0}, execution_count=1), 'market_expert': NodeResult(result=AgentResult(stop_reason='end_turn', message={'role': 'assistant', 'content': []}, metrics=EventLoopMetrics(cycle_count=1, tool_metrics={}, cycle_durations=[8.034435510635376], traces=[<strands.telemetry.metrics.Trace object at 0x7fa5a1c8bfb0>], accumulated_usage={'inputTokens': 0, 'outputTokens': 0, 'totalTokens': 0}, accumulated_metrics={'latencyMs': 0}), state={}, interrupts=None, structured_output=None), execution_time=8035, status=<Status.COMPLETED: 'completed'>, accumulated_usage={'inputTokens': 0, 'outputTokens': 0, 'totalTokens': 0}, accumulated_metrics={'latencyMs': 0}, execution_count=1), 'risk_analyst': NodeResult(result=AgentResult(stop_reason='end_turn', message={'role': 'assistant', 'content': []}, metrics=EventLoopMetrics(cycle_count=1, tool_metrics={}, cycle_durations=[19.07399892807007], traces=[<strands.telemetry.metrics.Trace object at 0x7fa5a1cdba10>], accumulated_usage={'inputTokens': 0, 'outputTokens': 0, 'totalTokens': 0}, accumulated_metrics={'latencyMs': 0}), state={}, interrupts=None, structured_output=None), execution_time=19075, status=<Status.COMPLETED: 'completed'>, accumulated_usage={'inputTokens': 0, 'outputTokens': 0, 'totalTokens': 0}, accumulated_metrics={'latencyMs': 0}, execution_count=1)}, accumulated_usage={'inputTokens': 0, 'outputTokens': 0, 'totalTokens': 0}, accumulated_metrics={'latencyMs': 0}, execution_count=4, execution_time=0, total_nodes=4, completed_nodes=4, failed_nodes=0, execution_order=[GraphNode(node_id='finance_expert', executor=<strands.agent.agent.Agent object at 0x7fa5a1d5a420>, dependencies=set(), execution_status=<Status.COMPLETED: 'completed'>, result=NodeResult(result=AgentResult(stop_reason='end_turn', message={'role': 'assistant', 'content': []}, metrics=EventLoopMetrics(cycle_count=1, tool_metrics={}, cycle_durations=[8.44445252418518], traces=[<strands.telemetry.metrics.Trace object at 0x7fa5a1c896a0>], accumulated_usage={'inputTokens': 0, 'outputTokens': 0, 'totalTokens': 0}, accumulated_metrics={'latencyMs': 0}), state={}, interrupts=None, structured_output=None), execution_time=8445, status=<Status.COMPLETED: 'completed'>, accumulated_usage={'inputTokens': 0, 'outputTokens': 0, 'totalTokens': 0}, accumulated_metrics={'latencyMs': 0}, execution_count=1), execution_time=8445, _initial_messages=[], _initial_state=<strands.agent.state.AgentState object at 0x7fa5a1c88b90>), GraphNode(node_id='tech_expert', executor=<strands.agent.agent.Agent object at 0x7fa5a25c9cd0>, dependencies={GraphNode(node_id='finance_expert', executor=<strands.agent.agent.Agent object at 0x7fa5a1d5a420>, dependencies=set(), execution_status=<Status.COMPLETED: 'completed'>, result=NodeResult(result=AgentResult(stop_reason='end_turn', message={'role': 'assistant', 'content': []}, metrics=EventLoopMetrics(cycle_count=1, tool_metrics={}, cycle_durations=[8.44445252418518], traces=[<strands.telemetry.metrics.Trace object at 0x7fa5a1c896a0>], accumulated_usage={'inputTokens': 0, 'outputTokens': 0, 'totalTokens': 0}, accumulated_metrics={'latencyMs': 0}), state={}, interrupts=None, structured_output=None), execution_time=8445, status=<Status.COMPLETED: 'completed'>, accumulated_usage={'inputTokens': 0, 'outputTokens': 0, 'totalTokens': 0}, accumulated_metrics={'latencyMs': 0}, execution_count=1), execution_time=8445, _initial_messages=[], _initial_state=<strands.agent.state.AgentState object at 0x7fa5a1c88b90>)}, execution_status=<Status.COMPLETED: 'completed'>, result=NodeResult(result=AgentResult(stop_reason='end_turn', message={'role': 'assistant', 'content': []}, metrics=EventLoopMetrics(cycle_count=1, tool_metrics={}, cycle_durations=[19.023441791534424], traces=[<strands.telemetry.metrics.Trace object at 0x7fa5a1c8be00>], accumulated_usage={'inputTokens': 0, 'outputTokens': 0, 'totalTokens': 0}, accumulated_metrics={'latencyMs': 0}), state={}, interrupts=None, structured_output=None), execution_time=19024, status=<Status.COMPLETED: 'completed'>, accumulated_usage={'inputTokens': 0, 'outputTokens': 0, 'totalTokens': 0}, accumulated_metrics={'latencyMs': 0}, execution_count=1), execution_time=19024, _initial_messages=[], _initial_state=<strands.agent.state.AgentState object at 0x7fa5a1c88c20>), GraphNode(node_id='market_expert', executor=<strands.agent.agent.Agent object at 0x7fa5a1c88440>, dependencies={GraphNode(node_id='finance_expert', executor=<strands.agent.agent.Agent object at 0x7fa5a1d5a420>, dependencies=set(), execution_status=<Status.COMPLETED: 'completed'>, result=NodeResult(result=AgentResult(stop_reason='end_turn', message={'role': 'assistant', 'content': []}, metrics=EventLoopMetrics(cycle_count=1, tool_metrics={}, cycle_durations=[8.44445252418518], traces=[<strands.telemetry.metrics.Trace object at 0x7fa5a1c896a0>], accumulated_usage={'inputTokens': 0, 'outputTokens': 0, 'totalTokens': 0}, accumulated_metrics={'latencyMs': 0}), state={}, interrupts=None, structured_output=None), execution_time=8445, status=<Status.COMPLETED: 'completed'>, accumulated_usage={'inputTokens': 0, 'outputTokens': 0, 'totalTokens': 0}, accumulated_metrics={'latencyMs': 0}, execution_count=1), execution_time=8445, _initial_messages=[], _initial_state=<strands.agent.state.AgentState object at 0x7fa5a1c88b90>)}, execution_status=<Status.COMPLETED: 'completed'>, result=NodeResult(result=AgentResult(stop_reason='end_turn', message={'role': 'assistant', 'content': []}, metrics=EventLoopMetrics(cycle_count=1, tool_metrics={}, cycle_durations=[8.034435510635376], traces=[<strands.telemetry.metrics.Trace object at 0x7fa5a1c8bfb0>], accumulated_usage={'inputTokens': 0, 'outputTokens': 0, 'totalTokens': 0}, accumulated_metrics={'latencyMs': 0}), state={}, interrupts=None, structured_output=None), execution_time=8035, status=<Status.COMPLETED: 'completed'>, accumulated_usage={'inputTokens': 0, 'outputTokens': 0, 'totalTokens': 0}, accumulated_metrics={'latencyMs': 0}, execution_count=1), execution_time=8035, _initial_messages=[], _initial_state=<strands.agent.state.AgentState object at 0x7fa5a1c88c80>), GraphNode(node_id='risk_analyst', executor=<strands.agent.agent.Agent object at 0x7fa5a1c886b0>, dependencies={GraphNode(node_id='tech_expert', executor=<strands.agent.agent.Agent object at 0x7fa5a25c9cd0>, dependencies={GraphNode(node_id='finance_expert', executor=<strands.agent.agent.Agent object at 0x7fa5a1d5a420>, dependencies=set(), execution_status=<Status.COMPLETED: 'completed'>, result=NodeResult(result=AgentResult(stop_reason='end_turn', message={'role': 'assistant', 'content': []}, metrics=EventLoopMetrics(cycle_count=1, tool_metrics={}, cycle_durations=[8.44445252418518], traces=[<strands.telemetry.metrics.Trace object at 0x7fa5a1c896a0>], accumulated_usage={'inputTokens': 0, 'outputTokens': 0, 'totalTokens': 0}, accumulated_metrics={'latencyMs': 0}), state={}, interrupts=None, structured_output=None), execution_time=8445, status=<Status.COMPLETED: 'completed'>, accumulated_usage={'inputTokens': 0, 'outputTokens': 0, 'totalTokens': 0}, accumulated_metrics={'latencyMs': 0}, execution_count=1), execution_time=8445, _initial_messages=[], _initial_state=<strands.agent.state.AgentState object at 0x7fa5a1c88b90>)}, execution_status=<Status.COMPLETED: 'completed'>, result=NodeResult(result=AgentResult(stop_reason='end_turn', message={'role': 'assistant', 'content': []}, metrics=EventLoopMetrics(cycle_count=1, tool_metrics={}, cycle_durations=[19.023441791534424], traces=[<strands.telemetry.metrics.Trace object at 0x7fa5a1c8be00>], accumulated_usage={'inputTokens': 0, 'outputTokens': 0, 'totalTokens': 0}, accumulated_metrics={'latencyMs': 0}), state={}, interrupts=None, structured_output=None), execution_time=19024, status=<Status.COMPLETED: 'completed'>, accumulated_usage={'inputTokens': 0, 'outputTokens': 0, 'totalTokens': 0}, accumulated_metrics={'latencyMs': 0}, execution_count=1), execution_time=19024, _initial_messages=[], _initial_state=<strands.agent.state.AgentState object at 0x7fa5a1c88c20>), GraphNode(node_id='market_expert', executor=<strands.agent.agent.Agent object at 0x7fa5a1c88440>, dependencies={GraphNode(node_id='finance_expert', executor=<strands.agent.agent.Agent object at 0x7fa5a1d5a420>, dependencies=set(), execution_status=<Status.COMPLETED: 'completed'>, result=NodeResult(result=AgentResult(stop_reason='end_turn', message={'role': 'assistant', 'content': []}, metrics=EventLoopMetrics(cycle_count=1, tool_metrics={}, cycle_durations=[8.44445252418518], traces=[<strands.telemetry.metrics.Trace object at 0x7fa5a1c896a0>], accumulated_usage={'inputTokens': 0, 'outputTokens': 0, 'totalTokens': 0}, accumulated_metrics={'latencyMs': 0}), state={}, interrupts=None, structured_output=None), execution_time=8445, status=<Status.COMPLETED: 'completed'>, accumulated_usage={'inputTokens': 0, 'outputTokens': 0, 'totalTokens': 0}, accumulated_metrics={'latencyMs': 0}, execution_count=1), execution_time=8445, _initial_messages=[], _initial_state=<strands.agent.state.AgentState object at 0x7fa5a1c88b90>)}, execution_status=<Status.COMPLETED: 'completed'>, result=NodeResult(result=AgentResult(stop_reason='end_turn', message={'role': 'assistant', 'content': []}, metrics=EventLoopMetrics(cycle_count=1, tool_metrics={}, cycle_durations=[8.034435510635376], traces=[<strands.telemetry.metrics.Trace object at 0x7fa5a1c8bfb0>], accumulated_usage={'inputTokens': 0, 'outputTokens': 0, 'totalTokens': 0}, accumulated_metrics={'latencyMs': 0}), state={}, interrupts=None, structured_output=None), execution_time=8035, status=<Status.COMPLETED: 'completed'>, accumulated_usage={'inputTokens': 0, 'outputTokens': 0, 'totalTokens': 0}, accumulated_metrics={'latencyMs': 0}, execution_count=1), execution_time=8035, _initial_messages=[], _initial_state=<strands.agent.state.AgentState object at 0x7fa5a1c88c80>)}, execution_status=<Status.COMPLETED: 'completed'>, result=NodeResult(result=AgentResult(stop_reason='end_turn', message={'role': 'assistant', 'content': []}, metrics=EventLoopMetrics(cycle_count=1, tool_metrics={}, cycle_durations=[19.07399892807007], traces=[<strands.telemetry.metrics.Trace object at 0x7fa5a1cdba10>], accumulated_usage={'inputTokens': 0, 'outputTokens': 0, 'totalTokens': 0}, accumulated_metrics={'latencyMs': 0}), state={}, interrupts=None, structured_output=None), execution_time=19075, status=<Status.COMPLETED: 'completed'>, accumulated_usage={'inputTokens': 0, 'outputTokens': 0, 'totalTokens': 0}, accumulated_metrics={'latencyMs': 0}, execution_count=1), execution_time=19075, _initial_messages=[], _initial_state=<strands.agent.state.AgentState object at 0x7fa5a1c88ce0>)], edges=[(GraphNode(node_id='tech_expert', executor=<strands.agent.agent.Agent object at 0x7fa5a25c9cd0>, dependencies={GraphNode(node_id='finance_expert', executor=<strands.agent.agent.Agent object at 0x7fa5a1d5a420>, dependencies=set(), execution_status=<Status.COMPLETED: 'completed'>, result=NodeResult(result=AgentResult(stop_reason='end_turn', message={'role': 'assistant', 'content': []}, metrics=EventLoopMetrics(cycle_count=1, tool_metrics={}, cycle_durations=[8.44445252418518], traces=[<strands.telemetry.metrics.Trace object at 0x7fa5a1c896a0>], accumulated_usage={'inputTokens': 0, 'outputTokens': 0, 'totalTokens': 0}, accumulated_metrics={'latencyMs': 0}), state={}, interrupts=None, structured_output=None), execution_time=8445, status=<Status.COMPLETED: 'completed'>, accumulated_usage={'inputTokens': 0, 'outputTokens': 0, 'totalTokens': 0}, accumulated_metrics={'latencyMs': 0}, execution_count=1), execution_time=8445, _initial_messages=[], _initial_state=<strands.agent.state.AgentState object at 0x7fa5a1c88b90>)}, execution_status=<Status.COMPLETED: 'completed'>, result=NodeResult(result=AgentResult(stop_reason='end_turn', message={'role': 'assistant', 'content': []}, metrics=EventLoopMetrics(cycle_count=1, tool_metrics={}, cycle_durations=[19.023441791534424], traces=[<strands.telemetry.metrics.Trace object at 0x7fa5a1c8be00>], accumulated_usage={'inputTokens': 0, 'outputTokens': 0, 'totalTokens': 0}, accumulated_metrics={'latencyMs': 0}), state={}, interrupts=None, structured_output=None), execution_time=19024, status=<Status.COMPLETED: 'completed'>, accumulated_usage={'inputTokens': 0, 'outputTokens': 0, 'totalTokens': 0}, accumulated_metrics={'latencyMs': 0}, execution_count=1), execution_time=19024, _initial_messages=[], _initial_state=<strands.agent.state.AgentState object at 0x7fa5a1c88c20>), GraphNode(node_id='risk_analyst', executor=<strands.agent.agent.Agent object at 0x7fa5a1c886b0>, dependencies={GraphNode(node_id='tech_expert', executor=<strands.agent.agent.Agent object at 0x7fa5a25c9cd0>, dependencies={GraphNode(node_id='finance_expert', executor=<strands.agent.agent.Agent object at 0x7fa5a1d5a420>, dependencies=set(), execution_status=<Status.COMPLETED: 'completed'>, result=NodeResult(result=AgentResult(stop_reason='end_turn', message={'role': 'assistant', 'content': []}, metrics=EventLoopMetrics(cycle_count=1, tool_metrics={}, cycle_durations=[8.44445252418518], traces=[<strands.telemetry.metrics.Trace object at 0x7fa5a1c896a0>], accumulated_usage={'inputTokens': 0, 'outputTokens': 0, 'totalTokens': 0}, accumulated_metrics={'latencyMs': 0}), state={}, interrupts=None, structured_output=None), execution_time=8445, status=<Status.COMPLETED: 'completed'>, accumulated_usage={'inputTokens': 0, 'outputTokens': 0, 'totalTokens': 0}, accumulated_metrics={'latencyMs': 0}, execution_count=1), execution_time=8445, _initial_messages=[], _initial_state=<strands.agent.state.AgentState object at 0x7fa5a1c88b90>)}, execution_status=<Status.COMPLETED: 'completed'>, result=NodeResult(result=AgentResult(stop_reason='end_turn', message={'role': 'assistant', 'content': []}, metrics=EventLoopMetrics(cycle_count=1, tool_metrics={}, cycle_durations=[19.023441791534424], traces=[<strands.telemetry.metrics.Trace object at 0x7fa5a1c8be00>], accumulated_usage={'inputTokens': 0, 'outputTokens': 0, 'totalTokens': 0}, accumulated_metrics={'latencyMs': 0}), state={}, interrupts=None, structured_output=None), execution_time=19024, status=<Status.COMPLETED: 'completed'>, accumulated_usage={'inputTokens': 0, 'outputTokens': 0, 'totalTokens': 0}, accumulated_metrics={'latencyMs': 0}, execution_count=1), execution_time=19024, _initial_messages=[], _initial_state=<strands.agent.state.AgentState object at 0x7fa5a1c88c20>), GraphNode(node_id='market_expert', executor=<strands.agent.agent.Agent object at 0x7fa5a1c88440>, dependencies={GraphNode(node_id='finance_expert', executor=<strands.agent.agent.Agent object at 0x7fa5a1d5a420>, dependencies=set(), execution_status=<Status.COMPLETED: 'completed'>, result=NodeResult(result=AgentResult(stop_reason='end_turn', message={'role': 'assistant', 'content': []}, metrics=EventLoopMetrics(cycle_count=1, tool_metrics={}, cycle_durations=[8.44445252418518], traces=[<strands.telemetry.metrics.Trace object at 0x7fa5a1c896a0>], accumulated_usage={'inputTokens': 0, 'outputTokens': 0, 'totalTokens': 0}, accumulated_metrics={'latencyMs': 0}), state={}, interrupts=None, structured_output=None), execution_time=8445, status=<Status.COMPLETED: 'completed'>, accumulated_usage={'inputTokens': 0, 'outputTokens': 0, 'totalTokens': 0}, accumulated_metrics={'latencyMs': 0}, execution_count=1), execution_time=8445, _initial_messages=[], _initial_state=<strands.agent.state.AgentState object at 0x7fa5a1c88b90>)}, execution_status=<Status.COMPLETED: 'completed'>, result=NodeResult(result=AgentResult(stop_reason='end_turn', message={'role': 'assistant', 'content': []}, metrics=EventLoopMetrics(cycle_count=1, tool_metrics={}, cycle_durations=[8.034435510635376], traces=[<strands.telemetry.metrics.Trace object at 0x7fa5a1c8bfb0>], accumulated_usage={'inputTokens': 0, 'outputTokens': 0, 'totalTokens': 0}, accumulated_metrics={'latencyMs': 0}), state={}, interrupts=None, structured_output=None), execution_time=8035, status=<Status.COMPLETED: 'completed'>, accumulated_usage={'inputTokens': 0, 'outputTokens': 0, 'totalTokens': 0}, accumulated_metrics={'latencyMs': 0}, execution_count=1), execution_time=8035, _initial_messages=[], _initial_state=<strands.agent.state.AgentState object at 0x7fa5a1c88c80>)}, execution_status=<Status.COMPLETED: 'completed'>, result=NodeResult(result=AgentResult(stop_reason='end_turn', message={'role': 'assistant', 'content': []}, metrics=EventLoopMetrics(cycle_count=1, tool_metrics={}, cycle_durations=[19.07399892807007], traces=[<strands.telemetry.metrics.Trace object at 0x7fa5a1cdba10>], accumulated_usage={'inputTokens': 0, 'outputTokens': 0, 'totalTokens': 0}, accumulated_metrics={'latencyMs': 0}), state={}, interrupts=None, structured_output=None), execution_time=19075, status=<Status.COMPLETED: 'completed'>, accumulated_usage={'inputTokens': 0, 'outputTokens': 0, 'totalTokens': 0}, accumulated_metrics={'latencyMs': 0}, execution_count=1), execution_time=19075, _initial_messages=[], _initial_state=<strands.agent.state.AgentState object at 0x7fa5a1c88ce0>)), (GraphNode(node_id='finance_expert', executor=<strands.agent.agent.Agent object at 0x7fa5a1d5a420>, dependencies=set(), execution_status=<Status.COMPLETED: 'completed'>, result=NodeResult(result=AgentResult(stop_reason='end_turn', message={'role': 'assistant', 'content': []}, metrics=EventLoopMetrics(cycle_count=1, tool_metrics={}, cycle_durations=[8.44445252418518], traces=[<strands.telemetry.metrics.Trace object at 0x7fa5a1c896a0>], accumulated_usage={'inputTokens': 0, 'outputTokens': 0, 'totalTokens': 0}, accumulated_metrics={'latencyMs': 0}), state={}, interrupts=None, structured_output=None), execution_time=8445, status=<Status.COMPLETED: 'completed'>, accumulated_usage={'inputTokens': 0, 'outputTokens': 0, 'totalTokens': 0}, accumulated_metrics={'latencyMs': 0}, execution_count=1), execution_time=8445, _initial_messages=[], _initial_state=<strands.agent.state.AgentState object at 0x7fa5a1c88b90>), GraphNode(node_id='tech_expert', executor=<strands.agent.agent.Agent object at 0x7fa5a25c9cd0>, dependencies={GraphNode(node_id='finance_expert', executor=<strands.agent.agent.Agent object at 0x7fa5a1d5a420>, dependencies=set(), execution_status=<Status.COMPLETED: 'completed'>, result=NodeResult(result=AgentResult(stop_reason='end_turn', message={'role': 'assistant', 'content': []}, metrics=EventLoopMetrics(cycle_count=1, tool_metrics={}, cycle_durations=[8.44445252418518], traces=[<strands.telemetry.metrics.Trace object at 0x7fa5a1c896a0>], accumulated_usage={'inputTokens': 0, 'outputTokens': 0, 'totalTokens': 0}, accumulated_metrics={'latencyMs': 0}), state={}, interrupts=None, structured_output=None), execution_time=8445, status=<Status.COMPLETED: 'completed'>, accumulated_usage={'inputTokens': 0, 'outputTokens': 0, 'totalTokens': 0}, accumulated_metrics={'latencyMs': 0}, execution_count=1), execution_time=8445, _initial_messages=[], _initial_state=<strands.agent.state.AgentState object at 0x7fa5a1c88b90>)}, execution_status=<Status.COMPLETED: 'completed'>, result=NodeResult(result=AgentResult(stop_reason='end_turn', message={'role': 'assistant', 'content': []}, metrics=EventLoopMetrics(cycle_count=1, tool_metrics={}, cycle_durations=[19.023441791534424], traces=[<strands.telemetry.metrics.Trace object at 0x7fa5a1c8be00>], accumulated_usage={'inputTokens': 0, 'outputTokens': 0, 'totalTokens': 0}, accumulated_metrics={'latencyMs': 0}), state={}, interrupts=None, structured_output=None), execution_time=19024, status=<Status.COMPLETED: 'completed'>, accumulated_usage={'inputTokens': 0, 'outputTokens': 0, 'totalTokens': 0}, accumulated_metrics={'latencyMs': 0}, execution_count=1), execution_time=19024, _initial_messages=[], _initial_state=<strands.agent.state.AgentState object at 0x7fa5a1c88c20>)), (GraphNode(node_id='finance_expert', executor=<strands.agent.agent.Agent object at 0x7fa5a1d5a420>, dependencies=set(), execution_status=<Status.COMPLETED: 'completed'>, result=NodeResult(result=AgentResult(stop_reason='end_turn', message={'role': 'assistant', 'content': []}, metrics=EventLoopMetrics(cycle_count=1, tool_metrics={}, cycle_durations=[8.44445252418518], traces=[<strands.telemetry.metrics.Trace object at 0x7fa5a1c896a0>], accumulated_usage={'inputTokens': 0, 'outputTokens': 0, 'totalTokens': 0}, accumulated_metrics={'latencyMs': 0}), state={}, interrupts=None, structured_output=None), execution_time=8445, status=<Status.COMPLETED: 'completed'>, accumulated_usage={'inputTokens': 0, 'outputTokens': 0, 'totalTokens': 0}, accumulated_metrics={'latencyMs': 0}, execution_count=1), execution_time=8445, _initial_messages=[], _initial_state=<strands.agent.state.AgentState object at 0x7fa5a1c88b90>), GraphNode(node_id='market_expert', executor=<strands.agent.agent.Agent object at 0x7fa5a1c88440>, dependencies={GraphNode(node_id='finance_expert', executor=<strands.agent.agent.Agent object at 0x7fa5a1d5a420>, dependencies=set(), execution_status=<Status.COMPLETED: 'completed'>, result=NodeResult(result=AgentResult(stop_reason='end_turn', message={'role': 'assistant', 'content': []}, metrics=EventLoopMetrics(cycle_count=1, tool_metrics={}, cycle_durations=[8.44445252418518], traces=[<strands.telemetry.metrics.Trace object at 0x7fa5a1c896a0>], accumulated_usage={'inputTokens': 0, 'outputTokens': 0, 'totalTokens': 0}, accumulated_metrics={'latencyMs': 0}), state={}, interrupts=None, structured_output=None), execution_time=8445, status=<Status.COMPLETED: 'completed'>, accumulated_usage={'inputTokens': 0, 'outputTokens': 0, 'totalTokens': 0}, accumulated_metrics={'latencyMs': 0}, execution_count=1), execution_time=8445, _initial_messages=[], _initial_state=<strands.agent.state.AgentState object at 0x7fa5a1c88b90>)}, execution_status=<Status.COMPLETED: 'completed'>, result=NodeResult(result=AgentResult(stop_reason='end_turn', message={'role': 'assistant', 'content': []}, metrics=EventLoopMetrics(cycle_count=1, tool_metrics={}, cycle_durations=[8.034435510635376], traces=[<strands.telemetry.metrics.Trace object at 0x7fa5a1c8bfb0>], accumulated_usage={'inputTokens': 0, 'outputTokens': 0, 'totalTokens': 0}, accumulated_metrics={'latencyMs': 0}), state={}, interrupts=None, structured_output=None), execution_time=8035, status=<Status.COMPLETED: 'completed'>, accumulated_usage={'inputTokens': 0, 'outputTokens': 0, 'totalTokens': 0}, accumulated_metrics={'latencyMs': 0}, execution_count=1), execution_time=8035, _initial_messages=[], _initial_state=<strands.agent.state.AgentState object at 0x7fa5a1c88c80>)), (GraphNode(node_id='market_expert', executor=<strands.agent.agent.Agent object at 0x7fa5a1c88440>, dependencies={GraphNode(node_id='finance_expert', executor=<strands.agent.agent.Agent object at 0x7fa5a1d5a420>, dependencies=set(), execution_status=<Status.COMPLETED: 'completed'>, result=NodeResult(result=AgentResult(stop_reason='end_turn', message={'role': 'assistant', 'content': []}, metrics=EventLoopMetrics(cycle_count=1, tool_metrics={}, cycle_durations=[8.44445252418518], traces=[<strands.telemetry.metrics.Trace object at 0x7fa5a1c896a0>], accumulated_usage={'inputTokens': 0, 'outputTokens': 0, 'totalTokens': 0}, accumulated_metrics={'latencyMs': 0}), state={}, interrupts=None, structured_output=None), execution_time=8445, status=<Status.COMPLETED: 'completed'>, accumulated_usage={'inputTokens': 0, 'outputTokens': 0, 'totalTokens': 0}, accumulated_metrics={'latencyMs': 0}, execution_count=1), execution_time=8445, _initial_messages=[], _initial_state=<strands.agent.state.AgentState object at 0x7fa5a1c88b90>)}, execution_status=<Status.COMPLETED: 'completed'>, result=NodeResult(result=AgentResult(stop_reason='end_turn', message={'role': 'assistant', 'content': []}, metrics=EventLoopMetrics(cycle_count=1, tool_metrics={}, cycle_durations=[8.034435510635376], traces=[<strands.telemetry.metrics.Trace object at 0x7fa5a1c8bfb0>], accumulated_usage={'inputTokens': 0, 'outputTokens': 0, 'totalTokens': 0}, accumulated_metrics={'latencyMs': 0}), state={}, interrupts=None, structured_output=None), execution_time=8035, status=<Status.COMPLETED: 'completed'>, accumulated_usage={'inputTokens': 0, 'outputTokens': 0, 'totalTokens': 0}, accumulated_metrics={'latencyMs': 0}, execution_count=1), execution_time=8035, _initial_messages=[], _initial_state=<strands.agent.state.AgentState object at 0x7fa5a1c88c80>), GraphNode(node_id='risk_analyst', executor=<strands.agent.agent.Agent object at 0x7fa5a1c886b0>, dependencies={GraphNode(node_id='tech_expert', executor=<strands.agent.agent.Agent object at 0x7fa5a25c9cd0>, dependencies={GraphNode(node_id='finance_expert', executor=<strands.agent.agent.Agent object at 0x7fa5a1d5a420>, dependencies=set(), execution_status=<Status.COMPLETED: 'completed'>, result=NodeResult(result=AgentResult(stop_reason='end_turn', message={'role': 'assistant', 'content': []}, metrics=EventLoopMetrics(cycle_count=1, tool_metrics={}, cycle_durations=[8.44445252418518], traces=[<strands.telemetry.metrics.Trace object at 0x7fa5a1c896a0>], accumulated_usage={'inputTokens': 0, 'outputTokens': 0, 'totalTokens': 0}, accumulated_metrics={'latencyMs': 0}), state={}, interrupts=None, structured_output=None), execution_time=8445, status=<Status.COMPLETED: 'completed'>, accumulated_usage={'inputTokens': 0, 'outputTokens': 0, 'totalTokens': 0}, accumulated_metrics={'latencyMs': 0}, execution_count=1), execution_time=8445, _initial_messages=[], _initial_state=<strands.agent.state.AgentState object at 0x7fa5a1c88b90>)}, execution_status=<Status.COMPLETED: 'completed'>, result=NodeResult(result=AgentResult(stop_reason='end_turn', message={'role': 'assistant', 'content': []}, metrics=EventLoopMetrics(cycle_count=1, tool_metrics={}, cycle_durations=[19.023441791534424], traces=[<strands.telemetry.metrics.Trace object at 0x7fa5a1c8be00>], accumulated_usage={'inputTokens': 0, 'outputTokens': 0, 'totalTokens': 0}, accumulated_metrics={'latencyMs': 0}), state={}, interrupts=None, structured_output=None), execution_time=19024, status=<Status.COMPLETED: 'completed'>, accumulated_usage={'inputTokens': 0, 'outputTokens': 0, 'totalTokens': 0}, accumulated_metrics={'latencyMs': 0}, execution_count=1), execution_time=19024, _initial_messages=[], _initial_state=<strands.agent.state.AgentState object at 0x7fa5a1c88c20>), GraphNode(node_id='market_expert', executor=<strands.agent.agent.Agent object at 0x7fa5a1c88440>, dependencies={GraphNode(node_id='finance_expert', executor=<strands.agent.agent.Agent object at 0x7fa5a1d5a420>, dependencies=set(), execution_status=<Status.COMPLETED: 'completed'>, result=NodeResult(result=AgentResult(stop_reason='end_turn', message={'role': 'assistant', 'content': []}, metrics=EventLoopMetrics(cycle_count=1, tool_metrics={}, cycle_durations=[8.44445252418518], traces=[<strands.telemetry.metrics.Trace object at 0x7fa5a1c896a0>], accumulated_usage={'inputTokens': 0, 'outputTokens': 0, 'totalTokens': 0}, accumulated_metrics={'latencyMs': 0}), state={}, interrupts=None, structured_output=None), execution_time=8445, status=<Status.COMPLETED: 'completed'>, accumulated_usage={'inputTokens': 0, 'outputTokens': 0, 'totalTokens': 0}, accumulated_metrics={'latencyMs': 0}, execution_count=1), execution_time=8445, _initial_messages=[], _initial_state=<strands.agent.state.AgentState object at 0x7fa5a1c88b90>)}, execution_status=<Status.COMPLETED: 'completed'>, result=NodeResult(result=AgentResult(stop_reason='end_turn', message={'role': 'assistant', 'content': []}, metrics=EventLoopMetrics(cycle_count=1, tool_metrics={}, cycle_durations=[8.034435510635376], traces=[<strands.telemetry.metrics.Trace object at 0x7fa5a1c8bfb0>], accumulated_usage={'inputTokens': 0, 'outputTokens': 0, 'totalTokens': 0}, accumulated_metrics={'latencyMs': 0}), state={}, interrupts=None, structured_output=None), execution_time=8035, status=<Status.COMPLETED: 'completed'>, accumulated_usage={'inputTokens': 0, 'outputTokens': 0, 'totalTokens': 0}, accumulated_metrics={'latencyMs': 0}, execution_count=1), execution_time=8035, _initial_messages=[], _initial_state=<strands.agent.state.AgentState object at 0x7fa5a1c88c80>)}, execution_status=<Status.COMPLETED: 'completed'>, result=NodeResult(result=AgentResult(stop_reason='end_turn', message={'role': 'assistant', 'content': []}, metrics=EventLoopMetrics(cycle_count=1, tool_metrics={}, cycle_durations=[19.07399892807007], traces=[<strands.telemetry.metrics.Trace object at 0x7fa5a1cdba10>], accumulated_usage={'inputTokens': 0, 'outputTokens': 0, 'totalTokens': 0}, accumulated_metrics={'latencyMs': 0}), state={}, interrupts=None, structured_output=None), execution_time=19075, status=<Status.COMPLETED: 'completed'>, accumulated_usage={'inputTokens': 0, 'outputTokens': 0, 'totalTokens': 0}, accumulated_metrics={'latencyMs': 0}, execution_count=1), execution_time=19075, _initial_messages=[], _initial_state=<strands.agent.state.AgentState object at 0x7fa5a1c88ce0>))], entry_points=[GraphNode(node_id='finance_expert', executor=<strands.agent.agent.Agent object at 0x7fa5a1d5a420>, dependencies=set(), execution_status=<Status.COMPLETED: 'completed'>, result=NodeResult(result=AgentResult(stop_reason='end_turn', message={'role': 'assistant', 'content': []}, metrics=EventLoopMetrics(cycle_count=1, tool_metrics={}, cycle_durations=[8.44445252418518], traces=[<strands.telemetry.metrics.Trace object at 0x7fa5a1c896a0>], accumulated_usage={'inputTokens': 0, 'outputTokens': 0, 'totalTokens': 0}, accumulated_metrics={'latencyMs': 0}), state={}, interrupts=None, structured_output=None), execution_time=8445, status=<Status.COMPLETED: 'completed'>, accumulated_usage={'inputTokens': 0, 'outputTokens': 0, 'totalTokens': 0}, accumulated_metrics={'latencyMs': 0}, execution_count=1), execution_time=8445, _initial_messages=[], _initial_state=<strands.agent.state.AgentState object at 0x7fa5a1c88b90>)])\n",
            "=============Node execution order:==========================\n",
            "============================================================\n",
            "Executed: finance_expert\n",
            "Executed: tech_expert\n",
            "Executed: market_expert\n",
            "Executed: risk_analyst\n",
            "=============Graph metrics:=================================\n",
            "============================================================\n",
            "Total nodes: 4\n",
            "Completed nodes: 4\n",
            "Failed nodes: 0\n",
            "Execution time: 0ms\n",
            "Token usage: {'inputTokens': 0, 'outputTokens': 0, 'totalTokens': 0}\n",
            "Financial Advisor:\n",
            "============================================================\n",
            "============================================================\n",
            "\n",
            "\n",
            "\n",
            "Technical Expert:\n",
            "============================================================\n",
            "============================================================\n",
            "\n",
            "\n",
            "\n",
            "Market Researcher:\n",
            "============================================================\n",
            "============================================================\n",
            "\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "#Initialize an agent with agent_graph capability\n",
        "from strands.multiagent import GraphBuilder\n",
        "\n",
        "mesh_agent = Agent()\n",
        "# Create specialized agents\n",
        "\n",
        "financial_advisor = Agent(model=model,name=\"financial_advisor\", system_prompt=\"You are a financial advisor focused on cost-benefit analysis, budget implications, and ROI calculations. Engage with other experts to build comprehensive financial perspectives.\")\n",
        "technical_architect = Agent(model=model, name=\"technical_architect\", system_prompt=\"You are a technical architect who evaluates feasibility, implementation challenges, and technical risks. Collaborate with other experts to ensure technical viability.\")\n",
        "market_researcher = Agent(model=model, name=\"market_researcher\", system_prompt=\"You are a market researcher who analyzes market conditions, user needs, and competitive landscape. Work with other experts to validate market opportunities.\")\n",
        "risk_analyst = Agent(model=model, name=\"risk_analyst\", system_prompt=\"You are a risk analyst who identifies potential risks, mitigation strategies, and compliance issues. Collaborate with other experts to ensure comprehensive risk assessment.\")\n",
        "\n",
        "\n",
        "# Build the graph\n",
        "builder = GraphBuilder()\n",
        "\n",
        "# Add nodes\n",
        "builder.add_node(financial_advisor, \"finance_expert\")\n",
        "builder.add_node(technical_architect, \"tech_expert\")\n",
        "builder.add_node(market_researcher, \"market_expert\")\n",
        "builder.add_node(risk_analyst, \"risk_analyst\")\n",
        "\n",
        "# Add edges (dependencies)\n",
        "builder.add_edge(\"finance_expert\", \"tech_expert\")\n",
        "builder.add_edge(\"finance_expert\", \"market_expert\")\n",
        "builder.add_edge(\"tech_expert\", \"risk_analyst\")\n",
        "builder.add_edge(\"market_expert\", \"risk_analyst\")\n",
        "\n",
        "\n",
        "# Set entry points (optional - will be auto-detected if not specified)\n",
        "builder.set_entry_point(\"finance_expert\")\n",
        "\n",
        "# Build the graph\n",
        "graph = builder.build()\n",
        "\n",
        "print(\"============================================================\")\n",
        "print(\"============================================================\")\n",
        "\n",
        "#Execute task on newly built graph\n",
        "result = graph(\"Our company is considering launching a new AI-powered customer service platform. Initial investment is \\$2M with projected 3-year ROI of 150%. What's your financial assessment?\")\n",
        "print(\"\\n\")\n",
        "print(\"============================================================\")\n",
        "print(\"============================================================\")\n",
        "\n",
        "print(f\"Response: {result}\")\n",
        "\n",
        "print(\"=============Node execution order:==========================\")\n",
        "print(\"============================================================\")\n",
        "\n",
        "# See which nodes were executed and in what order\n",
        "for node in result.execution_order:\n",
        "    print(f\"Executed: {node.node_id}\")\n",
        "\n",
        "print(\"=============Graph metrics:=================================\")\n",
        "print(\"============================================================\")\n",
        "\n",
        "\n",
        "# Get performance metrics\n",
        "print(f\"Total nodes: {result.total_nodes}\")\n",
        "print(f\"Completed nodes: {result.completed_nodes}\")\n",
        "print(f\"Failed nodes: {result.failed_nodes}\")\n",
        "print(f\"Execution time: {result.execution_time}ms\")\n",
        "print(f\"Token usage: {result.accumulated_usage}\")\n",
        "\n",
        "\n",
        "# Get results from specific nodes\n",
        "\n",
        "print(\"Financial Advisor:\")\n",
        "print(\"============================================================\")\n",
        "print(\"============================================================\")\n",
        "print(result.results[\"finance_expert\"].result)\n",
        "print(\"\\n\")\n",
        "\n",
        "print(\"Technical Expert:\")\n",
        "print(\"============================================================\")\n",
        "print(\"============================================================\")\n",
        "print(result.results[\"tech_expert\"].result)\n",
        "print(\"\\n\")\n",
        "\n",
        "print(\"Market Researcher:\")\n",
        "print(\"============================================================\")\n",
        "print(\"============================================================\")\n",
        "print(result.results[\"market_expert\"].result)\n",
        "print(\"\\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ae0eb88e-fdc1-4387-8eb0-4a9ae50ca2ea",
      "metadata": {
        "id": "ae0eb88e-fdc1-4387-8eb0-4a9ae50ca2ea"
      },
      "source": [
        "### Branching with conditions\n",
        "\n",
        "Let's create an agent graph that would classify the request and depending on conditions we define in the code - will route the request either to technical or business agent.\n",
        "\n",
        "Take a close look on differences between the node execution order and number of nodes executed in this graph based on two different prompts.\n",
        "\n",
        "<div style=\"text-align:left\">\n",
        "    <img src=\"https://github.com/strands-agents/samples/blob/main/01-tutorials/02-multi-agent-systems/03-graph-agent/images/conditional.png?raw=1\" width=\"55%\" />\n",
        "</div>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 89,
      "id": "5058e219-8fb8-4503-8bbf-9e69dd06cf62",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5058e219-8fb8-4503-8bbf-9e69dd06cf62",
        "outputId": "54732468-7987-4056-a1fe-9cb025bde0f7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:strands.multiagent.graph:Graph without execution limits may run indefinitely if cycles exist\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================================================\n",
            "============================================================\n",
            "The technical aspect of working from home centers on ensuring secure, reliable access to workplace systems, appropriate hardware and software, and a safe and productive work environment. Key considerations and risk factors include equipment requirements, network security, software needs, and ergonomics.\n",
            "\n",
            "**Things to Consider:**\n",
            "\n",
            "- **Hardware Requirements:**\n",
            "  - A modern **laptop or desktop** with up-to-date processors (e.g., current Intel Core or AMD Ryzen), at least **8GB RAM** (16GB preferred for heavy multitasking), **256GB+ SSD storage**, and a **21-inch or larger monitor** for comfortable viewing[1][9].\n",
            "  - Essential peripherals: **Webcam, microphone, speakers or headset, keyboard, mouse**, docking station, and surge protector/uninterruptible power supply[3][7][13].\n",
            "  - Good ergonomics: An **ergonomic chair**, properly positioned desk, and adequate lighting reduce physical health risks[4][13].\n",
            "- **Software & Tools:**\n",
            "  - Operating system (Windows 10 or Mac OS X), up-to-date **antivirus software**, **VPN client** for secure company access, and standard productivity suites (Microsoft Office, project management, communication and collaboration tools)[1][3][9].\n",
            "- **Internet Connectivity:**\n",
            "  - **High-speed, reliable internet** (minimum 10 Mbps per device) is essential for video conferencing and cloud access[1][5][11].\n",
            "  - Wired (Ethernet) connections are preferred for stability in critical tasks[13].\n",
            "- **Physical Workspace:**\n",
            "  - A **quiet, dedicated workspace** that minimizes distractions and supports confidentiality[5].\n",
            "\n",
            "**Key Risk Factors:**\n",
            "\n",
            "- **Cybersecurity Risks:**\n",
            "  - **Unsecured home Wi-Fi:** Home networks usually lack enterprise-grade security, increasing the risk of unauthorized access and data breaches[2][4][8].\n",
            "  - **Personal device usage (BYOD):** Personal devices may lack security updates and proper configuration, making them vulnerable to malware, phishing, and data leaks[2][4][6][10].\n",
            "  - **Phishing and social engineering:** Remote workers are prime targets for cyberattacks due to lower IT oversight and more isolated communication[2][4][10].\n",
            "  - **Expanded attack surface:** More endpoints (devices, home networks) to protect increases the workload for IT and the potential for vulnerabilities[6].\n",
            "  - **Weak password practices and lack of multi-factor authentication (MFA):** Increases the risk of unauthorized system access[2][8].\n",
            "- **Data Protection and Compliance:**\n",
            "  - Risk of **data loss** or exposure if local storage is not encrypted or if files are stored on personal devices/cloud accounts[2][4].\n",
            "  - **Difficulty in enforcing data handling policies** remotely can lead to regulatory non-compliance.\n",
            "- **IT Support and Oversight:**\n",
            "  - **Absence of physical IT support** makes it harder to monitor, patch, and secure devices, increasing the risk of undetected vulnerabilities[2].\n",
            "- **Physical and Environmental Risks:**\n",
            "  - **Ergonomic concerns:** Improper setups can lead to musculoskeletal injuries, eye strain, and reduced productivity[4][13].\n",
            "  - **Electrical safety:** Inadequate surge protection or use of faulty devices can damage equipment or cause hazards[7].\n",
            "- **Business Continuity:**\n",
            "  - **Power outages** or network downtime at home can disrupt work, so backup solutions (UPS, mobile hotspots) are advisable[7][13].\n",
            "\n",
            "**Summary Table: Technical Considerations and Risks**\n",
            "\n",
            "| Aspect                 | Key Considerations                                     | Main Risks Identified                                     |\n",
            "|------------------------|--------------------------------------------------------|-----------------------------------------------------------|\n",
            "| Hardware               | Modern computer, peripherals, ergonomic furniture      | Device failure, poor ergonomics, electrical hazards       |\n",
            "| Software               | Up-to-date OS, security, productivity, VPN tools       | Unpatched software, inadequate security                   |\n",
            "| Internet Connectivity  | High-speed, reliable connection, preferably wired      | Outages, slow speeds, unsecured Wi-Fi                     |\n",
            "| Cybersecurity          | Encrypted data, MFA, company-issued devices if possible| Data breaches, phishing, malware, weak passwords          |\n",
            "| IT Support             | Remote monitoring, regular updates and support         | Delayed incident response, lack of oversight              |\n",
            "| Physical Workspace     | Quiet, dedicated, well-lit and ventilated area         | Distractions, confidentiality breaches, health issues     |\n",
            "\n",
            "Organizations should conduct regular risk assessments of remote setups, enforce clear security policies (especially for BYOD), and offer training on best practices to mitigate these risks[4][2][10].\n",
            "\n",
            "============================================================\n",
            "============================================================\n",
            "Response: GraphResult(status=<Status.COMPLETED: 'completed'>, results={'classifier': NodeResult(result=AgentResult(stop_reason='end_turn', message={'role': 'assistant', 'content': []}, metrics=EventLoopMetrics(cycle_count=1, tool_metrics={}, cycle_durations=[10.476651430130005], traces=[<strands.telemetry.metrics.Trace object at 0x7fa5a14330b0>], accumulated_usage={'inputTokens': 0, 'outputTokens': 0, 'totalTokens': 0}, accumulated_metrics={'latencyMs': 0}), state={}, interrupts=None, structured_output=None), execution_time=10477, status=<Status.COMPLETED: 'completed'>, accumulated_usage={'inputTokens': 0, 'outputTokens': 0, 'totalTokens': 0}, accumulated_metrics={'latencyMs': 0}, execution_count=1)}, accumulated_usage={'inputTokens': 0, 'outputTokens': 0, 'totalTokens': 0}, accumulated_metrics={'latencyMs': 0}, execution_count=1, execution_time=0, total_nodes=3, completed_nodes=1, failed_nodes=0, execution_order=[GraphNode(node_id='classifier', executor=<strands.agent.agent.Agent object at 0x7fa5a1cd8560>, dependencies=set(), execution_status=<Status.COMPLETED: 'completed'>, result=NodeResult(result=AgentResult(stop_reason='end_turn', message={'role': 'assistant', 'content': []}, metrics=EventLoopMetrics(cycle_count=1, tool_metrics={}, cycle_durations=[10.476651430130005], traces=[<strands.telemetry.metrics.Trace object at 0x7fa5a14330b0>], accumulated_usage={'inputTokens': 0, 'outputTokens': 0, 'totalTokens': 0}, accumulated_metrics={'latencyMs': 0}), state={}, interrupts=None, structured_output=None), execution_time=10477, status=<Status.COMPLETED: 'completed'>, accumulated_usage={'inputTokens': 0, 'outputTokens': 0, 'totalTokens': 0}, accumulated_metrics={'latencyMs': 0}, execution_count=1), execution_time=10477, _initial_messages=[], _initial_state=<strands.agent.state.AgentState object at 0x7fa5a14327e0>)], edges=[(GraphNode(node_id='classifier', executor=<strands.agent.agent.Agent object at 0x7fa5a1cd8560>, dependencies=set(), execution_status=<Status.COMPLETED: 'completed'>, result=NodeResult(result=AgentResult(stop_reason='end_turn', message={'role': 'assistant', 'content': []}, metrics=EventLoopMetrics(cycle_count=1, tool_metrics={}, cycle_durations=[10.476651430130005], traces=[<strands.telemetry.metrics.Trace object at 0x7fa5a14330b0>], accumulated_usage={'inputTokens': 0, 'outputTokens': 0, 'totalTokens': 0}, accumulated_metrics={'latencyMs': 0}), state={}, interrupts=None, structured_output=None), execution_time=10477, status=<Status.COMPLETED: 'completed'>, accumulated_usage={'inputTokens': 0, 'outputTokens': 0, 'totalTokens': 0}, accumulated_metrics={'latencyMs': 0}, execution_count=1), execution_time=10477, _initial_messages=[], _initial_state=<strands.agent.state.AgentState object at 0x7fa5a14327e0>), GraphNode(node_id='business_report', executor=<strands.agent.agent.Agent object at 0x7fa5a1432300>, dependencies={GraphNode(node_id='classifier', executor=<strands.agent.agent.Agent object at 0x7fa5a1cd8560>, dependencies=set(), execution_status=<Status.COMPLETED: 'completed'>, result=NodeResult(result=AgentResult(stop_reason='end_turn', message={'role': 'assistant', 'content': []}, metrics=EventLoopMetrics(cycle_count=1, tool_metrics={}, cycle_durations=[10.476651430130005], traces=[<strands.telemetry.metrics.Trace object at 0x7fa5a14330b0>], accumulated_usage={'inputTokens': 0, 'outputTokens': 0, 'totalTokens': 0}, accumulated_metrics={'latencyMs': 0}), state={}, interrupts=None, structured_output=None), execution_time=10477, status=<Status.COMPLETED: 'completed'>, accumulated_usage={'inputTokens': 0, 'outputTokens': 0, 'totalTokens': 0}, accumulated_metrics={'latencyMs': 0}, execution_count=1), execution_time=10477, _initial_messages=[], _initial_state=<strands.agent.state.AgentState object at 0x7fa5a14327e0>)}, execution_status=<Status.PENDING: 'pending'>, result=None, execution_time=0, _initial_messages=[], _initial_state=<strands.agent.state.AgentState object at 0x7fa5a14328d0>)), (GraphNode(node_id='classifier', executor=<strands.agent.agent.Agent object at 0x7fa5a1cd8560>, dependencies=set(), execution_status=<Status.COMPLETED: 'completed'>, result=NodeResult(result=AgentResult(stop_reason='end_turn', message={'role': 'assistant', 'content': []}, metrics=EventLoopMetrics(cycle_count=1, tool_metrics={}, cycle_durations=[10.476651430130005], traces=[<strands.telemetry.metrics.Trace object at 0x7fa5a14330b0>], accumulated_usage={'inputTokens': 0, 'outputTokens': 0, 'totalTokens': 0}, accumulated_metrics={'latencyMs': 0}), state={}, interrupts=None, structured_output=None), execution_time=10477, status=<Status.COMPLETED: 'completed'>, accumulated_usage={'inputTokens': 0, 'outputTokens': 0, 'totalTokens': 0}, accumulated_metrics={'latencyMs': 0}, execution_count=1), execution_time=10477, _initial_messages=[], _initial_state=<strands.agent.state.AgentState object at 0x7fa5a14327e0>), GraphNode(node_id='technical_report', executor=<strands.agent.agent.Agent object at 0x7fa5a14320c0>, dependencies={GraphNode(node_id='classifier', executor=<strands.agent.agent.Agent object at 0x7fa5a1cd8560>, dependencies=set(), execution_status=<Status.COMPLETED: 'completed'>, result=NodeResult(result=AgentResult(stop_reason='end_turn', message={'role': 'assistant', 'content': []}, metrics=EventLoopMetrics(cycle_count=1, tool_metrics={}, cycle_durations=[10.476651430130005], traces=[<strands.telemetry.metrics.Trace object at 0x7fa5a14330b0>], accumulated_usage={'inputTokens': 0, 'outputTokens': 0, 'totalTokens': 0}, accumulated_metrics={'latencyMs': 0}), state={}, interrupts=None, structured_output=None), execution_time=10477, status=<Status.COMPLETED: 'completed'>, accumulated_usage={'inputTokens': 0, 'outputTokens': 0, 'totalTokens': 0}, accumulated_metrics={'latencyMs': 0}, execution_count=1), execution_time=10477, _initial_messages=[], _initial_state=<strands.agent.state.AgentState object at 0x7fa5a14327e0>)}, execution_status=<Status.PENDING: 'pending'>, result=None, execution_time=0, _initial_messages=[], _initial_state=<strands.agent.state.AgentState object at 0x7fa5a1432870>))], entry_points=[GraphNode(node_id='classifier', executor=<strands.agent.agent.Agent object at 0x7fa5a1cd8560>, dependencies=set(), execution_status=<Status.COMPLETED: 'completed'>, result=NodeResult(result=AgentResult(stop_reason='end_turn', message={'role': 'assistant', 'content': []}, metrics=EventLoopMetrics(cycle_count=1, tool_metrics={}, cycle_durations=[10.476651430130005], traces=[<strands.telemetry.metrics.Trace object at 0x7fa5a14330b0>], accumulated_usage={'inputTokens': 0, 'outputTokens': 0, 'totalTokens': 0}, accumulated_metrics={'latencyMs': 0}), state={}, interrupts=None, structured_output=None), execution_time=10477, status=<Status.COMPLETED: 'completed'>, accumulated_usage={'inputTokens': 0, 'outputTokens': 0, 'totalTokens': 0}, accumulated_metrics={'latencyMs': 0}, execution_count=1), execution_time=10477, _initial_messages=[], _initial_state=<strands.agent.state.AgentState object at 0x7fa5a14327e0>)])\n",
            "=============Node execution order:==========================\n",
            "============================================================\n",
            "Executed: classifier\n",
            "=============Graph metrics:=================================\n",
            "============================================================\n",
            "Total nodes: 3\n",
            "Completed nodes: 1\n",
            "Failed nodes: 0\n",
            "Execution time: 0ms\n",
            "Token usage: {'inputTokens': 0, 'outputTokens': 0, 'totalTokens': 0}\n",
            "Classifier:\n",
            "============================================================\n",
            "============================================================\n",
            "\n",
            "\n",
            "\n",
            "Working from home has significantly transformed business operations, delivering both measurable benefits and notable challenges. Key considerations for organizations include productivity, cost, employee satisfaction, and risks related to management, collaboration, and career progression.\n",
            "\n",
            "**Key Business Impacts to Consider:**\n",
            "\n",
            "- **Productivity:** Multiple studies show remote work can lead to higher productivity, with gains of 13–40% reported in some cases, often attributed to fewer workplace distractions and improved flexibility[1][5]. US Bureau of Labor Statistics data links increased remote work with higher total factor productivity (TFP) across many industries[4].\n",
            "- **Cost Savings:** Remote work reduces the need for physical office space, lowering real estate and facilities costs. A 1% increase in remote work was associated with a 0.4% decrease in office building cost growth[4]. Businesses also save on utilities and some recruitment costs.\n",
            "- **Talent Attraction & Retention:** Offering remote or hybrid options is now a major driver of employee satisfaction and retention. Remote workers are 24% more satisfied, and companies offering flexibility see up to 25% lower turnover[1]. Many employees would accept lower pay to maintain remote options.\n",
            "- **Business Growth:** Fully remote firms have demonstrated revenue growth rates 1.7 times higher than office-based peers between 2019 and 2024[2].\n",
            "- **Employee Well-being & Engagement:** Most employees report improved work-life balance and lower stress levels when working remotely[8]. However, engagement and a sense of connection with teams can suffer, with 30–40% reporting feelings of disconnection[1].\n",
            "\n",
            "**Key Risk Factors:**\n",
            "\n",
            "- **Management and Performance Assessment Challenges:** Managers report lower visibility into employee performance, making evaluation and career development more difficult. Around 60% of managers find it harder to assess remote employees compared to on-site staff[1].\n",
            "- **Collaboration and Communication:** Remote work can create communication gaps (29% of employees cite this as a challenge), increase reliance on asynchronous tools, and often leads to more frequent—but sometimes less effective—virtual meetings, contributing to mental fatigue[1].\n",
            "- **Career Progression Concerns:** About 50% of remote workers worry their chances for promotion are negatively impacted by reduced visibility compared to in-office peers[1].\n",
            "- **Employee Isolation:** Loneliness and a lack of team cohesion are significant risks, with 22% of employees citing loneliness as a primary challenge[1]. This can affect morale, engagement, and retention.\n",
            "- **Distractions and Time Management:** Home environments can introduce distractions, and 25% of remote workers report difficulty managing their time effectively[1].\n",
            "- **Security and Compliance:** While not always top of mind for business leaders, remote work increases risks around data security and compliance due to distributed access and varied home network setups. Businesses must invest in secure tools and training.\n",
            "\n",
            "**Additional Considerations:**\n",
            "\n",
            "- **Hybrid Models Preferred:** In 2025, 83% of workers cite hybrid work—a blend of remote and in-office—as the ideal model, offering flexibility while maintaining opportunities for in-person collaboration[1].\n",
            "- **Technology Investment:** Cloud-based collaboration and project management tools are critical to sustaining productivity, with companies reporting up to 35% productivity gains from adopting centralized digital platforms[1].\n",
            "- **Organizational Culture:** Sustaining a strong, inclusive company culture requires intentional strategies when teams are remote, such as regular virtual check-ins, transparent communication, and targeted team-building initiatives.\n",
            "\n",
            "Overall, while working from home offers compelling business advantages—including productivity gains, cost savings, and talent retention—companies must proactively address risks around management, communication, career development, and employee well-being to maximize benefits and minimize drawbacks.\n",
            "\n",
            "============================================================\n",
            "============================================================\n",
            "Response: GraphResult(status=<Status.COMPLETED: 'completed'>, results={'classifier': NodeResult(result=AgentResult(stop_reason='end_turn', message={'role': 'assistant', 'content': []}, metrics=EventLoopMetrics(cycle_count=2, tool_metrics={}, cycle_durations=[10.476651430130005, 13.257744073867798], traces=[<strands.telemetry.metrics.Trace object at 0x7fa5a14330b0>, <strands.telemetry.metrics.Trace object at 0x7fa5a1cd8d40>], accumulated_usage={'inputTokens': 0, 'outputTokens': 0, 'totalTokens': 0}, accumulated_metrics={'latencyMs': 0}), state={}, interrupts=None, structured_output=None), execution_time=13258, status=<Status.COMPLETED: 'completed'>, accumulated_usage={'inputTokens': 0, 'outputTokens': 0, 'totalTokens': 0}, accumulated_metrics={'latencyMs': 0}, execution_count=1)}, accumulated_usage={'inputTokens': 0, 'outputTokens': 0, 'totalTokens': 0}, accumulated_metrics={'latencyMs': 0}, execution_count=1, execution_time=0, total_nodes=3, completed_nodes=1, failed_nodes=0, execution_order=[GraphNode(node_id='classifier', executor=<strands.agent.agent.Agent object at 0x7fa5a1cd8560>, dependencies=set(), execution_status=<Status.COMPLETED: 'completed'>, result=NodeResult(result=AgentResult(stop_reason='end_turn', message={'role': 'assistant', 'content': []}, metrics=EventLoopMetrics(cycle_count=2, tool_metrics={}, cycle_durations=[10.476651430130005, 13.257744073867798], traces=[<strands.telemetry.metrics.Trace object at 0x7fa5a14330b0>, <strands.telemetry.metrics.Trace object at 0x7fa5a1cd8d40>], accumulated_usage={'inputTokens': 0, 'outputTokens': 0, 'totalTokens': 0}, accumulated_metrics={'latencyMs': 0}), state={}, interrupts=None, structured_output=None), execution_time=13258, status=<Status.COMPLETED: 'completed'>, accumulated_usage={'inputTokens': 0, 'outputTokens': 0, 'totalTokens': 0}, accumulated_metrics={'latencyMs': 0}, execution_count=1), execution_time=13258, _initial_messages=[], _initial_state=<strands.agent.state.AgentState object at 0x7fa5a14327e0>)], edges=[(GraphNode(node_id='classifier', executor=<strands.agent.agent.Agent object at 0x7fa5a1cd8560>, dependencies=set(), execution_status=<Status.COMPLETED: 'completed'>, result=NodeResult(result=AgentResult(stop_reason='end_turn', message={'role': 'assistant', 'content': []}, metrics=EventLoopMetrics(cycle_count=2, tool_metrics={}, cycle_durations=[10.476651430130005, 13.257744073867798], traces=[<strands.telemetry.metrics.Trace object at 0x7fa5a14330b0>, <strands.telemetry.metrics.Trace object at 0x7fa5a1cd8d40>], accumulated_usage={'inputTokens': 0, 'outputTokens': 0, 'totalTokens': 0}, accumulated_metrics={'latencyMs': 0}), state={}, interrupts=None, structured_output=None), execution_time=13258, status=<Status.COMPLETED: 'completed'>, accumulated_usage={'inputTokens': 0, 'outputTokens': 0, 'totalTokens': 0}, accumulated_metrics={'latencyMs': 0}, execution_count=1), execution_time=13258, _initial_messages=[], _initial_state=<strands.agent.state.AgentState object at 0x7fa5a14327e0>), GraphNode(node_id='business_report', executor=<strands.agent.agent.Agent object at 0x7fa5a1432300>, dependencies={GraphNode(node_id='classifier', executor=<strands.agent.agent.Agent object at 0x7fa5a1cd8560>, dependencies=set(), execution_status=<Status.COMPLETED: 'completed'>, result=NodeResult(result=AgentResult(stop_reason='end_turn', message={'role': 'assistant', 'content': []}, metrics=EventLoopMetrics(cycle_count=2, tool_metrics={}, cycle_durations=[10.476651430130005, 13.257744073867798], traces=[<strands.telemetry.metrics.Trace object at 0x7fa5a14330b0>, <strands.telemetry.metrics.Trace object at 0x7fa5a1cd8d40>], accumulated_usage={'inputTokens': 0, 'outputTokens': 0, 'totalTokens': 0}, accumulated_metrics={'latencyMs': 0}), state={}, interrupts=None, structured_output=None), execution_time=13258, status=<Status.COMPLETED: 'completed'>, accumulated_usage={'inputTokens': 0, 'outputTokens': 0, 'totalTokens': 0}, accumulated_metrics={'latencyMs': 0}, execution_count=1), execution_time=13258, _initial_messages=[], _initial_state=<strands.agent.state.AgentState object at 0x7fa5a14327e0>)}, execution_status=<Status.PENDING: 'pending'>, result=None, execution_time=0, _initial_messages=[], _initial_state=<strands.agent.state.AgentState object at 0x7fa5a14328d0>)), (GraphNode(node_id='classifier', executor=<strands.agent.agent.Agent object at 0x7fa5a1cd8560>, dependencies=set(), execution_status=<Status.COMPLETED: 'completed'>, result=NodeResult(result=AgentResult(stop_reason='end_turn', message={'role': 'assistant', 'content': []}, metrics=EventLoopMetrics(cycle_count=2, tool_metrics={}, cycle_durations=[10.476651430130005, 13.257744073867798], traces=[<strands.telemetry.metrics.Trace object at 0x7fa5a14330b0>, <strands.telemetry.metrics.Trace object at 0x7fa5a1cd8d40>], accumulated_usage={'inputTokens': 0, 'outputTokens': 0, 'totalTokens': 0}, accumulated_metrics={'latencyMs': 0}), state={}, interrupts=None, structured_output=None), execution_time=13258, status=<Status.COMPLETED: 'completed'>, accumulated_usage={'inputTokens': 0, 'outputTokens': 0, 'totalTokens': 0}, accumulated_metrics={'latencyMs': 0}, execution_count=1), execution_time=13258, _initial_messages=[], _initial_state=<strands.agent.state.AgentState object at 0x7fa5a14327e0>), GraphNode(node_id='technical_report', executor=<strands.agent.agent.Agent object at 0x7fa5a14320c0>, dependencies={GraphNode(node_id='classifier', executor=<strands.agent.agent.Agent object at 0x7fa5a1cd8560>, dependencies=set(), execution_status=<Status.COMPLETED: 'completed'>, result=NodeResult(result=AgentResult(stop_reason='end_turn', message={'role': 'assistant', 'content': []}, metrics=EventLoopMetrics(cycle_count=2, tool_metrics={}, cycle_durations=[10.476651430130005, 13.257744073867798], traces=[<strands.telemetry.metrics.Trace object at 0x7fa5a14330b0>, <strands.telemetry.metrics.Trace object at 0x7fa5a1cd8d40>], accumulated_usage={'inputTokens': 0, 'outputTokens': 0, 'totalTokens': 0}, accumulated_metrics={'latencyMs': 0}), state={}, interrupts=None, structured_output=None), execution_time=13258, status=<Status.COMPLETED: 'completed'>, accumulated_usage={'inputTokens': 0, 'outputTokens': 0, 'totalTokens': 0}, accumulated_metrics={'latencyMs': 0}, execution_count=1), execution_time=13258, _initial_messages=[], _initial_state=<strands.agent.state.AgentState object at 0x7fa5a14327e0>)}, execution_status=<Status.PENDING: 'pending'>, result=None, execution_time=0, _initial_messages=[], _initial_state=<strands.agent.state.AgentState object at 0x7fa5a1432870>))], entry_points=[GraphNode(node_id='classifier', executor=<strands.agent.agent.Agent object at 0x7fa5a1cd8560>, dependencies=set(), execution_status=<Status.COMPLETED: 'completed'>, result=NodeResult(result=AgentResult(stop_reason='end_turn', message={'role': 'assistant', 'content': []}, metrics=EventLoopMetrics(cycle_count=2, tool_metrics={}, cycle_durations=[10.476651430130005, 13.257744073867798], traces=[<strands.telemetry.metrics.Trace object at 0x7fa5a14330b0>, <strands.telemetry.metrics.Trace object at 0x7fa5a1cd8d40>], accumulated_usage={'inputTokens': 0, 'outputTokens': 0, 'totalTokens': 0}, accumulated_metrics={'latencyMs': 0}), state={}, interrupts=None, structured_output=None), execution_time=13258, status=<Status.COMPLETED: 'completed'>, accumulated_usage={'inputTokens': 0, 'outputTokens': 0, 'totalTokens': 0}, accumulated_metrics={'latencyMs': 0}, execution_count=1), execution_time=13258, _initial_messages=[], _initial_state=<strands.agent.state.AgentState object at 0x7fa5a14327e0>)])\n",
            "=============Node execution order:==========================\n",
            "============================================================\n",
            "Executed: classifier\n",
            "=============Graph metrics:=================================\n",
            "============================================================\n",
            "Total nodes: 3\n",
            "Completed nodes: 1\n",
            "Failed nodes: 0\n",
            "Execution time: 0ms\n",
            "Token usage: {'inputTokens': 0, 'outputTokens': 0, 'totalTokens': 0}\n",
            "Classifier:\n",
            "============================================================\n",
            "============================================================\n",
            "\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "#Initialize an agent with agent_graph capability\n",
        "from strands.multiagent import GraphBuilder\n",
        "\n",
        "mesh_agent = Agent()\n",
        "# Create specialized agents\n",
        "\n",
        "classifier = Agent(model=model,name=\"classifier\", system_prompt=\"You are an agent responsible for classification of the report request, return only Technical or Business clasification.\")\n",
        "technical_report = Agent(model=model, name=\"technical_expert\", system_prompt=\"You are a technical expert htat focuses on providing short summary from technical perspective\")\n",
        "business_report = Agent(model=model, name=\"business_expert\", system_prompt=\"You are a business expert that focuses on providing short summary from business perspective\")\n",
        "\n",
        "# Build the graph\n",
        "builder = GraphBuilder()\n",
        "\n",
        "# Add nodes\n",
        "builder.add_node(classifier, \"classifier\")\n",
        "builder.add_node(technical_report, \"technical_report\")\n",
        "builder.add_node(business_report, \"business_report\")\n",
        "\n",
        "def is_technical(state):\n",
        "    classifier_result = state.results.get(\"classifier\")\n",
        "    if not classifier_result:\n",
        "        return False\n",
        "    result_text = str(classifier_result.result)\n",
        "    return \"technical\" in result_text.lower()\n",
        "\n",
        "def is_business(state):\n",
        "    classifier_result = state.results.get(\"classifier\")\n",
        "    if not classifier_result:\n",
        "        return False\n",
        "    result_text = str(classifier_result.result)\n",
        "    return \"business\" in result_text.lower()\n",
        "\n",
        "# Add edges (dependencies)\n",
        "builder.add_edge(\"classifier\", \"technical_report\", condition=is_technical)\n",
        "builder.add_edge(\"classifier\", \"business_report\", condition=is_business)\n",
        "\n",
        "# Set entry points (optional - will be auto-detected if not specified)\n",
        "builder.set_entry_point(\"classifier\")\n",
        "\n",
        "# Build the graph\n",
        "graph = builder.build()\n",
        "\n",
        "print(\"============================================================\")\n",
        "print(\"============================================================\")\n",
        "\n",
        "#Execute task on newly built graph\n",
        "result = graph(\"Provide report on technical aspect of working from home, outline things to consider and key risk factors\")\n",
        "print(\"\\n\")\n",
        "print(\"============================================================\")\n",
        "print(\"============================================================\")\n",
        "\n",
        "print(f\"Response: {result}\")\n",
        "\n",
        "print(\"=============Node execution order:==========================\")\n",
        "print(\"============================================================\")\n",
        "\n",
        "# See which nodes were executed and in what order\n",
        "for node in result.execution_order:\n",
        "    print(f\"Executed: {node.node_id}\")\n",
        "\n",
        "print(\"=============Graph metrics:=================================\")\n",
        "print(\"============================================================\")\n",
        "\n",
        "\n",
        "# Get performance metrics\n",
        "print(f\"Total nodes: {result.total_nodes}\")\n",
        "print(f\"Completed nodes: {result.completed_nodes}\")\n",
        "print(f\"Failed nodes: {result.failed_nodes}\")\n",
        "print(f\"Execution time: {result.execution_time}ms\")\n",
        "print(f\"Token usage: {result.accumulated_usage}\")\n",
        "\n",
        "# Get results from specific nodes\n",
        "\n",
        "print(\"Classifier:\")\n",
        "print(\"============================================================\")\n",
        "print(\"============================================================\")\n",
        "print(result.results[\"classifier\"].result)\n",
        "print(\"\\n\")\n",
        "\n",
        "#Execute task on newly built graph\n",
        "result = graph(\"Provide report on business impact of working from home, outline things to consider and key risk factors\")\n",
        "print(\"\\n\")\n",
        "print(\"============================================================\")\n",
        "print(\"============================================================\")\n",
        "\n",
        "print(f\"Response: {result}\")\n",
        "\n",
        "print(\"=============Node execution order:==========================\")\n",
        "print(\"============================================================\")\n",
        "\n",
        "# See which nodes were executed and in what order\n",
        "for node in result.execution_order:\n",
        "    print(f\"Executed: {node.node_id}\")\n",
        "\n",
        "print(\"=============Graph metrics:=================================\")\n",
        "print(\"============================================================\")\n",
        "\n",
        "\n",
        "# Get performance metrics\n",
        "print(f\"Total nodes: {result.total_nodes}\")\n",
        "print(f\"Completed nodes: {result.completed_nodes}\")\n",
        "print(f\"Failed nodes: {result.failed_nodes}\")\n",
        "print(f\"Execution time: {result.execution_time}ms\")\n",
        "print(f\"Token usage: {result.accumulated_usage}\")\n",
        "\n",
        "# Get results from specific nodes\n",
        "\n",
        "print(\"Classifier:\")\n",
        "print(\"============================================================\")\n",
        "print(\"============================================================\")\n",
        "print(result.results[\"classifier\"].result)\n",
        "print(\"\\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6d35f546-fe6a-4ce2-acf5-4ed8690c593d",
      "metadata": {
        "id": "6d35f546-fe6a-4ce2-acf5-4ed8690c593d"
      },
      "source": [
        "## Key Takeaways and Best Practices\n",
        "\n",
        "\n",
        "### Best Practices:\n",
        "\n",
        "**Design for acyclicity:** Ensure your graph has no cycles</p>\n",
        "**Use meaningful node IDs:** Choose descriptive names for nodes</p>\n",
        "**Validate graph structure:** The builder will check for cycles and validate entry points</p>\n",
        "**Handle node failures:** Consider how failures in one node affect the overall workflow</p>\n",
        "**Use conditional edges:** For dynamic workflows based on intermediate results</p>\n",
        "**Consider parallelism:** Independent branches can execute concurrently</p>\n",
        "**Nest multi-agent patterns:** Use Swarms within Graphs for complex workflows</p>\n",
        "**Leverage multi-modal inputs:** Use ContentBlocks for rich inputs including images</p>\n",
        "\n",
        "## Conclusion\n",
        "\n",
        "You've now mastered the fundamentals of building multi-agent systems with Strands Agent Graph! You can create sophisticated networks of specialized AI agents that collaborate to solve complex problems.\n",
        "\n",
        "The key to successful multi-agent systems is:\n",
        "- Matching topology to use case\n",
        "- Defining clear agent roles and responsibilities  \n",
        "- Establishing proper communication patterns\n",
        "- Managing resources and cleanup effectively\n",
        "\n",
        "From here, you can build increasingly sophisticated systems for real-world applications in research, content creation, decision-making, customer service, and beyond."
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.3"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "b3fa745a-a393-498b-ab51-68804fadf751",
      "metadata": {
        "id": "b3fa745a-a393-498b-ab51-68804fadf751"
      },
      "source": [
        "\n",
        "# Building Multi-Agent Systems with Strands Agent Graph\n",
        "Multi-agent systems leverage multiple specialized AI agents working together to solve complex problems through coordinated collaboration. Each agent has specific capabilities and roles, connected through explicit communication pathways.\n",
        "\n",
        "In this lab, you'll learn to build multi-agent systems using the Strands Agent SDK. We'll progress from basic concepts to advanced implementations, exploring different topologies and real-world applications.\n",
        "\n",
        "**Learning Objectives:**\n",
        "By the end of this notebook, you'll be able to:\n",
        "- Understand the three core components of agent graphs (nodes, edges, conditions)\n",
        "- Send targeted messages between specific agents\n",
        "- Monitor and control multi-agent networks\n",
        "- Design specialized agent systems for real-world scenarios\n",
        "\n",
        "## Prerequisites\n",
        "\n",
        "- Python 3.10+\n",
        "- AWS account with Anthropic Claude 3.7 enabled on Amazon Bedrock\n",
        "- IAM role with permissions to use Amazon Bedrock\n",
        "- Basic understanding of AI agents and prompt engineering"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "afc1a597-0490-4ab1-9324-5498b5592662",
      "metadata": {
        "id": "afc1a597-0490-4ab1-9324-5498b5592662"
      },
      "source": [
        "## Setup and Installation\n",
        "\n",
        "Before we start, let's install the requirement packages for `strands-agents` and `strands-agents-tools`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e048e8cf-3fa7-495b-a761-7999936171c5",
      "metadata": {
        "id": "e048e8cf-3fa7-495b-a761-7999936171c5"
      },
      "outputs": [],
      "source": [
        "!pip install -r requirements.txt"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.environ[\"PERPLEXITY_API_KEY\"] = \"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\"\n"
      ],
      "metadata": {
        "id": "CGsRUVY5rlcB"
      },
      "id": "CGsRUVY5rlcB",
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from strands import Agent\n",
        "import importlib\n",
        "import perplexity_model\n",
        "importlib.reload(perplexity_model)\n",
        "from perplexity_model import PerplexityModel\n",
        "\n",
        "\n",
        "model = PerplexityModel(\n",
        "    api_key='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',\n",
        "    model_id=\"sonar-pro\",\n",
        "    params={\"max_tokens\": 2048, \"temperature\": 0.7}\n",
        ")\n",
        "\n",
        "agent = Agent(model=model)\n",
        "response = agent(\"Hello, how are you today?\")\n",
        "print(response)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 339
        },
        "id": "tcuiSLxWtuq6",
        "outputId": "e2cbc814-1ba8-456f-b0fe-2415c3119131"
      },
      "id": "tcuiSLxWtuq6",
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ClientResponseError",
          "evalue": "400, message='Bad Request', url='https://api.perplexity.ai/chat/completions'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mClientResponseError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-3226169055.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0magent\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAgent\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0magent\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Hello, how are you today?\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/strands/agent/agent.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, prompt, invocation_state, structured_output_model, **kwargs)\u001b[0m\n\u001b[1;32m    455\u001b[0m                 \u001b[0;34m-\u001b[0m \u001b[0mstructured_output\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mParsed\u001b[0m \u001b[0mstructured\u001b[0m \u001b[0moutput\u001b[0m \u001b[0mwhen\u001b[0m \u001b[0mstructured_output_model\u001b[0m \u001b[0mwas\u001b[0m \u001b[0mspecified\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    456\u001b[0m         \"\"\"\n\u001b[0;32m--> 457\u001b[0;31m         return run_async(\n\u001b[0m\u001b[1;32m    458\u001b[0m             lambda: self.invoke_async(\n\u001b[1;32m    459\u001b[0m                 \u001b[0mprompt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minvocation_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minvocation_state\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstructured_output_model\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstructured_output_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/strands/_async.py\u001b[0m in \u001b[0;36mrun_async\u001b[0;34m(async_func)\u001b[0m\n\u001b[1;32m     31\u001b[0m         \u001b[0mcontext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcontextvars\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m         \u001b[0mfuture\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexecutor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubmit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexecute\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfuture\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/lib/python3.12/concurrent/futures/_base.py\u001b[0m in \u001b[0;36mresult\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    454\u001b[0m                     \u001b[0;32mraise\u001b[0m \u001b[0mCancelledError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    455\u001b[0m                 \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_state\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mFINISHED\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 456\u001b[0;31m                     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__get_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    457\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    458\u001b[0m                     \u001b[0;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/concurrent/futures/_base.py\u001b[0m in \u001b[0;36m__get_result\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    399\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_exception\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    400\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 401\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_exception\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    402\u001b[0m             \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    403\u001b[0m                 \u001b[0;31m# Break a reference cycle with the exception in self._exception\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/concurrent/futures/thread.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     60\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mBaseException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfuture\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/opentelemetry/instrumentation/threading/__init__.py\u001b[0m in \u001b[0;36mwrapped_func\u001b[0;34m(*func_args, **func_kwargs)\u001b[0m\n\u001b[1;32m    169\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    170\u001b[0m                 \u001b[0mtoken\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mattach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0motel_context\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 171\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0moriginal_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mfunc_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfunc_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    172\u001b[0m             \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    173\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mtoken\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/strands/_async.py\u001b[0m in \u001b[0;36mexecute\u001b[0;34m()\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mexecute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mT\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0masyncio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexecute_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mThreadPoolExecutor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mexecutor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/asyncio/runners.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(main, debug, loop_factory)\u001b[0m\n\u001b[1;32m    193\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    194\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mRunner\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdebug\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdebug\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloop_factory\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mloop_factory\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mrunner\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 195\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mrunner\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmain\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    196\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    197\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/asyncio/runners.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, coro, context)\u001b[0m\n\u001b[1;32m    116\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_interrupt_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 118\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_loop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_until_complete\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    119\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mexceptions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCancelledError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    120\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_interrupt_count\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/asyncio/base_events.py\u001b[0m in \u001b[0;36mrun_until_complete\u001b[0;34m(self, future)\u001b[0m\n\u001b[1;32m    689\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Event loop stopped before Future completed.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    690\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 691\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfuture\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    692\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    693\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mstop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/strands/_async.py\u001b[0m in \u001b[0;36mexecute_async\u001b[0;34m()\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[0;32masync\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mexecute_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mT\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0;32mawait\u001b[0m \u001b[0masync_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mexecute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mT\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/strands/agent/agent.py\u001b[0m in \u001b[0;36minvoke_async\u001b[0;34m(self, prompt, invocation_state, structured_output_model, **kwargs)\u001b[0m\n\u001b[1;32m    498\u001b[0m             \u001b[0mprompt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minvocation_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minvocation_state\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstructured_output_model\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstructured_output_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    499\u001b[0m         )\n\u001b[0;32m--> 500\u001b[0;31m         \u001b[0;32masync\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mevent\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mevents\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    501\u001b[0m             \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevent\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    502\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/strands/agent/agent.py\u001b[0m in \u001b[0;36mstream_async\u001b[0;34m(self, prompt, invocation_state, structured_output_model, **kwargs)\u001b[0m\n\u001b[1;32m    694\u001b[0m                 \u001b[0mevents\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_loop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmerged_state\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstructured_output_model\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    695\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 696\u001b[0;31m                 \u001b[0;32masync\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mevent\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mevents\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    697\u001b[0m                     \u001b[0mevent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprepare\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minvocation_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmerged_state\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    698\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/strands/agent/agent.py\u001b[0m in \u001b[0;36m_run_loop\u001b[0;34m(self, messages, invocation_state, structured_output_model)\u001b[0m\n\u001b[1;32m    742\u001b[0m             \u001b[0;31m# Execute the event loop cycle with retry logic for context limits\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    743\u001b[0m             \u001b[0mevents\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_execute_event_loop_cycle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minvocation_state\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstructured_output_context\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 744\u001b[0;31m             \u001b[0;32masync\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mevent\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mevents\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    745\u001b[0m                 \u001b[0;31m# Signal from the model provider that the message sent by the user should be redacted,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    746\u001b[0m                 \u001b[0;31m# likely due to a guardrail.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/strands/agent/agent.py\u001b[0m in \u001b[0;36m_execute_event_loop_cycle\u001b[0;34m(self, invocation_state, structured_output_context)\u001b[0m\n\u001b[1;32m    790\u001b[0m                 \u001b[0mstructured_output_context\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstructured_output_context\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    791\u001b[0m             )\n\u001b[0;32m--> 792\u001b[0;31m             \u001b[0;32masync\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mevent\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mevents\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    793\u001b[0m                 \u001b[0;32myield\u001b[0m \u001b[0mevent\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    794\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/strands/event_loop/event_loop.py\u001b[0m in \u001b[0;36mevent_loop_cycle\u001b[0;34m(agent, invocation_state, structured_output_context)\u001b[0m\n\u001b[1;32m    150\u001b[0m             \u001b[0magent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcycle_span\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcycle_trace\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minvocation_state\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtracer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstructured_output_context\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    151\u001b[0m         )\n\u001b[0;32m--> 152\u001b[0;31m         \u001b[0;32masync\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mmodel_event\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmodel_events\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    153\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_event\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mModelStopReason\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    154\u001b[0m                 \u001b[0;32myield\u001b[0m \u001b[0mmodel_event\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/strands/event_loop/event_loop.py\u001b[0m in \u001b[0;36m_handle_model_execution\u001b[0;34m(agent, cycle_span, cycle_trace, invocation_state, tracer, structured_output_context)\u001b[0m\n\u001b[1;32m    394\u001b[0m                     \u001b[0;32myield\u001b[0m \u001b[0mEventLoopThrottleEvent\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdelay\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcurrent_delay\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    395\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 396\u001b[0;31m                     \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    397\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    398\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/strands/event_loop/event_loop.py\u001b[0m in \u001b[0;36m_handle_model_execution\u001b[0;34m(agent, cycle_span, cycle_trace, invocation_state, tracer, structured_output_context)\u001b[0m\n\u001b[1;32m    335\u001b[0m                 \u001b[0mtool_specs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0magent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtool_registry\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_all_tool_specs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    336\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 337\u001b[0;31m                 async for event in stream_messages(\n\u001b[0m\u001b[1;32m    338\u001b[0m                     \u001b[0magent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    339\u001b[0m                     \u001b[0magent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msystem_prompt\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/strands/event_loop/streaming.py\u001b[0m in \u001b[0;36mstream_messages\u001b[0;34m(model, system_prompt, messages, tool_specs, tool_choice, system_prompt_content, **kwargs)\u001b[0m\n\u001b[1;32m    455\u001b[0m     )\n\u001b[1;32m    456\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 457\u001b[0;31m     \u001b[0;32masync\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mevent\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mprocess_stream\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchunks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstart_time\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    458\u001b[0m         \u001b[0;32myield\u001b[0m \u001b[0mevent\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/strands/event_loop/streaming.py\u001b[0m in \u001b[0;36mprocess_stream\u001b[0;34m(chunks, start_time)\u001b[0m\n\u001b[1;32m    389\u001b[0m     \u001b[0mmetrics\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mMetrics\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMetrics\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlatencyMs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeToFirstByteMs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    390\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 391\u001b[0;31m     \u001b[0;32masync\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mchunk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mchunks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    392\u001b[0m         \u001b[0;31m# Track first byte time when we get first content\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    393\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mfirst_byte_time\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\"contentBlockDelta\"\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mchunk\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m\"contentBlockStart\"\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mchunk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/perplexity_model.py\u001b[0m in \u001b[0;36mstream\u001b[0;34m(self, messages, tool_specs, system_prompt, **kwargs)\u001b[0m\n\u001b[1;32m     56\u001b[0m         \u001b[0;32masync\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0maiohttp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mClientSession\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m             \u001b[0;32masync\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpost\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mapi_url\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheaders\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mheaders\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mresp\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 58\u001b[0;31m                 \u001b[0mresp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_for_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     59\u001b[0m                 \u001b[0;32masync\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mline\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mresp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontent\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m                     \u001b[0;32myield\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parse_stream_event\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/aiohttp/client_reqrep.py\u001b[0m in \u001b[0;36mraise_for_status\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    634\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelease\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    635\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 636\u001b[0;31m             raise ClientResponseError(\n\u001b[0m\u001b[1;32m    637\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest_info\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    638\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mClientResponseError\u001b[0m: 400, message='Bad Request', url='https://api.perplexity.ai/chat/completions'"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9a203754-ecd3-402d-be98-9ee8facc23d9",
      "metadata": {
        "id": "9a203754-ecd3-402d-be98-9ee8facc23d9"
      },
      "source": [
        "### Importing required packages\n",
        "\n",
        "Next we can import the required packages"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "680c68aa-36e9-48e7-a3ed-9d2e63a3b95c",
      "metadata": {
        "id": "680c68aa-36e9-48e7-a3ed-9d2e63a3b95c"
      },
      "outputs": [],
      "source": [
        "from strands import Agent\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cb3b24d8-69d5-496d-92a5-24ff8705de1c",
      "metadata": {
        "id": "cb3b24d8-69d5-496d-92a5-24ff8705de1c"
      },
      "source": [
        "## Understanding Agent Graph Components\n",
        "An agent graph is a structured network of interconnected AI agents designed to solve complex problems through coordinated collaboration. Each agent represents a specialized node with specific capabilities, and the connections between agents define explicit communication pathways.\n",
        "\n",
        "Before we start building, let's understand the three primary components of an agent graph:\n",
        "\n",
        "### 1. Nodes (Agents)\n",
        "Each node represents an AI agent with:\n",
        "- **Identity**: Unique identifier within the graph\n",
        "- **Role**: Specialized function or purpose\n",
        "- **System Prompt**: Instructions defining the agent's behavior\n",
        "- **Tools**: Capabilities available to the agent\n",
        "\n",
        "### 2. Edges (Connections)\n",
        "Edges define communication pathways with:\n",
        "- **Direction**: One-way or bidirectional information flow\n",
        "- **Condition**: Optional function that determines if the edge should be traversed\n",
        "- **Dependencies**: Define execution order and data flow between nodes\n",
        "\n",
        "### 3. GraphBuilder\n",
        "The GraphBuilder provides a simple interface for constructing graphs:\n",
        "- **add_node()**: Add an agent or multi-agent system as a node\n",
        "- **add_edge()**: Create a dependency between nodes\n",
        "- **set_entry_point()**: Define starting nodes for execution\n",
        "- **build()**: Validate and create the Graph instance\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "80c47290-ef84-4ab5-ad14-70d41f0ed40b",
      "metadata": {
        "id": "80c47290-ef84-4ab5-ad14-70d41f0ed40b"
      },
      "source": [
        "### Basic processing\n",
        "\n",
        "Let's start with a simple example of one task processed by two different agents providing an output that will depend on their defined role. Take a look at the execution order of the nodes and also the fact that with STrands SDK you can explicitly get a response only from one single node if needed. Architecture looks as following:\n",
        "\n",
        "<div style=\"text-align:left\">\n",
        "    <img src=\"https://github.com/strands-agents/samples/blob/main/01-tutorials/02-multi-agent-systems/03-graph-agent/images/basic.png?raw=1\" width=\"55%\" />\n",
        "</div>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "eba5fc53-8eca-46e8-84cf-9ca0f551140d",
      "metadata": {
        "id": "eba5fc53-8eca-46e8-84cf-9ca0f551140d"
      },
      "outputs": [],
      "source": [
        "#Initialize an agent with agent_graph capability\n",
        "from strands.multiagent import GraphBuilder\n",
        "\n",
        "# Create specialized agents\n",
        "coordinator = Agent(name=\"coordinator\", system_prompt=\"You are a research team leader coordinating specialists. Provide a short analysis, no need for follow ups\")\n",
        "analyst = Agent(name=\"data_analyst\", system_prompt=\"You are a data analyst specializing in statistical analysis. Provide a short analysis, no need for follow ups\")\n",
        "domain_expert = Agent(name=\"domain_expert\", system_prompt=\"You are a domain expert with deep subject knowledge. Provide a short analysis, no need for follow ups\")\n",
        "\n",
        "# Build the graph\n",
        "builder = GraphBuilder()\n",
        "\n",
        "# Add nodes\n",
        "builder.add_node(coordinator, \"team_lead\")\n",
        "builder.add_node(analyst, \"analyst\")\n",
        "builder.add_node(domain_expert, \"expert\")\n",
        "\n",
        "# Add edges (dependencies)\n",
        "builder.add_edge(\"team_lead\", \"analyst\")\n",
        "builder.add_edge(\"team_lead\", \"expert\")\n",
        "\n",
        "# Set entry points (optional - will be auto-detected if not specified)\n",
        "builder.set_entry_point(\"team_lead\")\n",
        "\n",
        "# Build the graph\n",
        "graph = builder.build()\n",
        "\n",
        "#Execute task on newly built graph\n",
        "result = graph(\"Analyze the impact of remote work on employee productivity.Provide a short analysis, no need for follow ups\")\n",
        "print(\"\\n\")\n",
        "print(\"============================================================\")\n",
        "print(\"============================================================\")\n",
        "\n",
        "print(f\"Response: {result}\")\n",
        "\n",
        "print(\"=============Node execution order:==========================\")\n",
        "print(\"============================================================\")\n",
        "\n",
        "# See which nodes were executed and in what order\n",
        "for node in result.execution_order:\n",
        "    print(f\"Executed: {node.node_id}\")\n",
        "\n",
        "print(\"=============Graph metrics:=================================\")\n",
        "print(\"============================================================\")\n",
        "\n",
        "\n",
        "# Get performance metrics\n",
        "print(f\"Total nodes: {result.total_nodes}\")\n",
        "print(f\"Completed nodes: {result.completed_nodes}\")\n",
        "print(f\"Failed nodes: {result.failed_nodes}\")\n",
        "print(f\"Execution time: {result.execution_time}ms\")\n",
        "print(f\"Token usage: {result.accumulated_usage}\")\n",
        "\n",
        "\n",
        "# Get results from specific nodes\n",
        "print(\"\\n\")\n",
        "print(\"=============Expert node results only:======================\")\n",
        "print(\"============================================================\")\n",
        "print(result.results[\"expert\"].result)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "de57dc8d-d748-4dc4-8380-ed789ba84d6b",
      "metadata": {
        "id": "de57dc8d-d748-4dc4-8380-ed789ba84d6b"
      },
      "source": [
        "### Parallel processing\n",
        "\n",
        "Now let's create a topology when we will have 2 agents processing the request looking at 2 different aspect  of the problem and have them input into a final agent responsible for summarization and risk calculation based on provided input\n",
        "<div style=\"text-align:left\">\n",
        "    <img src=\"https://github.com/strands-agents/samples/blob/main/01-tutorials/02-multi-agent-systems/03-graph-agent/images/parallel.png?raw=1\" width=\"55%\" />\n",
        "</div>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7926cfeb-90c1-48cb-8d61-850ade47aebf",
      "metadata": {
        "id": "7926cfeb-90c1-48cb-8d61-850ade47aebf"
      },
      "outputs": [],
      "source": [
        "#Initialize an agent with agent_graph capability\n",
        "from strands.multiagent import GraphBuilder\n",
        "\n",
        "mesh_agent = Agent()\n",
        "# Create specialized agents\n",
        "\n",
        "financial_advisor = Agent(name=\"financial_advisor\", system_prompt=\"You are a financial advisor focused on cost-benefit analysis, budget implications, and ROI calculations. Engage with other experts to build comprehensive financial perspectives.\")\n",
        "technical_architect = Agent(name=\"technical_architect\", system_prompt=\"You are a technical architect who evaluates feasibility, implementation challenges, and technical risks. Collaborate with other experts to ensure technical viability.\")\n",
        "market_researcher = Agent(name=\"market_researcher\", system_prompt=\"You are a market researcher who analyzes market conditions, user needs, and competitive landscape. Work with other experts to validate market opportunities.\")\n",
        "risk_analyst = Agent(name=\"risk_analyst\", system_prompt=\"You are a risk analyst who identifies potential risks, mitigation strategies, and compliance issues. Collaborate with other experts to ensure comprehensive risk assessment.\")\n",
        "\n",
        "\n",
        "# Build the graph\n",
        "builder = GraphBuilder()\n",
        "\n",
        "# Add nodes\n",
        "builder.add_node(financial_advisor, \"finance_expert\")\n",
        "builder.add_node(technical_architect, \"tech_expert\")\n",
        "builder.add_node(market_researcher, \"market_expert\")\n",
        "builder.add_node(risk_analyst, \"risk_analyst\")\n",
        "\n",
        "# Add edges (dependencies)\n",
        "builder.add_edge(\"finance_expert\", \"tech_expert\")\n",
        "builder.add_edge(\"finance_expert\", \"market_expert\")\n",
        "builder.add_edge(\"tech_expert\", \"risk_analyst\")\n",
        "builder.add_edge(\"market_expert\", \"risk_analyst\")\n",
        "\n",
        "\n",
        "# Set entry points (optional - will be auto-detected if not specified)\n",
        "builder.set_entry_point(\"finance_expert\")\n",
        "\n",
        "# Build the graph\n",
        "graph = builder.build()\n",
        "\n",
        "print(\"============================================================\")\n",
        "print(\"============================================================\")\n",
        "\n",
        "#Execute task on newly built graph\n",
        "result = graph(\"Our company is considering launching a new AI-powered customer service platform. Initial investment is \\$2M with projected 3-year ROI of 150%. What's your financial assessment?\")\n",
        "print(\"\\n\")\n",
        "print(\"============================================================\")\n",
        "print(\"============================================================\")\n",
        "\n",
        "print(f\"Response: {result}\")\n",
        "\n",
        "print(\"=============Node execution order:==========================\")\n",
        "print(\"============================================================\")\n",
        "\n",
        "# See which nodes were executed and in what order\n",
        "for node in result.execution_order:\n",
        "    print(f\"Executed: {node.node_id}\")\n",
        "\n",
        "print(\"=============Graph metrics:=================================\")\n",
        "print(\"============================================================\")\n",
        "\n",
        "\n",
        "# Get performance metrics\n",
        "print(f\"Total nodes: {result.total_nodes}\")\n",
        "print(f\"Completed nodes: {result.completed_nodes}\")\n",
        "print(f\"Failed nodes: {result.failed_nodes}\")\n",
        "print(f\"Execution time: {result.execution_time}ms\")\n",
        "print(f\"Token usage: {result.accumulated_usage}\")\n",
        "\n",
        "\n",
        "# Get results from specific nodes\n",
        "\n",
        "print(\"Financial Advisor:\")\n",
        "print(\"============================================================\")\n",
        "print(\"============================================================\")\n",
        "print(result.results[\"finance_expert\"].result)\n",
        "print(\"\\n\")\n",
        "\n",
        "print(\"Technical Expert:\")\n",
        "print(\"============================================================\")\n",
        "print(\"============================================================\")\n",
        "print(result.results[\"tech_expert\"].result)\n",
        "print(\"\\n\")\n",
        "\n",
        "print(\"Market Researcher:\")\n",
        "print(\"============================================================\")\n",
        "print(\"============================================================\")\n",
        "print(result.results[\"market_expert\"].result)\n",
        "print(\"\\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ae0eb88e-fdc1-4387-8eb0-4a9ae50ca2ea",
      "metadata": {
        "id": "ae0eb88e-fdc1-4387-8eb0-4a9ae50ca2ea"
      },
      "source": [
        "### Branching with conditions\n",
        "\n",
        "Let's create an agent graph that would classify the request and depending on conditions we define in the code - will route the request either to technical or business agent.\n",
        "\n",
        "Take a close look on differences between the node execution order and number of nodes executed in this graph based on two different prompts.\n",
        "\n",
        "<div style=\"text-align:left\">\n",
        "    <img src=\"https://github.com/strands-agents/samples/blob/main/01-tutorials/02-multi-agent-systems/03-graph-agent/images/conditional.png?raw=1\" width=\"55%\" />\n",
        "</div>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5058e219-8fb8-4503-8bbf-9e69dd06cf62",
      "metadata": {
        "id": "5058e219-8fb8-4503-8bbf-9e69dd06cf62"
      },
      "outputs": [],
      "source": [
        "#Initialize an agent with agent_graph capability\n",
        "from strands.multiagent import GraphBuilder\n",
        "\n",
        "mesh_agent = Agent()\n",
        "# Create specialized agents\n",
        "\n",
        "classifier = Agent(name=\"classifier\", system_prompt=\"You are an agent responsible for classification of the report request, return only Technical or Business clasification.\")\n",
        "technical_report = Agent(name=\"technical_expert\", system_prompt=\"You are a technical expert htat focuses on providing short summary from technical perspective\")\n",
        "business_report = Agent(name=\"business_expert\", system_prompt=\"You are a business expert that focuses on providing short summary from business perspective\")\n",
        "\n",
        "# Build the graph\n",
        "builder = GraphBuilder()\n",
        "\n",
        "# Add nodes\n",
        "builder.add_node(classifier, \"classifier\")\n",
        "builder.add_node(technical_report, \"technical_report\")\n",
        "builder.add_node(business_report, \"business_report\")\n",
        "\n",
        "def is_technical(state):\n",
        "    classifier_result = state.results.get(\"classifier\")\n",
        "    if not classifier_result:\n",
        "        return False\n",
        "    result_text = str(classifier_result.result)\n",
        "    return \"technical\" in result_text.lower()\n",
        "\n",
        "def is_business(state):\n",
        "    classifier_result = state.results.get(\"classifier\")\n",
        "    if not classifier_result:\n",
        "        return False\n",
        "    result_text = str(classifier_result.result)\n",
        "    return \"business\" in result_text.lower()\n",
        "\n",
        "# Add edges (dependencies)\n",
        "builder.add_edge(\"classifier\", \"technical_report\", condition=is_technical)\n",
        "builder.add_edge(\"classifier\", \"business_report\", condition=is_business)\n",
        "\n",
        "# Set entry points (optional - will be auto-detected if not specified)\n",
        "builder.set_entry_point(\"classifier\")\n",
        "\n",
        "# Build the graph\n",
        "graph = builder.build()\n",
        "\n",
        "print(\"============================================================\")\n",
        "print(\"============================================================\")\n",
        "\n",
        "#Execute task on newly built graph\n",
        "result = graph(\"Provide report on technical aspect of working from home, outline things to consider and key risk factors\")\n",
        "print(\"\\n\")\n",
        "print(\"============================================================\")\n",
        "print(\"============================================================\")\n",
        "\n",
        "print(f\"Response: {result}\")\n",
        "\n",
        "print(\"=============Node execution order:==========================\")\n",
        "print(\"============================================================\")\n",
        "\n",
        "# See which nodes were executed and in what order\n",
        "for node in result.execution_order:\n",
        "    print(f\"Executed: {node.node_id}\")\n",
        "\n",
        "print(\"=============Graph metrics:=================================\")\n",
        "print(\"============================================================\")\n",
        "\n",
        "\n",
        "# Get performance metrics\n",
        "print(f\"Total nodes: {result.total_nodes}\")\n",
        "print(f\"Completed nodes: {result.completed_nodes}\")\n",
        "print(f\"Failed nodes: {result.failed_nodes}\")\n",
        "print(f\"Execution time: {result.execution_time}ms\")\n",
        "print(f\"Token usage: {result.accumulated_usage}\")\n",
        "\n",
        "# Get results from specific nodes\n",
        "\n",
        "print(\"Classifier:\")\n",
        "print(\"============================================================\")\n",
        "print(\"============================================================\")\n",
        "print(result.results[\"classifier\"].result)\n",
        "print(\"\\n\")\n",
        "\n",
        "#Execute task on newly built graph\n",
        "result = graph(\"Provide report on business impact of working from home, outline things to consider and key risk factors\")\n",
        "print(\"\\n\")\n",
        "print(\"============================================================\")\n",
        "print(\"============================================================\")\n",
        "\n",
        "print(f\"Response: {result}\")\n",
        "\n",
        "print(\"=============Node execution order:==========================\")\n",
        "print(\"============================================================\")\n",
        "\n",
        "# See which nodes were executed and in what order\n",
        "for node in result.execution_order:\n",
        "    print(f\"Executed: {node.node_id}\")\n",
        "\n",
        "print(\"=============Graph metrics:=================================\")\n",
        "print(\"============================================================\")\n",
        "\n",
        "\n",
        "# Get performance metrics\n",
        "print(f\"Total nodes: {result.total_nodes}\")\n",
        "print(f\"Completed nodes: {result.completed_nodes}\")\n",
        "print(f\"Failed nodes: {result.failed_nodes}\")\n",
        "print(f\"Execution time: {result.execution_time}ms\")\n",
        "print(f\"Token usage: {result.accumulated_usage}\")\n",
        "\n",
        "# Get results from specific nodes\n",
        "\n",
        "print(\"Classifier:\")\n",
        "print(\"============================================================\")\n",
        "print(\"============================================================\")\n",
        "print(result.results[\"classifier\"].result)\n",
        "print(\"\\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6d35f546-fe6a-4ce2-acf5-4ed8690c593d",
      "metadata": {
        "id": "6d35f546-fe6a-4ce2-acf5-4ed8690c593d"
      },
      "source": [
        "## Key Takeaways and Best Practices\n",
        "\n",
        "\n",
        "### Best Practices:\n",
        "\n",
        "**Design for acyclicity:** Ensure your graph has no cycles</p>\n",
        "**Use meaningful node IDs:** Choose descriptive names for nodes</p>\n",
        "**Validate graph structure:** The builder will check for cycles and validate entry points</p>\n",
        "**Handle node failures:** Consider how failures in one node affect the overall workflow</p>\n",
        "**Use conditional edges:** For dynamic workflows based on intermediate results</p>\n",
        "**Consider parallelism:** Independent branches can execute concurrently</p>\n",
        "**Nest multi-agent patterns:** Use Swarms within Graphs for complex workflows</p>\n",
        "**Leverage multi-modal inputs:** Use ContentBlocks for rich inputs including images</p>\n",
        "\n",
        "## Conclusion\n",
        "\n",
        "You've now mastered the fundamentals of building multi-agent systems with Strands Agent Graph! You can create sophisticated networks of specialized AI agents that collaborate to solve complex problems.\n",
        "\n",
        "The key to successful multi-agent systems is:\n",
        "- Matching topology to use case\n",
        "- Defining clear agent roles and responsibilities  \n",
        "- Establishing proper communication patterns\n",
        "- Managing resources and cleanup effectively\n",
        "\n",
        "From here, you can build increasingly sophisticated systems for real-world applications in research, content creation, decision-making, customer service, and beyond."
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.3"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
